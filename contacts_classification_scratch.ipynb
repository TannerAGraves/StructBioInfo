{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ewVXNIEM7IV_",
        "outputId": "c94a2c13-ef2d-4843-917a-6d7753eafc76",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.1.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.6.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n"
          ]
        }
      ],
      "source": [
        "!pip3 install scikit-learn\n",
        "!pip3 install torch\n",
        "!pip3 install torchinfo\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AKx-1SDs7IWH",
        "outputId": "15ad7a7d-bae7-4604-892d-f6194f3a6db7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-colab in /usr/local/lib/python3.10/dist-packages (1.0.0)\n",
            "Requirement already satisfied: google-auth==2.17.3 in /usr/local/lib/python3.10/dist-packages (from google-colab) (2.17.3)\n",
            "Requirement already satisfied: ipykernel==5.5.6 in /usr/local/lib/python3.10/dist-packages (from google-colab) (5.5.6)\n",
            "Requirement already satisfied: ipython==7.34.0 in /usr/local/lib/python3.10/dist-packages (from google-colab) (7.34.0)\n",
            "Requirement already satisfied: notebook==6.4.8 in /usr/local/lib/python3.10/dist-packages (from google-colab) (6.4.8)\n",
            "Requirement already satisfied: pandas==1.5.3 in /usr/local/lib/python3.10/dist-packages (from google-colab) (1.5.3)\n",
            "Requirement already satisfied: portpicker==1.5.2 in /usr/local/lib/python3.10/dist-packages (from google-colab) (1.5.2)\n",
            "Requirement already satisfied: requests==2.27.1 in /usr/local/lib/python3.10/dist-packages (from google-colab) (2.27.1)\n",
            "Requirement already satisfied: tornado==6.3.1 in /usr/local/lib/python3.10/dist-packages (from google-colab) (6.3.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth==2.17.3->google-colab) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth==2.17.3->google-colab) (0.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth==2.17.3->google-colab) (1.16.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth==2.17.3->google-colab) (4.9)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.10/dist-packages (from ipykernel==5.5.6->google-colab) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel==5.5.6->google-colab) (5.7.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel==5.5.6->google-colab) (6.1.12)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython==7.34.0->google-colab) (67.7.2)\n",
            "Collecting jedi>=0.16 (from ipython==7.34.0->google-colab)\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython==7.34.0->google-colab) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython==7.34.0->google-colab) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython==7.34.0->google-colab) (3.0.38)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython==7.34.0->google-colab) (2.14.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython==7.34.0->google-colab) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython==7.34.0->google-colab) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython==7.34.0->google-colab) (4.8.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from notebook==6.4.8->google-colab) (3.1.2)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.10/dist-packages (from notebook==6.4.8->google-colab) (23.2.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook==6.4.8->google-colab) (21.3.0)\n",
            "Requirement already satisfied: jupyter-core>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from notebook==6.4.8->google-colab) (5.3.1)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from notebook==6.4.8->google-colab) (5.9.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.10/dist-packages (from notebook==6.4.8->google-colab) (6.5.4)\n",
            "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook==6.4.8->google-colab) (1.5.6)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook==6.4.8->google-colab) (1.8.2)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook==6.4.8->google-colab) (0.17.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook==6.4.8->google-colab) (0.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas==1.5.3->google-colab) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas==1.5.3->google-colab) (2022.7.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas==1.5.3->google-colab) (1.22.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from portpicker==1.5.2->google-colab) (5.9.5)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests==2.27.1->google-colab) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests==2.27.1->google-colab) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests==2.27.1->google-colab) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests==2.27.1->google-colab) (3.4)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython==7.34.0->google-colab) (0.8.3)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.6.1->notebook==6.4.8->google-colab) (3.7.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython==7.34.0->google-colab) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython==7.34.0->google-colab) (0.2.6)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth==2.17.3->google-colab) (0.5.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook==6.4.8->google-colab) (21.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->notebook==6.4.8->google-colab) (2.1.3)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nbconvert->notebook==6.4.8->google-colab) (4.9.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert->notebook==6.4.8->google-colab) (4.11.2)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from nbconvert->notebook==6.4.8->google-colab) (6.0.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert->notebook==6.4.8->google-colab) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert->notebook==6.4.8->google-colab) (0.4)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert->notebook==6.4.8->google-colab) (0.2.2)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->notebook==6.4.8->google-colab) (0.8.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert->notebook==6.4.8->google-colab) (0.8.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from nbconvert->notebook==6.4.8->google-colab) (23.1)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->notebook==6.4.8->google-colab) (1.5.0)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert->notebook==6.4.8->google-colab) (1.2.1)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook==6.4.8->google-colab) (2.17.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook==6.4.8->google-colab) (4.3.3)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook==6.4.8->google-colab) (23.1.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook==6.4.8->google-colab) (0.19.3)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook==6.4.8->google-colab) (1.15.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert->notebook==6.4.8->google-colab) (2.4.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->nbconvert->notebook==6.4.8->google-colab) (0.5.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook==6.4.8->google-colab) (2.21)\n",
            "Installing collected packages: jedi\n",
            "Successfully installed jedi-0.18.2\n"
          ]
        }
      ],
      "source": [
        "!pip3 install google-colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "i1nJM4827IWE"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchinfo import summary\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_GVRc7Ky7IWG"
      },
      "outputs": [],
      "source": [
        "# only for running locally\n",
        "#dfs = []\n",
        "#for filename in os.listdir('features_ring'):\n",
        "#    if filename[-4:] == '.tsv':\n",
        "#        dfs.append(pd.read_csv('features_ring/' + filename, sep='\\t'))\n",
        "#df = pd.concat(dfs)\n",
        "#df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rmKCVbWQ7IWG"
      },
      "outputs": [],
      "source": [
        "# don't need to execute - only to export df for training in cloud\n",
        "#df.to_csv('contact_df.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FO0jpYz27IWI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce1093ce-cd56-4b36-ab4e-1a50abc80e5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# only for running on drive for training\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "df = pd.read_csv('drive/MyDrive/StructuralBioinformatics/data/contact_df.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PcBk80rJ7IWI",
        "outputId": "c4fd6a63-9452-4de5-a9de-3c0b68055b9c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0               VDW\n",
              "1             HBOND\n",
              "2             HBOND\n",
              "3         PIPISTACK\n",
              "4             HBOND\n",
              "            ...    \n",
              "454188          VDW\n",
              "454189        HBOND\n",
              "454190          VDW\n",
              "454191        HBOND\n",
              "454192        HBOND\n",
              "Name: Interaction, Length: 454193, dtype: category\n",
              "Categories (6, object): ['HBOND', 'IONIC', 'PICATION', 'PIPISTACK', 'SSBOND', 'VDW']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "df.dropna(inplace=True)\n",
        "\n",
        "# Define ground truth values\n",
        "y = df['Interaction'].astype('category')\n",
        "y_oneHot = pd.get_dummies(y)\n",
        "y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "God_1B2t7IWJ",
        "outputId": "cd32d562-4a3d-4206-ad5e-c09125c2a6e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           s_rsa      s_up    s_down     s_phi     s_psi      s_a1      s_a2  \\\n",
              "0      -0.612926  1.212548  1.272426 -0.080637  1.435561  1.032979  0.438314   \n",
              "1       0.235709  0.077481 -0.558473  0.268180 -0.783304  1.337499 -1.430106   \n",
              "2       1.797971 -1.341352 -0.009203  0.266785 -0.772920  0.928827  0.998308   \n",
              "3      -0.096994  1.070665 -0.741563 -1.206618  1.219451 -1.006413 -0.511333   \n",
              "4      -0.096994  1.070665 -0.741563 -1.206618  1.219451 -1.006413 -0.511333   \n",
              "...          ...       ...       ...       ...       ...       ...       ...   \n",
              "454188  1.161494 -2.050769  0.173887 -0.373643 -0.294621 -0.389438  1.875560   \n",
              "454189 -0.786511  0.503131 -0.558473  0.021218  1.453084 -1.006413 -0.511333   \n",
              "454190 -0.878125  0.645015 -0.009203 -0.975003  1.163638 -1.237531 -0.465554   \n",
              "454191  1.682248 -1.341352 -1.107742 -1.269405 -0.158335  1.807671 -0.480459   \n",
              "454192  1.209712 -1.341352  0.906247  0.183069  1.325884 -1.019308 -0.933990   \n",
              "\n",
              "            s_a3      s_a4      s_a5     t_rsa      t_up    t_down     t_phi  \\\n",
              "0      -1.675155 -0.535573 -1.967293 -0.926898  0.482516  1.366067 -1.502723   \n",
              "1       0.702567 -0.124882 -0.467409 -0.118231 -0.267989 -0.712127  0.257241   \n",
              "2       0.620114 -0.436212  0.636456  1.398591 -1.318697  0.500153  0.283161   \n",
              "3       0.894341 -0.687926  0.311533 -0.926898  0.932819  1.192884 -1.816354   \n",
              "4       0.894341 -0.687926  0.311533 -0.926898  0.932819  1.192884 -1.816354   \n",
              "...          ...       ...       ...       ...       ...       ...       ...   \n",
              "454188  0.634473  0.904054  1.341807  0.854911 -1.618899  1.019702  0.564392   \n",
              "454189  0.894341 -0.687926  0.311533  1.901152 -2.219303 -0.538944  4.190592   \n",
              "454190  1.005515  0.184240  0.563489 -0.433474  1.082920 -1.404858 -1.406819   \n",
              "454191  0.265285 -0.555445  1.082368  2.335182 -2.369404 -1.058493  3.708481   \n",
              "454192 -0.678763  1.148039 -0.514183 -0.675617  0.482516  1.192884 -0.590341   \n",
              "\n",
              "           t_psi      t_a1      t_a2      t_a3      t_a4      t_a5  \n",
              "0       1.362867 -0.045132  0.558611  1.029760  0.741296  0.813673  \n",
              "1      -0.791289  1.476577  0.135358  0.690168  0.232221  1.818554  \n",
              "2      -0.812362  1.003587  0.531949 -1.773429 -0.528128 -2.075994  \n",
              "3       1.560677 -0.989173 -0.458974  0.875965 -0.678240  0.242084  \n",
              "4       1.560677 -0.989173 -0.458974  0.875965 -0.678240  0.242084  \n",
              "...          ...       ...       ...       ...       ...       ...  \n",
              "454188 -0.796048 -1.001773 -0.900002 -0.746055  1.130717 -0.597855  \n",
              "454189 -0.494914 -0.386305  2.031665  0.608016  0.890320  1.290104  \n",
              "454190  1.223517  0.237886  1.118505  1.451982 -1.157946  0.939918  \n",
              "454191 -0.372558 -0.386305  2.031665  0.608016  0.890320  1.290104  \n",
              "454192 -0.099295  1.003587  0.531949 -1.773429 -0.528128 -2.075994  \n",
              "\n",
              "[454193 rows x 20 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5bddb79f-1178-42e8-a768-533c3fa45d0a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>s_rsa</th>\n",
              "      <th>s_up</th>\n",
              "      <th>s_down</th>\n",
              "      <th>s_phi</th>\n",
              "      <th>s_psi</th>\n",
              "      <th>s_a1</th>\n",
              "      <th>s_a2</th>\n",
              "      <th>s_a3</th>\n",
              "      <th>s_a4</th>\n",
              "      <th>s_a5</th>\n",
              "      <th>t_rsa</th>\n",
              "      <th>t_up</th>\n",
              "      <th>t_down</th>\n",
              "      <th>t_phi</th>\n",
              "      <th>t_psi</th>\n",
              "      <th>t_a1</th>\n",
              "      <th>t_a2</th>\n",
              "      <th>t_a3</th>\n",
              "      <th>t_a4</th>\n",
              "      <th>t_a5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.612926</td>\n",
              "      <td>1.212548</td>\n",
              "      <td>1.272426</td>\n",
              "      <td>-0.080637</td>\n",
              "      <td>1.435561</td>\n",
              "      <td>1.032979</td>\n",
              "      <td>0.438314</td>\n",
              "      <td>-1.675155</td>\n",
              "      <td>-0.535573</td>\n",
              "      <td>-1.967293</td>\n",
              "      <td>-0.926898</td>\n",
              "      <td>0.482516</td>\n",
              "      <td>1.366067</td>\n",
              "      <td>-1.502723</td>\n",
              "      <td>1.362867</td>\n",
              "      <td>-0.045132</td>\n",
              "      <td>0.558611</td>\n",
              "      <td>1.029760</td>\n",
              "      <td>0.741296</td>\n",
              "      <td>0.813673</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.235709</td>\n",
              "      <td>0.077481</td>\n",
              "      <td>-0.558473</td>\n",
              "      <td>0.268180</td>\n",
              "      <td>-0.783304</td>\n",
              "      <td>1.337499</td>\n",
              "      <td>-1.430106</td>\n",
              "      <td>0.702567</td>\n",
              "      <td>-0.124882</td>\n",
              "      <td>-0.467409</td>\n",
              "      <td>-0.118231</td>\n",
              "      <td>-0.267989</td>\n",
              "      <td>-0.712127</td>\n",
              "      <td>0.257241</td>\n",
              "      <td>-0.791289</td>\n",
              "      <td>1.476577</td>\n",
              "      <td>0.135358</td>\n",
              "      <td>0.690168</td>\n",
              "      <td>0.232221</td>\n",
              "      <td>1.818554</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.797971</td>\n",
              "      <td>-1.341352</td>\n",
              "      <td>-0.009203</td>\n",
              "      <td>0.266785</td>\n",
              "      <td>-0.772920</td>\n",
              "      <td>0.928827</td>\n",
              "      <td>0.998308</td>\n",
              "      <td>0.620114</td>\n",
              "      <td>-0.436212</td>\n",
              "      <td>0.636456</td>\n",
              "      <td>1.398591</td>\n",
              "      <td>-1.318697</td>\n",
              "      <td>0.500153</td>\n",
              "      <td>0.283161</td>\n",
              "      <td>-0.812362</td>\n",
              "      <td>1.003587</td>\n",
              "      <td>0.531949</td>\n",
              "      <td>-1.773429</td>\n",
              "      <td>-0.528128</td>\n",
              "      <td>-2.075994</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.096994</td>\n",
              "      <td>1.070665</td>\n",
              "      <td>-0.741563</td>\n",
              "      <td>-1.206618</td>\n",
              "      <td>1.219451</td>\n",
              "      <td>-1.006413</td>\n",
              "      <td>-0.511333</td>\n",
              "      <td>0.894341</td>\n",
              "      <td>-0.687926</td>\n",
              "      <td>0.311533</td>\n",
              "      <td>-0.926898</td>\n",
              "      <td>0.932819</td>\n",
              "      <td>1.192884</td>\n",
              "      <td>-1.816354</td>\n",
              "      <td>1.560677</td>\n",
              "      <td>-0.989173</td>\n",
              "      <td>-0.458974</td>\n",
              "      <td>0.875965</td>\n",
              "      <td>-0.678240</td>\n",
              "      <td>0.242084</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.096994</td>\n",
              "      <td>1.070665</td>\n",
              "      <td>-0.741563</td>\n",
              "      <td>-1.206618</td>\n",
              "      <td>1.219451</td>\n",
              "      <td>-1.006413</td>\n",
              "      <td>-0.511333</td>\n",
              "      <td>0.894341</td>\n",
              "      <td>-0.687926</td>\n",
              "      <td>0.311533</td>\n",
              "      <td>-0.926898</td>\n",
              "      <td>0.932819</td>\n",
              "      <td>1.192884</td>\n",
              "      <td>-1.816354</td>\n",
              "      <td>1.560677</td>\n",
              "      <td>-0.989173</td>\n",
              "      <td>-0.458974</td>\n",
              "      <td>0.875965</td>\n",
              "      <td>-0.678240</td>\n",
              "      <td>0.242084</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>454188</th>\n",
              "      <td>1.161494</td>\n",
              "      <td>-2.050769</td>\n",
              "      <td>0.173887</td>\n",
              "      <td>-0.373643</td>\n",
              "      <td>-0.294621</td>\n",
              "      <td>-0.389438</td>\n",
              "      <td>1.875560</td>\n",
              "      <td>0.634473</td>\n",
              "      <td>0.904054</td>\n",
              "      <td>1.341807</td>\n",
              "      <td>0.854911</td>\n",
              "      <td>-1.618899</td>\n",
              "      <td>1.019702</td>\n",
              "      <td>0.564392</td>\n",
              "      <td>-0.796048</td>\n",
              "      <td>-1.001773</td>\n",
              "      <td>-0.900002</td>\n",
              "      <td>-0.746055</td>\n",
              "      <td>1.130717</td>\n",
              "      <td>-0.597855</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>454189</th>\n",
              "      <td>-0.786511</td>\n",
              "      <td>0.503131</td>\n",
              "      <td>-0.558473</td>\n",
              "      <td>0.021218</td>\n",
              "      <td>1.453084</td>\n",
              "      <td>-1.006413</td>\n",
              "      <td>-0.511333</td>\n",
              "      <td>0.894341</td>\n",
              "      <td>-0.687926</td>\n",
              "      <td>0.311533</td>\n",
              "      <td>1.901152</td>\n",
              "      <td>-2.219303</td>\n",
              "      <td>-0.538944</td>\n",
              "      <td>4.190592</td>\n",
              "      <td>-0.494914</td>\n",
              "      <td>-0.386305</td>\n",
              "      <td>2.031665</td>\n",
              "      <td>0.608016</td>\n",
              "      <td>0.890320</td>\n",
              "      <td>1.290104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>454190</th>\n",
              "      <td>-0.878125</td>\n",
              "      <td>0.645015</td>\n",
              "      <td>-0.009203</td>\n",
              "      <td>-0.975003</td>\n",
              "      <td>1.163638</td>\n",
              "      <td>-1.237531</td>\n",
              "      <td>-0.465554</td>\n",
              "      <td>1.005515</td>\n",
              "      <td>0.184240</td>\n",
              "      <td>0.563489</td>\n",
              "      <td>-0.433474</td>\n",
              "      <td>1.082920</td>\n",
              "      <td>-1.404858</td>\n",
              "      <td>-1.406819</td>\n",
              "      <td>1.223517</td>\n",
              "      <td>0.237886</td>\n",
              "      <td>1.118505</td>\n",
              "      <td>1.451982</td>\n",
              "      <td>-1.157946</td>\n",
              "      <td>0.939918</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>454191</th>\n",
              "      <td>1.682248</td>\n",
              "      <td>-1.341352</td>\n",
              "      <td>-1.107742</td>\n",
              "      <td>-1.269405</td>\n",
              "      <td>-0.158335</td>\n",
              "      <td>1.807671</td>\n",
              "      <td>-0.480459</td>\n",
              "      <td>0.265285</td>\n",
              "      <td>-0.555445</td>\n",
              "      <td>1.082368</td>\n",
              "      <td>2.335182</td>\n",
              "      <td>-2.369404</td>\n",
              "      <td>-1.058493</td>\n",
              "      <td>3.708481</td>\n",
              "      <td>-0.372558</td>\n",
              "      <td>-0.386305</td>\n",
              "      <td>2.031665</td>\n",
              "      <td>0.608016</td>\n",
              "      <td>0.890320</td>\n",
              "      <td>1.290104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>454192</th>\n",
              "      <td>1.209712</td>\n",
              "      <td>-1.341352</td>\n",
              "      <td>0.906247</td>\n",
              "      <td>0.183069</td>\n",
              "      <td>1.325884</td>\n",
              "      <td>-1.019308</td>\n",
              "      <td>-0.933990</td>\n",
              "      <td>-0.678763</td>\n",
              "      <td>1.148039</td>\n",
              "      <td>-0.514183</td>\n",
              "      <td>-0.675617</td>\n",
              "      <td>0.482516</td>\n",
              "      <td>1.192884</td>\n",
              "      <td>-0.590341</td>\n",
              "      <td>-0.099295</td>\n",
              "      <td>1.003587</td>\n",
              "      <td>0.531949</td>\n",
              "      <td>-1.773429</td>\n",
              "      <td>-0.528128</td>\n",
              "      <td>-2.075994</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>454193 rows × 20 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5bddb79f-1178-42e8-a768-533c3fa45d0a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5bddb79f-1178-42e8-a768-533c3fa45d0a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5bddb79f-1178-42e8-a768-533c3fa45d0a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "# Define training features\n",
        "X = df[['s_rsa', 's_up', 's_down', 's_phi', 's_psi', 's_a1', 's_a2', 's_a3', 's_a4', 's_a5',\n",
        "        't_rsa', 't_up', 't_down', 't_phi', 't_psi', 't_a1', 't_a2', 't_a3', 't_a4', 't_a5']]\n",
        "\n",
        "#is this working?\n",
        "X = X.fillna({col: X[col].mode()[0] for col in X.columns})\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_scaled = pd.DataFrame(X_scaled, columns=X.columns)\n",
        "X_scaled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "tPxPV5w_7IWK"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_oneHot, test_size=0.1, random_state=0)\n",
        "kf = KFold(n_splits=10, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "u0Y845Xj7IWL",
        "outputId": "862dad11-2c1b-46da-88d1-849cd0cb6117",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "=================================================================\n",
              "Layer (type:depth-idx)                   Param #\n",
              "=================================================================\n",
              "ContactNet                               --\n",
              "├─ModuleList: 1-1                        --\n",
              "│    └─Linear: 2-1                       1,260\n",
              "│    └─Linear: 2-2                       3,660\n",
              "│    └─Linear: 2-3                       7,808\n",
              "│    └─Linear: 2-4                       16,512\n",
              "│    └─Linear: 2-5                       16,512\n",
              "│    └─Linear: 2-6                       16,512\n",
              "│    └─Linear: 2-7                       33,024\n",
              "│    └─Linear: 2-8                       65,792\n",
              "│    └─Linear: 2-9                       65,792\n",
              "│    └─Linear: 2-10                      65,792\n",
              "│    └─Linear: 2-11                      1,542\n",
              "=================================================================\n",
              "Total params: 294,206\n",
              "Trainable params: 294,206\n",
              "Non-trainable params: 0\n",
              "================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ],
      "source": [
        "class ContactNet(nn.Module):\n",
        "    def __init__(self, input_dim, num_classes, hidden_layers_dim=[]):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList()\n",
        "        if len(hidden_layers_dim) == 0:\n",
        "            self.layers = self.layers.append(nn.Linear(input_dim, num_classes))\n",
        "        else:\n",
        "            for layer_idx in range(len(hidden_layers_dim)):\n",
        "                if layer_idx == 0:  # first layer, from input to hidden\n",
        "                    self.layers = self.layers.append(nn.Linear(input_dim, hidden_layers_dim[layer_idx]))\n",
        "                else:  # hidden layers, depending on the input\n",
        "                    self.layers = self.layers.append(nn.Linear(hidden_layers_dim[layer_idx-1], hidden_layers_dim[layer_idx]))\n",
        "            self.layers = self.layers.append(nn.Linear(hidden_layers_dim[-1], num_classes))  # final output layer\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, nn.Linear):\n",
        "            module.weight.data.normal_(mean=0.0, std=.1)\n",
        "            if module.bias is not None:\n",
        "                module.bias.data.zero_()\n",
        "\n",
        "    def forward(self, x):\n",
        "        if not isinstance(x, torch.Tensor):\n",
        "            x = torch.Tensor(x)\n",
        "        if x.dtype != torch.float32:\n",
        "            x = x.float()\n",
        "        if len(self.layers) == 1:\n",
        "            return self.layers[0](x)\n",
        "        else:\n",
        "            for layer in self.layers[:-1]:\n",
        "                x = F.relu(layer(x))\n",
        "        return F.log_softmax(x, dim=1)#self.layers[-1](x)\n",
        "\n",
        "input_size = X.shape[1]  # The number of input features\n",
        "num_classes = y_oneHot.shape[1] # The number of output classes\n",
        "\n",
        "model = ContactNet(input_size, num_classes, [60, 60, 128, 128, 128, 128, 256, 256, 256, 256])\n",
        "\n",
        "# Criterion and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "lr = 1e-3\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "summary(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "Ik79A97A7IWM"
      },
      "outputs": [],
      "source": [
        "class EarlyStopping:\n",
        "    def __init__(self, tolerance, min_delta):\n",
        "        self.tolerance = tolerance\n",
        "        self.min_delta = min_delta\n",
        "        self.counter = 0\n",
        "        self.early_stop = False\n",
        "\n",
        "    def __call__(self, train_loss, validation_loss):\n",
        "        if abs(validation_loss - train_loss) > self.min_delta:\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.tolerance:\n",
        "                self.early_stop = True\n",
        "\n",
        "\n",
        "def train(model, optimizer, num_epochs):\n",
        "    early_stopping = EarlyStopping(tolerance=7, min_delta=0.001)\n",
        "\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    train_accuracies = []\n",
        "    val_accuracies = []\n",
        "\n",
        "    for train_index, val_index in kf.split(X_train):\n",
        "\n",
        "        early_stopping.early_stop = False\n",
        "        early_stopping.counter = 0\n",
        "\n",
        "        X_train_fold = X_train.values[train_index]\n",
        "        y_train_fold = y_train.values[train_index]\n",
        "        X_val_fold = X_train.values[val_index]\n",
        "        y_val_fold = y_train.values[val_index]\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            out = model(torch.tensor(X_train_fold))\n",
        "            y_train_fold_labels = np.argmax(y_train_fold, axis=1)\n",
        "            loss = criterion(out, torch.tensor(y_train_fold_labels).long())\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            with torch.no_grad():\n",
        "              val_outputs = model(X_val_fold)\n",
        "              y_val_fold_labels = np.argmax(y_val_fold, axis=1)\n",
        "              val_loss =  criterion(val_outputs, torch.tensor(y_val_fold_labels).long())\n",
        "              _, val_preds = torch.max(val_outputs, 1)\n",
        "              val_accuracy = accuracy_score(y_val_fold_labels, val_preds)\n",
        "              train_accuracy = accuracy_score(y_train_fold_labels, torch.argmax(out, 1))\n",
        "\n",
        "\n",
        "            print(f'Epoch {epoch+1}/{num_epochs} :')\n",
        "            print(f'Train Loss: {loss.item()} - Validation Loss: {val_loss.item()} - Train Accuracy: {train_accuracy} - Validation Accuracy: {val_accuracy}')\n",
        "\n",
        "            train_losses.append(loss.item())\n",
        "            val_losses.append(val_loss.item())\n",
        "            train_accuracies.append(train_accuracy)\n",
        "            val_accuracies.append(val_accuracy)\n",
        "\n",
        "\n",
        "            # Check for early stopping\n",
        "            #early_stopping(loss.item(), val_loss.item())\n",
        "            #if early_stopping.early_stop:\n",
        "            #    print('Early stopping triggered...')\n",
        "            #    break\n",
        "\n",
        "        #if early_stopping.early_stop:\n",
        "        #    break\n",
        "\n",
        "    return train_losses, val_losses, train_accuracies, val_accuracies"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 50\n",
        "\n",
        "train_loss, val_loss, train_accuracy, val_accuracy = train(model, optimizer, num_epochs=EPOCHS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ywIQxX5ZhY8e",
        "outputId": "7846cfaf-592d-4791-ed13-a52b3e77178f"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50 :\n",
            "Train Loss: 5.563241958618164 - Validation Loss: 5.3825459480285645 - Train Accuracy: 0.0 - Validation Accuracy: 0.29619844415088803\n",
            "Epoch 2/50 :\n",
            "Train Loss: 5.381259918212891 - Validation Loss: 5.11652946472168 - Train Accuracy: 0.3004199567811468 - Validation Accuracy: 0.3117813983071579\n",
            "Epoch 3/50 :\n",
            "Train Loss: 5.115726470947266 - Validation Loss: 4.7068328857421875 - Train Accuracy: 0.3167262398238628 - Validation Accuracy: 0.462987425999315\n",
            "Epoch 4/50 :\n",
            "Train Loss: 4.706809997558594 - Validation Loss: 4.086988925933838 - Train Accuracy: 0.4684842142459126 - Validation Accuracy: 0.6542394441998141\n",
            "Epoch 5/50 :\n",
            "Train Loss: 4.088394641876221 - Validation Loss: 3.2007153034210205 - Train Accuracy: 0.6494815096698786 - Validation Accuracy: 0.6591565145065805\n",
            "Epoch 6/50 :\n",
            "Train Loss: 3.2044601440429688 - Validation Loss: 2.1169655323028564 - Train Accuracy: 0.6547819350629935 - Validation Accuracy: 0.6591565145065805\n",
            "Epoch 7/50 :\n",
            "Train Loss: 2.1229822635650635 - Validation Loss: 1.318536400794983 - Train Accuracy: 0.6547819350629935 - Validation Accuracy: 0.6591565145065805\n",
            "Epoch 8/50 :\n",
            "Train Loss: 1.3257429599761963 - Validation Loss: 1.2228304147720337 - Train Accuracy: 0.6547819350629935 - Validation Accuracy: 0.6591565145065805\n",
            "Epoch 9/50 :\n",
            "Train Loss: 1.2297520637512207 - Validation Loss: 1.2103657722473145 - Train Accuracy: 0.6547819350629935 - Validation Accuracy: 0.6591565145065805\n",
            "Epoch 10/50 :\n",
            "Train Loss: 1.2134168148040771 - Validation Loss: 1.164383053779602 - Train Accuracy: 0.6547819350629935 - Validation Accuracy: 0.6591565145065805\n",
            "Epoch 11/50 :\n",
            "Train Loss: 1.1586627960205078 - Validation Loss: 1.512640118598938 - Train Accuracy: 0.6547819350629935 - Validation Accuracy: 0.29940310191300945\n",
            "Epoch 12/50 :\n",
            "Train Loss: 1.498202919960022 - Validation Loss: 1.3173352479934692 - Train Accuracy: 0.30443468924557276 - Validation Accuracy: 0.5638240618425558\n",
            "Epoch 13/50 :\n",
            "Train Loss: 1.3069063425064087 - Validation Loss: 1.3298002481460571 - Train Accuracy: 0.5643485233558488 - Validation Accuracy: 0.6591565145065805\n",
            "Epoch 14/50 :\n",
            "Train Loss: 1.3268505334854126 - Validation Loss: 1.4289363622665405 - Train Accuracy: 0.6547819350629935 - Validation Accuracy: 0.6591565145065805\n",
            "Epoch 15/50 :\n",
            "Train Loss: 1.4292815923690796 - Validation Loss: 1.3152360916137695 - Train Accuracy: 0.6547819350629935 - Validation Accuracy: 0.6591565145065805\n",
            "Epoch 16/50 :\n",
            "Train Loss: 1.3140804767608643 - Validation Loss: 1.1694915294647217 - Train Accuracy: 0.6547819350629935 - Validation Accuracy: 0.6591565145065805\n",
            "Epoch 17/50 :\n",
            "Train Loss: 1.1639642715454102 - Validation Loss: 1.2031562328338623 - Train Accuracy: 0.6547819350629935 - Validation Accuracy: 0.44872547580605704\n",
            "Epoch 18/50 :\n",
            "Train Loss: 1.1938129663467407 - Validation Loss: 1.1617783308029175 - Train Accuracy: 0.4539447396675682 - Validation Accuracy: 0.3840452076911786\n",
            "Epoch 19/50 :\n",
            "Train Loss: 1.1529163122177124 - Validation Loss: 1.0310306549072266 - Train Accuracy: 0.3910354856684652 - Validation Accuracy: 0.6591565145065805\n",
            "Epoch 20/50 :\n",
            "Train Loss: 1.0254805088043213 - Validation Loss: 0.9710842370986938 - Train Accuracy: 0.6547819350629935 - Validation Accuracy: 0.6591565145065805\n",
            "Epoch 21/50 :\n",
            "Train Loss: 0.9693164229393005 - Validation Loss: 0.9563636779785156 - Train Accuracy: 0.6547819350629935 - Validation Accuracy: 0.6591565145065805\n",
            "Epoch 22/50 :\n",
            "Train Loss: 0.957191526889801 - Validation Loss: 0.9254736304283142 - Train Accuracy: 0.6547819350629935 - Validation Accuracy: 0.6591565145065805\n",
            "Epoch 23/50 :\n",
            "Train Loss: 0.9272733330726624 - Validation Loss: 0.8769786357879639 - Train Accuracy: 0.6547819350629935 - Validation Accuracy: 0.6591565145065805\n",
            "Epoch 24/50 :\n",
            "Train Loss: 0.8784536123275757 - Validation Loss: 0.8366917371749878 - Train Accuracy: 0.6547819350629935 - Validation Accuracy: 0.6591565145065805\n",
            "Epoch 25/50 :\n",
            "Train Loss: 0.837123453617096 - Validation Loss: 0.8239760994911194 - Train Accuracy: 0.6547819350629935 - Validation Accuracy: 0.6591565145065805\n",
            "Epoch 26/50 :\n",
            "Train Loss: 0.8232125639915466 - Validation Loss: 0.8357019424438477 - Train Accuracy: 0.6547819350629935 - Validation Accuracy: 0.6591565145065805\n",
            "Epoch 27/50 :\n",
            "Train Loss: 0.8340460658073425 - Validation Loss: 0.8533103466033936 - Train Accuracy: 0.6547819350629935 - Validation Accuracy: 0.6591565145065805\n",
            "Epoch 28/50 :\n",
            "Train Loss: 0.8512903451919556 - Validation Loss: 0.8620591759681702 - Train Accuracy: 0.6547819350629935 - Validation Accuracy: 0.6591565145065805\n",
            "Epoch 29/50 :\n",
            "Train Loss: 0.860238254070282 - Validation Loss: 0.8597235083580017 - Train Accuracy: 0.6547819350629935 - Validation Accuracy: 0.6591565145065805\n",
            "Epoch 30/50 :\n",
            "Train Loss: 0.8585278987884521 - Validation Loss: 0.8512341380119324 - Train Accuracy: 0.6547819350629935 - Validation Accuracy: 0.6591565145065805\n",
            "Epoch 31/50 :\n",
            "Train Loss: 0.850925087928772 - Validation Loss: 0.8421103954315186 - Train Accuracy: 0.6547819350629935 - Validation Accuracy: 0.6591565145065805\n",
            "Epoch 32/50 :\n",
            "Train Loss: 0.8427929282188416 - Validation Loss: 0.8347919583320618 - Train Accuracy: 0.6547819350629935 - Validation Accuracy: 0.6591565145065805\n",
            "Epoch 33/50 :\n",
            "Train Loss: 0.8363845348358154 - Validation Loss: 0.8282675743103027 - Train Accuracy: 0.6547819350629935 - Validation Accuracy: 0.6591565145065805\n",
            "Epoch 34/50 :\n",
            "Train Loss: 0.830501914024353 - Validation Loss: 0.8201153874397278 - Train Accuracy: 0.6547819350629935 - Validation Accuracy: 0.6591565145065805\n",
            "Epoch 35/50 :\n",
            "Train Loss: 0.8226107358932495 - Validation Loss: 0.8090211749076843 - Train Accuracy: 0.6547819350629935 - Validation Accuracy: 0.6591565145065805\n",
            "Epoch 36/50 :\n",
            "Train Loss: 0.8113306164741516 - Validation Loss: 0.7965570092201233 - Train Accuracy: 0.6547819350629935 - Validation Accuracy: 0.6591565145065805\n",
            "Epoch 37/50 :\n",
            "Train Loss: 0.7982543706893921 - Validation Loss: 0.7871112823486328 - Train Accuracy: 0.6547819350629935 - Validation Accuracy: 0.6591565145065805\n",
            "Epoch 38/50 :\n",
            "Train Loss: 0.7878978848457336 - Validation Loss: 0.7848154902458191 - Train Accuracy: 0.6547819350629935 - Validation Accuracy: 0.6591565145065805\n",
            "Epoch 39/50 :\n",
            "Train Loss: 0.7846162915229797 - Validation Loss: 0.7882776260375977 - Train Accuracy: 0.6547819350629935 - Validation Accuracy: 0.6591565145065805\n",
            "Epoch 40/50 :\n",
            "Train Loss: 0.7873054146766663 - Validation Loss: 0.7898731827735901 - Train Accuracy: 0.6547819350629935 - Validation Accuracy: 0.6591565145065805\n",
            "Epoch 41/50 :\n",
            "Train Loss: 0.7886044383049011 - Validation Loss: 0.7854183912277222 - Train Accuracy: 0.6547819350629935 - Validation Accuracy: 0.6591565145065805\n",
            "Epoch 42/50 :\n",
            "Train Loss: 0.7844182848930359 - Validation Loss: 0.780290424823761 - Train Accuracy: 0.6547819350629935 - Validation Accuracy: 0.6591565145065805\n",
            "Epoch 43/50 :\n",
            "Train Loss: 0.7799895405769348 - Validation Loss: 0.7804754972457886 - Train Accuracy: 0.6547819350629935 - Validation Accuracy: 0.6591565145065805\n",
            "Epoch 44/50 :\n",
            "Train Loss: 0.7809868454933167 - Validation Loss: 0.7830232977867126 - Train Accuracy: 0.6547819350629935 - Validation Accuracy: 0.6591565145065805\n",
            "Epoch 45/50 :\n",
            "Train Loss: 0.7840240001678467 - Validation Loss: 0.7814906239509583 - Train Accuracy: 0.6547819350629935 - Validation Accuracy: 0.6591565145065805\n",
            "Epoch 46/50 :\n",
            "Train Loss: 0.7823797464370728 - Validation Loss: 0.7764148712158203 - Train Accuracy: 0.6547819350629935 - Validation Accuracy: 0.6591565145065805\n",
            "Epoch 47/50 :\n",
            "Train Loss: 0.776635468006134 - Validation Loss: 0.7736943960189819 - Train Accuracy: 0.6547819350629935 - Validation Accuracy: 0.6591809775429326\n",
            "Epoch 48/50 :\n",
            "Train Loss: 0.7730066776275635 - Validation Loss: 0.7740129828453064 - Train Accuracy: 0.6547928077304666 - Validation Accuracy: 0.6610890943783942\n",
            "Epoch 49/50 :\n",
            "Train Loss: 0.7726359367370605 - Validation Loss: 0.7711091637611389 - Train Accuracy: 0.6568531782166107 - Validation Accuracy: 0.6650521062674299\n",
            "Epoch 50/50 :\n",
            "Train Loss: 0.7695960402488708 - Validation Loss: 0.7641035318374634 - Train Accuracy: 0.6597534622650485 - Validation Accuracy: 0.6618229854689565\n",
            "Epoch 1/50 :\n",
            "Train Loss: 0.7628733515739441 - Validation Loss: 0.7603940367698669 - Train Accuracy: 0.6580681988067247 - Validation Accuracy: 0.6562943392533881\n",
            "Epoch 2/50 :\n",
            "Train Loss: 0.7582047581672668 - Validation Loss: 0.7583624720573425 - Train Accuracy: 0.6556734937957841 - Validation Accuracy: 0.6561475610352757\n",
            "Epoch 3/50 :\n",
            "Train Loss: 0.7564089894294739 - Validation Loss: 0.7552873492240906 - Train Accuracy: 0.6552929504342272 - Validation Accuracy: 0.6563188022897402\n",
            "Epoch 4/50 :\n",
            "Train Loss: 0.7534340620040894 - Validation Loss: 0.7504773139953613 - Train Accuracy: 0.655610975957814 - Validation Accuracy: 0.6612847986692109\n",
            "Epoch 5/50 :\n",
            "Train Loss: 0.7485848665237427 - Validation Loss: 0.7473527789115906 - Train Accuracy: 0.6594898000788268 - Validation Accuracy: 0.6692597485199863\n",
            "Epoch 6/50 :\n",
            "Train Loss: 0.7453432679176331 - Validation Loss: 0.7466510534286499 - Train Accuracy: 0.6680003805433615 - Validation Accuracy: 0.672562258427516\n",
            "Epoch 7/50 :\n",
            "Train Loss: 0.744549572467804 - Validation Loss: 0.744899570941925 - Train Accuracy: 0.6715992334769432 - Validation Accuracy: 0.6721708498458828\n",
            "Epoch 8/50 :\n",
            "Train Loss: 0.7428345084190369 - Validation Loss: 0.7419017553329468 - Train Accuracy: 0.6722488753584582 - Validation Accuracy: 0.6729536670091492\n",
            "Epoch 9/50 :\n",
            "Train Loss: 0.7400019764900208 - Validation Loss: 0.7406131029129028 - Train Accuracy: 0.672626700553147 - Validation Accuracy: 0.6733450755907824\n",
            "Epoch 10/50 :\n",
            "Train Loss: 0.7389295101165771 - Validation Loss: 0.7403724789619446 - Train Accuracy: 0.6726076733850691 - Validation Accuracy: 0.6735163168452468\n",
            "Epoch 11/50 :\n",
            "Train Loss: 0.7388208508491516 - Validation Loss: 0.7386747598648071 - Train Accuracy: 0.6727272727272727 - Validation Accuracy: 0.6749596359900191\n",
            "Epoch 12/50 :\n",
            "Train Loss: 0.7370878458023071 - Validation Loss: 0.7368240356445312 - Train Accuracy: 0.6740020929884886 - Validation Accuracy: 0.6754244336807085\n",
            "Epoch 13/50 :\n",
            "Train Loss: 0.7350690364837646 - Validation Loss: 0.7364591956138611 - Train Accuracy: 0.6741189741638239 - Validation Accuracy: 0.6742012818631048\n",
            "Epoch 14/50 :\n",
            "Train Loss: 0.7345511317253113 - Validation Loss: 0.7352318167686462 - Train Accuracy: 0.6724989467103385 - Validation Accuracy: 0.6733695386271344\n",
            "Epoch 15/50 :\n",
            "Train Loss: 0.7333266139030457 - Validation Loss: 0.7328695058822632 - Train Accuracy: 0.6722624661927996 - Validation Accuracy: 0.6753755076080044\n",
            "Epoch 16/50 :\n",
            "Train Loss: 0.7311340570449829 - Validation Loss: 0.7317870259284973 - Train Accuracy: 0.6745783443645605 - Validation Accuracy: 0.6776261069523949\n",
            "Epoch 17/50 :\n",
            "Train Loss: 0.7302420735359192 - Validation Loss: 0.7305845022201538 - Train Accuracy: 0.6761385721469441 - Validation Accuracy: 0.6781642937521405\n",
            "Epoch 18/50 :\n",
            "Train Loss: 0.729088544845581 - Validation Loss: 0.7286485433578491 - Train Accuracy: 0.6768344228652197 - Validation Accuracy: 0.6781642937521405\n",
            "Epoch 19/50 :\n",
            "Train Loss: 0.72703617811203 - Validation Loss: 0.7277693748474121 - Train Accuracy: 0.6768126775302736 - Validation Accuracy: 0.6764763442438475\n",
            "Epoch 20/50 :\n",
            "Train Loss: 0.7260234951972961 - Validation Loss: 0.7265611886978149 - Train Accuracy: 0.6760597453077645 - Validation Accuracy: 0.6774304026615784\n",
            "Epoch 21/50 :\n",
            "Train Loss: 0.7248124480247498 - Validation Loss: 0.724574625492096 - Train Accuracy: 0.6770736215496269 - Validation Accuracy: 0.6789715739517589\n",
            "Epoch 22/50 :\n",
            "Train Loss: 0.7229666709899902 - Validation Loss: 0.7234864830970764 - Train Accuracy: 0.6788322755133938 - Validation Accuracy: 0.680708449532756\n",
            "Epoch 23/50 :\n",
            "Train Loss: 0.7220218181610107 - Validation Loss: 0.7221564054489136 - Train Accuracy: 0.6799168240938311 - Validation Accuracy: 0.6811243211507413\n",
            "Epoch 24/50 :\n",
            "Train Loss: 0.7207006812095642 - Validation Loss: 0.7208173274993896 - Train Accuracy: 0.6806425746476576 - Validation Accuracy: 0.6814912666960223\n",
            "Epoch 25/50 :\n",
            "Train Loss: 0.7192694544792175 - Validation Loss: 0.7200993895530701 - Train Accuracy: 0.681335707199065 - Validation Accuracy: 0.6814668036596703\n",
            "Epoch 26/50 :\n",
            "Train Loss: 0.7184968590736389 - Validation Loss: 0.718795895576477 - Train Accuracy: 0.6817080960600171 - Validation Accuracy: 0.682396399041049\n",
            "Epoch 27/50 :\n",
            "Train Loss: 0.7172478437423706 - Validation Loss: 0.7176788449287415 - Train Accuracy: 0.682417537612634 - Validation Accuracy: 0.6838397181858212\n",
            "Epoch 28/50 :\n",
            "Train Loss: 0.7162311673164368 - Validation Loss: 0.7167984247207642 - Train Accuracy: 0.6827192541350113 - Validation Accuracy: 0.6842800528401585\n",
            "Epoch 29/50 :\n",
            "Train Loss: 0.7153943181037903 - Validation Loss: 0.715556800365448 - Train Accuracy: 0.6830834884953587 - Validation Accuracy: 0.6844023680219189\n",
            "Epoch 30/50 :\n",
            "Train Loss: 0.7141008973121643 - Validation Loss: 0.7146278619766235 - Train Accuracy: 0.6837358485437421 - Validation Accuracy: 0.6844757571309751\n",
            "Epoch 31/50 :\n",
            "Train Loss: 0.7131139039993286 - Validation Loss: 0.7133538722991943 - Train Accuracy: 0.6842767637505266 - Validation Accuracy: 0.6849160917853124\n",
            "Epoch 32/50 :\n",
            "Train Loss: 0.7118531465530396 - Validation Loss: 0.711946427822113 - Train Accuracy: 0.6846029437747183 - Validation Accuracy: 0.6863349478937326\n",
            "Epoch 33/50 :\n",
            "Train Loss: 0.7105163931846619 - Validation Loss: 0.7107834815979004 - Train Accuracy: 0.6846328436102692 - Validation Accuracy: 0.6859680023484515\n",
            "Epoch 34/50 :\n",
            "Train Loss: 0.7093849182128906 - Validation Loss: 0.7093960046768188 - Train Accuracy: 0.6849318419657783 - Validation Accuracy: 0.6858456871666911\n",
            "Epoch 35/50 :\n",
            "Train Loss: 0.7079328894615173 - Validation Loss: 0.708331823348999 - Train Accuracy: 0.6856793378545509 - Validation Accuracy: 0.6857478350212829\n",
            "Epoch 36/50 :\n",
            "Train Loss: 0.7067996859550476 - Validation Loss: 0.7069827318191528 - Train Accuracy: 0.6858288370323055 - Validation Accuracy: 0.6862615587846763\n",
            "Epoch 37/50 :\n",
            "Train Loss: 0.7054638266563416 - Validation Loss: 0.7057471871376038 - Train Accuracy: 0.6861522988896288 - Validation Accuracy: 0.6859924653848035\n",
            "Epoch 38/50 :\n",
            "Train Loss: 0.7042868733406067 - Validation Loss: 0.7045006155967712 - Train Accuracy: 0.6865790510879463 - Validation Accuracy: 0.6867508195117178\n",
            "Epoch 39/50 :\n",
            "Train Loss: 0.7030184268951416 - Validation Loss: 0.703311026096344 - Train Accuracy: 0.6867829136030661 - Validation Accuracy: 0.6868731346934781\n",
            "Epoch 40/50 :\n",
            "Train Loss: 0.7017599940299988 - Validation Loss: 0.7018924355506897 - Train Accuracy: 0.6871688932983596 - Validation Accuracy: 0.6869954498752385\n",
            "Epoch 41/50 :\n",
            "Train Loss: 0.7003511190414429 - Validation Loss: 0.7004948258399963 - Train Accuracy: 0.6877750445099825 - Validation Accuracy: 0.6883164538382504\n",
            "Epoch 42/50 :\n",
            "Train Loss: 0.6989914178848267 - Validation Loss: 0.6991011500358582 - Train Accuracy: 0.6882860598812162 - Validation Accuracy: 0.6887567884925877\n",
            "Epoch 43/50 :\n",
            "Train Loss: 0.697549045085907 - Validation Loss: 0.697871208190918 - Train Accuracy: 0.6887155302464019 - Validation Accuracy: 0.6887567884925877\n",
            "Epoch 44/50 :\n",
            "Train Loss: 0.6962334513664246 - Validation Loss: 0.6964830756187439 - Train Accuracy: 0.6891585914459288 - Validation Accuracy: 0.6892460492196292\n",
            "Epoch 45/50 :\n",
            "Train Loss: 0.6948176622390747 - Validation Loss: 0.6951773166656494 - Train Accuracy: 0.6897239701545278 - Validation Accuracy: 0.6897597729830226\n",
            "Epoch 46/50 :\n",
            "Train Loss: 0.6934871673583984 - Validation Loss: 0.6938031315803528 - Train Accuracy: 0.6899169600021745 - Validation Accuracy: 0.6901267185283038\n",
            "Epoch 47/50 :\n",
            "Train Loss: 0.6920016407966614 - Validation Loss: 0.6924444437026978 - Train Accuracy: 0.6903491485342285 - Validation Accuracy: 0.6908850726552179\n",
            "Epoch 48/50 :\n",
            "Train Loss: 0.6905304789543152 - Validation Loss: 0.6908718943595886 - Train Accuracy: 0.6907269737289172 - Validation Accuracy: 0.6913987964186115\n",
            "Epoch 49/50 :\n",
            "Train Loss: 0.6889132261276245 - Validation Loss: 0.689412534236908 - Train Accuracy: 0.6909036545753544 - Validation Accuracy: 0.6914721855276676\n",
            "Epoch 50/50 :\n",
            "Train Loss: 0.6873286962509155 - Validation Loss: 0.6880730390548706 - Train Accuracy: 0.6913331249405401 - Validation Accuracy: 0.6920103723274132\n",
            "Epoch 1/50 :\n",
            "Train Loss: 0.6864721775054932 - Validation Loss: 0.6811941862106323 - Train Accuracy: 0.6915152421207138 - Validation Accuracy: 0.6912520182004991\n",
            "Epoch 2/50 :\n",
            "Train Loss: 0.6851422786712646 - Validation Loss: 0.6796461939811707 - Train Accuracy: 0.6916049416273665 - Validation Accuracy: 0.691912520182005\n",
            "Epoch 3/50 :\n",
            "Train Loss: 0.683721661567688 - Validation Loss: 0.6782812476158142 - Train Accuracy: 0.6917707498063306 - Validation Accuracy: 0.6916189637457801\n",
            "Epoch 4/50 :\n",
            "Train Loss: 0.6821622252464294 - Validation Loss: 0.6766350865364075 - Train Accuracy: 0.6918985036491391 - Validation Accuracy: 0.6918391310729488\n",
            "Epoch 5/50 :\n",
            "Train Loss: 0.6805552244186401 - Validation Loss: 0.6752913594245911 - Train Accuracy: 0.6922165291727259 - Validation Accuracy: 0.6917657419638925\n",
            "Epoch 6/50 :\n",
            "Train Loss: 0.6790964603424072 - Validation Loss: 0.6741511225700378 - Train Accuracy: 0.6924448551896601 - Validation Accuracy: 0.6924996330544547\n",
            "Epoch 7/50 :\n",
            "Train Loss: 0.6777840256690979 - Validation Loss: 0.6728594899177551 - Train Accuracy: 0.6926514358716481 - Validation Accuracy: 0.6928665785997358\n",
            "Epoch 8/50 :\n",
            "Train Loss: 0.6765064001083374 - Validation Loss: 0.6719621419906616 - Train Accuracy: 0.692814525883744 - Validation Accuracy: 0.6933803023631293\n",
            "Epoch 9/50 :\n",
            "Train Loss: 0.6752850413322449 - Validation Loss: 0.670616626739502 - Train Accuracy: 0.6930809062368338 - Validation Accuracy: 0.6932824502177211\n",
            "Epoch 10/50 :\n",
            "Train Loss: 0.6740767955780029 - Validation Loss: 0.6697859168052673 - Train Accuracy: 0.6931977874121692 - Validation Accuracy: 0.6938940261265228\n",
            "Epoch 11/50 :\n",
            "Train Loss: 0.6728748679161072 - Validation Loss: 0.6682195663452148 - Train Accuracy: 0.6934777585996005 - Validation Accuracy: 0.6938451000538187\n",
            "Epoch 12/50 :\n",
            "Train Loss: 0.6715004444122314 - Validation Loss: 0.6670368909835815 - Train Accuracy: 0.6936870574484567 - Validation Accuracy: 0.6938695630901708\n",
            "Epoch 13/50 :\n",
            "Train Loss: 0.6700776219367981 - Validation Loss: 0.6654977202415466 - Train Accuracy: 0.6940023648051754 - Validation Accuracy: 0.6941141934536915\n",
            "Epoch 14/50 :\n",
            "Train Loss: 0.6686689853668213 - Validation Loss: 0.6641534566879272 - Train Accuracy: 0.6941274004811155 - Validation Accuracy: 0.6950437888350702\n",
            "Epoch 15/50 :\n",
            "Train Loss: 0.6673168540000916 - Validation Loss: 0.6628949046134949 - Train Accuracy: 0.694306799494421 - Validation Accuracy: 0.6947013063261412\n",
            "Epoch 16/50 :\n",
            "Train Loss: 0.6660484671592712 - Validation Loss: 0.6616272330284119 - Train Accuracy: 0.6946248250180078 - Validation Accuracy: 0.6959733842164489\n",
            "Epoch 17/50 :\n",
            "Train Loss: 0.6649612784385681 - Validation Loss: 0.6615365743637085 - Train Accuracy: 0.6946873428559779 - Validation Accuracy: 0.6938451000538187\n",
            "Epoch 18/50 :\n",
            "Train Loss: 0.6645129919052124 - Validation Loss: 0.661666750907898 - Train Accuracy: 0.6950461408825888 - Validation Accuracy: 0.69362493272665\n",
            "Epoch 19/50 :\n",
            "Train Loss: 0.665270984172821 - Validation Loss: 0.6632338762283325 - Train Accuracy: 0.693091778904307 - Validation Accuracy: 0.6923039287636381\n",
            "Epoch 20/50 :\n",
            "Train Loss: 0.6658651232719421 - Validation Loss: 0.6575982570648193 - Train Accuracy: 0.6937903477894508 - Validation Accuracy: 0.6955575125984638\n",
            "Epoch 21/50 :\n",
            "Train Loss: 0.6609967947006226 - Validation Loss: 0.6555134057998657 - Train Accuracy: 0.6945949251824569 - Validation Accuracy: 0.6965604970888987\n",
            "Epoch 22/50 :\n",
            "Train Loss: 0.6587253212928772 - Validation Loss: 0.6574783325195312 - Train Accuracy: 0.6956577284279482 - Validation Accuracy: 0.6945056020353246\n",
            "Epoch 23/50 :\n",
            "Train Loss: 0.6601023077964783 - Validation Loss: 0.654321551322937 - Train Accuracy: 0.6955843379225051 - Validation Accuracy: 0.6964626449434904\n",
            "Epoch 24/50 :\n",
            "Train Loss: 0.6575780510902405 - Validation Loss: 0.6518337726593018 - Train Accuracy: 0.6953043667350739 - Validation Accuracy: 0.6967806644160673\n",
            "Epoch 25/50 :\n",
            "Train Loss: 0.654725193977356 - Validation Loss: 0.6524286270141602 - Train Accuracy: 0.6968781853517988 - Validation Accuracy: 0.695997847252801\n",
            "Epoch 26/50 :\n",
            "Train Loss: 0.654914140701294 - Validation Loss: 0.6507675647735596 - Train Accuracy: 0.6968537218499844 - Validation Accuracy: 0.6967562013797153\n",
            "Epoch 27/50 :\n",
            "Train Loss: 0.6537318825721741 - Validation Loss: 0.648712158203125 - Train Accuracy: 0.696263879639571 - Validation Accuracy: 0.6978570380155585\n",
            "Epoch 28/50 :\n",
            "Train Loss: 0.6511658430099487 - Validation Loss: 0.6479737162590027 - Train Accuracy: 0.6974354095597929 - Validation Accuracy: 0.6977836489065022\n",
            "Epoch 29/50 :\n",
            "Train Loss: 0.650230348110199 - Validation Loss: 0.6474179029464722 - Train Accuracy: 0.6976202449068348 - Validation Accuracy: 0.6969519056705318\n",
            "Epoch 30/50 :\n",
            "Train Loss: 0.649991512298584 - Validation Loss: 0.6466500759124756 - Train Accuracy: 0.6965329781595292 - Validation Accuracy: 0.697710259797446\n",
            "Epoch 31/50 :\n",
            "Train Loss: 0.6485520005226135 - Validation Loss: 0.6443760395050049 - Train Accuracy: 0.6980986422756493 - Validation Accuracy: 0.6983462987425999\n",
            "Epoch 32/50 :\n",
            "Train Loss: 0.646476686000824 - Validation Loss: 0.6436631083488464 - Train Accuracy: 0.6983677407956075 - Validation Accuracy: 0.6977347228337981\n",
            "Epoch 33/50 :\n",
            "Train Loss: 0.6457721590995789 - Validation Loss: 0.644127368927002 - Train Accuracy: 0.6981747509479607 - Validation Accuracy: 0.6979548901609668\n",
            "Epoch 34/50 :\n",
            "Train Loss: 0.6457040905952454 - Validation Loss: 0.6424551606178284 - Train Accuracy: 0.6985525761426494 - Validation Accuracy: 0.6986887812515289\n",
            "Epoch 35/50 :\n",
            "Train Loss: 0.644551157951355 - Validation Loss: 0.6412833333015442 - Train Accuracy: 0.6982318324521942 - Validation Accuracy: 0.6981016683790792\n",
            "Epoch 36/50 :\n",
            "Train Loss: 0.6429094076156616 - Validation Loss: 0.6399402618408203 - Train Accuracy: 0.6993299718669729 - Validation Accuracy: 0.6988600225059934\n",
            "Epoch 37/50 :\n",
            "Train Loss: 0.641669511795044 - Validation Loss: 0.6393538117408752 - Train Accuracy: 0.6996153793881407 - Validation Accuracy: 0.6996428396692598\n",
            "Epoch 38/50 :\n",
            "Train Loss: 0.6412444710731506 - Validation Loss: 0.6395992040634155 - Train Accuracy: 0.6991641636880088 - Validation Accuracy: 0.6987621703605852\n",
            "Epoch 39/50 :\n",
            "Train Loss: 0.6410222053527832 - Validation Loss: 0.6382089853286743 - Train Accuracy: 0.6997105152285299 - Validation Accuracy: 0.6994715984147952\n",
            "Epoch 40/50 :\n",
            "Train Loss: 0.6401259303092957 - Validation Loss: 0.6374363303184509 - Train Accuracy: 0.6991261093518532 - Validation Accuracy: 0.6986887812515289\n",
            "Epoch 41/50 :\n",
            "Train Loss: 0.6388789415359497 - Validation Loss: 0.6358706951141357 - Train Accuracy: 0.7000557224207994 - Validation Accuracy: 0.7003033416507657\n",
            "Epoch 42/50 :\n",
            "Train Loss: 0.6375530958175659 - Validation Loss: 0.6350785493850708 - Train Accuracy: 0.7002758939371287 - Validation Accuracy: 0.7007681393414551\n",
            "Epoch 43/50 :\n",
            "Train Loss: 0.6367349028587341 - Validation Loss: 0.6348752379417419 - Train Accuracy: 0.7004580111173024 - Validation Accuracy: 0.6991535789422183\n",
            "Epoch 44/50 :\n",
            "Train Loss: 0.6363226771354675 - Validation Loss: 0.6340972185134888 - Train Accuracy: 0.7007950638089673 - Validation Accuracy: 0.7001076373599491\n",
            "Epoch 45/50 :\n",
            "Train Loss: 0.6358993053436279 - Validation Loss: 0.6339782476425171 - Train Accuracy: 0.700020386251512 - Validation Accuracy: 0.6991535789422183\n",
            "Epoch 46/50 :\n",
            "Train Loss: 0.6353215575218201 - Validation Loss: 0.6325703263282776 - Train Accuracy: 0.700833118145123 - Validation Accuracy: 0.7000097852145408\n",
            "Epoch 47/50 :\n",
            "Train Loss: 0.6342955827713013 - Validation Loss: 0.6318340301513672 - Train Accuracy: 0.700411802280542 - Validation Accuracy: 0.6994226723420911\n",
            "Epoch 48/50 :\n",
            "Train Loss: 0.6332328915596008 - Validation Loss: 0.6308363676071167 - Train Accuracy: 0.701553432365213 - Validation Accuracy: 0.7009393805959195\n",
            "Epoch 49/50 :\n",
            "Train Loss: 0.6323404908180237 - Validation Loss: 0.6301987171173096 - Train Accuracy: 0.7012897701789913 - Validation Accuracy: 0.7004501198688782\n",
            "Epoch 50/50 :\n",
            "Train Loss: 0.6317204236984253 - Validation Loss: 0.6299955248832703 - Train Accuracy: 0.701471887359165 - Validation Accuracy: 0.7000342482508929\n",
            "Epoch 1/50 :\n",
            "Train Loss: 0.6309799551963806 - Validation Loss: 0.632981538772583 - Train Accuracy: 0.7019021680040012 - Validation Accuracy: 0.6972380556303055\n",
            "Epoch 2/50 :\n",
            "Train Loss: 0.6306887865066528 - Validation Loss: 0.6323233246803284 - Train Accuracy: 0.7013068910779133 - Validation Accuracy: 0.7000758372679012\n",
            "Epoch 3/50 :\n",
            "Train Loss: 0.6304992437362671 - Validation Loss: 0.6325045824050903 - Train Accuracy: 0.7019320677582795 - Validation Accuracy: 0.6972625192651124\n",
            "Epoch 4/50 :\n",
            "Train Loss: 0.6300682425498962 - Validation Loss: 0.6314172744750977 - Train Accuracy: 0.7010323569704482 - Validation Accuracy: 0.700296009981163\n",
            "Epoch 5/50 :\n",
            "Train Loss: 0.6296013593673706 - Validation Loss: 0.6309825778007507 - Train Accuracy: 0.7021332115597886 - Validation Accuracy: 0.6980208919441251\n",
            "Epoch 6/50 :\n",
            "Train Loss: 0.6285538077354431 - Validation Loss: 0.6294604539871216 - Train Accuracy: 0.7015977341422576 - Validation Accuracy: 0.7006629645032659\n",
            "Epoch 7/50 :\n",
            "Train Loss: 0.6274600028991699 - Validation Loss: 0.6287525296211243 - Train Accuracy: 0.7026931524126383 - Validation Accuracy: 0.6998312009198326\n",
            "Epoch 8/50 :\n",
            "Train Loss: 0.626427173614502 - Validation Loss: 0.6279811859130859 - Train Accuracy: 0.7029078870115467 - Validation Accuracy: 0.7006629645032659\n",
            "Epoch 9/50 :\n",
            "Train Loss: 0.6257151961326599 - Validation Loss: 0.6274517774581909 - Train Accuracy: 0.7031389305673342 - Validation Accuracy: 0.7007118917728796\n",
            "Epoch 10/50 :\n",
            "Train Loss: 0.6253029704093933 - Validation Loss: 0.6275134682655334 - Train Accuracy: 0.7033319198904038 - Validation Accuracy: 0.7000024463634806\n",
            "Epoch 11/50 :\n",
            "Train Loss: 0.6250523328781128 - Validation Loss: 0.6269968152046204 - Train Accuracy: 0.7027692608780742 - Validation Accuracy: 0.7009565281209482\n",
            "Epoch 12/50 :\n",
            "Train Loss: 0.6249580383300781 - Validation Loss: 0.6274261474609375 - Train Accuracy: 0.7032775567008067 - Validation Accuracy: 0.6993908554933091\n",
            "Epoch 13/50 :\n",
            "Train Loss: 0.6248151063919067 - Validation Loss: 0.6268202066421509 - Train Accuracy: 0.7022827103311805 - Validation Accuracy: 0.7013968735474717\n",
            "Epoch 14/50 :\n",
            "Train Loss: 0.6249040961265564 - Validation Loss: 0.6271567344665527 - Train Accuracy: 0.7030247678691804 - Validation Accuracy: 0.699439782762923\n",
            "Epoch 15/50 :\n",
            "Train Loss: 0.6244760751724243 - Validation Loss: 0.6259616017341614 - Train Accuracy: 0.7023588187966164 - Validation Accuracy: 0.7013968735474717\n",
            "Epoch 16/50 :\n",
            "Train Loss: 0.6240282654762268 - Validation Loss: 0.6253231167793274 - Train Accuracy: 0.7032476569465284 - Validation Accuracy: 0.7001981554419355\n",
            "Epoch 17/50 :\n",
            "Train Loss: 0.622650682926178 - Validation Loss: 0.6235038042068481 - Train Accuracy: 0.7033074564550851 - Validation Accuracy: 0.7018861462436089\n",
            "Epoch 18/50 :\n",
            "Train Loss: 0.6213224530220032 - Validation Loss: 0.6227136254310608 - Train Accuracy: 0.7043512296953487 - Validation Accuracy: 0.7023020280353255\n",
            "Epoch 19/50 :\n",
            "Train Loss: 0.6202239990234375 - Validation Loss: 0.622227132320404 - Train Accuracy: 0.7045686824537369 - Validation Accuracy: 0.7028646916358833\n",
            "Epoch 20/50 :\n",
            "Train Loss: 0.6196964979171753 - Validation Loss: 0.6219121813774109 - Train Accuracy: 0.7047426446604476 - Validation Accuracy: 0.7027179098270421\n",
            "Epoch 21/50 :\n",
            "Train Loss: 0.6196073889732361 - Validation Loss: 0.6223891973495483 - Train Accuracy: 0.7047453628199274 - Validation Accuracy: 0.7022041734960981\n",
            "Epoch 22/50 :\n",
            "Train Loss: 0.6196120977401733 - Validation Loss: 0.6218439340591431 - Train Accuracy: 0.704457237915063 - Validation Accuracy: 0.7021797098612912\n",
            "Epoch 23/50 :\n",
            "Train Loss: 0.6196478009223938 - Validation Loss: 0.6220760941505432 - Train Accuracy: 0.704623045643334 - Validation Accuracy: 0.7019840007828363\n",
            "Epoch 24/50 :\n",
            "Train Loss: 0.6191727519035339 - Validation Loss: 0.6208829283714294 - Train Accuracy: 0.7044273381607846 - Validation Accuracy: 0.7028891552706901\n",
            "Epoch 25/50 :\n",
            "Train Loss: 0.6185857653617859 - Validation Loss: 0.6204470992088318 - Train Accuracy: 0.7050389240437515 - Validation Accuracy: 0.7031093279839519\n",
            "Epoch 26/50 :\n",
            "Train Loss: 0.6175130009651184 - Validation Loss: 0.6190513968467712 - Train Accuracy: 0.7049383521429969 - Validation Accuracy: 0.7044303642635222\n",
            "Epoch 27/50 :\n",
            "Train Loss: 0.6165105104446411 - Validation Loss: 0.618492603302002 - Train Accuracy: 0.7057891360601909 - Validation Accuracy: 0.7034762825060548\n",
            "Epoch 28/50 :\n",
            "Train Loss: 0.6156256794929504 - Validation Loss: 0.6178649067878723 - Train Accuracy: 0.7059386348315828 - Validation Accuracy: 0.7046016097071703\n",
            "Epoch 29/50 :\n",
            "Train Loss: 0.6150136590003967 - Validation Loss: 0.6174526214599609 - Train Accuracy: 0.7061261878356927 - Validation Accuracy: 0.703965555202192\n",
            "Epoch 30/50 :\n",
            "Train Loss: 0.6146261692047119 - Validation Loss: 0.6175671815872192 - Train Accuracy: 0.7064088764215974 - Validation Accuracy: 0.7037209188541234\n",
            "Epoch 31/50 :\n",
            "Train Loss: 0.614417552947998 - Validation Loss: 0.6172876954078674 - Train Accuracy: 0.7060011524996195 - Validation Accuracy: 0.704650536976784\n",
            "Epoch 32/50 :\n",
            "Train Loss: 0.6144778728485107 - Validation Loss: 0.6182964444160461 - Train Accuracy: 0.706009306978059 - Validation Accuracy: 0.7035252097756685\n",
            "Epoch 33/50 :\n",
            "Train Loss: 0.6148115992546082 - Validation Loss: 0.6186826825141907 - Train Accuracy: 0.7052264770478613 - Validation Accuracy: 0.7046260733419771\n",
            "Epoch 34/50 :\n",
            "Train Loss: 0.6159841418266296 - Validation Loss: 0.6206837892532349 - Train Accuracy: 0.7051911409746232 - Validation Accuracy: 0.7008831372165276\n",
            "Epoch 35/50 :\n",
            "Train Loss: 0.6168666481971741 - Validation Loss: 0.6209761500358582 - Train Accuracy: 0.703514036575554 - Validation Accuracy: 0.7038921642977713\n",
            "Epoch 36/50 :\n",
            "Train Loss: 0.6184093356132507 - Validation Loss: 0.6197268962860107 - Train Accuracy: 0.7043131754626307 - Validation Accuracy: 0.7011277735645962\n",
            "Epoch 37/50 :\n",
            "Train Loss: 0.6158249974250793 - Validation Loss: 0.6157259941101074 - Train Accuracy: 0.7041691130101986 - Validation Accuracy: 0.706044964160775\n",
            "Epoch 38/50 :\n",
            "Train Loss: 0.6127282381057739 - Validation Loss: 0.6138830780982971 - Train Accuracy: 0.7061370604736121 - Validation Accuracy: 0.7060694277955819\n",
            "Epoch 39/50 :\n",
            "Train Loss: 0.610410749912262 - Validation Loss: 0.6148155331611633 - Train Accuracy: 0.7073846956748646 - Validation Accuracy: 0.7047239278812046\n",
            "Epoch 40/50 :\n",
            "Train Loss: 0.6110585927963257 - Validation Loss: 0.6157131195068359 - Train Accuracy: 0.7067758279513776 - Validation Accuracy: 0.7054333732906035\n",
            "Epoch 41/50 :\n",
            "Train Loss: 0.6126841902732849 - Validation Loss: 0.6155593991279602 - Train Accuracy: 0.7058652445256268 - Validation Accuracy: 0.7038677006629646\n",
            "Epoch 42/50 :\n",
            "Train Loss: 0.6115944385528564 - Validation Loss: 0.6128436923027039 - Train Accuracy: 0.7061098788788136 - Validation Accuracy: 0.7059471096215476\n",
            "Epoch 43/50 :\n",
            "Train Loss: 0.6094543933868408 - Validation Loss: 0.611961305141449 - Train Accuracy: 0.7072759692956705 - Validation Accuracy: 0.706044964160775\n",
            "Epoch 44/50 :\n",
            "Train Loss: 0.6083078384399414 - Validation Loss: 0.6129321455955505 - Train Accuracy: 0.7080044360362712 - Validation Accuracy: 0.7054089096557966\n",
            "Epoch 45/50 :\n",
            "Train Loss: 0.6089224815368652 - Validation Loss: 0.6130392551422119 - Train Accuracy: 0.7072270424250332 - Validation Accuracy: 0.7069501186486288\n",
            "Epoch 46/50 :\n",
            "Train Loss: 0.609653115272522 - Validation Loss: 0.6127789616584778 - Train Accuracy: 0.7070313349424837 - Validation Accuracy: 0.7054333732906035\n",
            "Epoch 47/50 :\n",
            "Train Loss: 0.6085920333862305 - Validation Loss: 0.6108453273773193 - Train Accuracy: 0.7070938526105204 - Validation Accuracy: 0.7067788732049808\n",
            "Epoch 48/50 :\n",
            "Train Loss: 0.6070741415023804 - Validation Loss: 0.610202431678772 - Train Accuracy: 0.7082082979972601 - Validation Accuracy: 0.7067788732049808\n",
            "Epoch 49/50 :\n",
            "Train Loss: 0.60622638463974 - Validation Loss: 0.6106550097465515 - Train Accuracy: 0.7086323308761172 - Validation Accuracy: 0.7065097732221053\n",
            "Epoch 50/50 :\n",
            "Train Loss: 0.6064011454582214 - Validation Loss: 0.6106240153312683 - Train Accuracy: 0.7083224606954139 - Validation Accuracy: 0.7071947549966974\n",
            "Epoch 1/50 :\n",
            "Train Loss: 0.6065895557403564 - Validation Loss: 0.6105231642723083 - Train Accuracy: 0.7079908452388719 - Validation Accuracy: 0.7072926095359249\n",
            "Epoch 2/50 :\n",
            "Train Loss: 0.6060097813606262 - Validation Loss: 0.6109822988510132 - Train Accuracy: 0.7080261813121099 - Validation Accuracy: 0.7069990459182426\n",
            "Epoch 3/50 :\n",
            "Train Loss: 0.6050958037376404 - Validation Loss: 0.6093712449073792 - Train Accuracy: 0.7087274664579121 - Validation Accuracy: 0.7078552731364827\n",
            "Epoch 4/50 :\n",
            "Train Loss: 0.6042002439498901 - Validation Loss: 0.6091152429580688 - Train Accuracy: 0.709281970991802 - Validation Accuracy: 0.7077818822320621\n",
            "Epoch 5/50 :\n",
            "Train Loss: 0.6037469506263733 - Validation Loss: 0.6097016930580139 - Train Accuracy: 0.7094396242416335 - Validation Accuracy: 0.7071213640922769\n",
            "Epoch 6/50 :\n",
            "Train Loss: 0.6036701202392578 - Validation Loss: 0.6087539196014404 - Train Accuracy: 0.7090590819144541 - Validation Accuracy: 0.7078063458668689\n",
            "Epoch 7/50 :\n",
            "Train Loss: 0.6036961078643799 - Validation Loss: 0.6103454828262329 - Train Accuracy: 0.7091052906256116 - Validation Accuracy: 0.7075861731536072\n",
            "Epoch 8/50 :\n",
            "Train Loss: 0.6037240028381348 - Validation Loss: 0.6085150241851807 - Train Accuracy: 0.7090645182334138 - Validation Accuracy: 0.7073415368055386\n",
            "Epoch 9/50 :\n",
            "Train Loss: 0.6034832000732422 - Validation Loss: 0.610143780708313 - Train Accuracy: 0.7087165938199926 - Validation Accuracy: 0.7076351004232209\n",
            "Epoch 10/50 :\n",
            "Train Loss: 0.6032435894012451 - Validation Loss: 0.6078677177429199 - Train Accuracy: 0.7089911279274578 - Validation Accuracy: 0.7079286640409032\n",
            "Epoch 11/50 :\n",
            "Train Loss: 0.6026780009269714 - Validation Loss: 0.6091050505638123 - Train Accuracy: 0.7091025724661317 - Validation Accuracy: 0.707977591310517\n",
            "Epoch 12/50 :\n",
            "Train Loss: 0.6021531224250793 - Validation Loss: 0.6070083975791931 - Train Accuracy: 0.7094803966338313 - Validation Accuracy: 0.7090539912420187\n",
            "Epoch 13/50 :\n",
            "Train Loss: 0.6014546155929565 - Validation Loss: 0.6076768040657043 - Train Accuracy: 0.7099153021506078 - Validation Accuracy: 0.7079042004060964\n",
            "Epoch 14/50 :\n",
            "Train Loss: 0.6008431315422058 - Validation Loss: 0.6062893867492676 - Train Accuracy: 0.7099506382238459 - Validation Accuracy: 0.7090295276072118\n",
            "Epoch 15/50 :\n",
            "Train Loss: 0.6002564430236816 - Validation Loss: 0.6064735054969788 - Train Accuracy: 0.7103882619001022 - Validation Accuracy: 0.7083690094674266\n",
            "Epoch 16/50 :\n",
            "Train Loss: 0.5997684001922607 - Validation Loss: 0.6058285236358643 - Train Accuracy: 0.7103746711027029 - Validation Accuracy: 0.7085157912762678\n",
            "Epoch 17/50 :\n",
            "Train Loss: 0.5993471145629883 - Validation Loss: 0.6056346893310547 - Train Accuracy: 0.7106002783395308 - Validation Accuracy: 0.7087848912591432\n",
            "Epoch 18/50 :\n",
            "Train Loss: 0.5989730954170227 - Validation Loss: 0.6054513454437256 - Train Accuracy: 0.7108802487659556 - Validation Accuracy: 0.7086381094503021\n",
            "Epoch 19/50 :\n",
            "Train Loss: 0.5986117720603943 - Validation Loss: 0.6050038933753967 - Train Accuracy: 0.7107959858220801 - Validation Accuracy: 0.7088582821635638\n",
            "Epoch 20/50 :\n",
            "Train Loss: 0.5982575416564941 - Validation Loss: 0.6050121188163757 - Train Accuracy: 0.7109699480287908 - Validation Accuracy: 0.7088582821635638\n",
            "Epoch 21/50 :\n",
            "Train Loss: 0.5979257822036743 - Validation Loss: 0.604473888874054 - Train Accuracy: 0.7111167286407029 - Validation Accuracy: 0.7097879002862245\n",
            "Epoch 22/50 :\n",
            "Train Loss: 0.5976470708847046 - Validation Loss: 0.6049008369445801 - Train Accuracy: 0.7111547828734207 - Validation Accuracy: 0.7092986275900873\n",
            "Epoch 23/50 :\n",
            "Train Loss: 0.5974812507629395 - Validation Loss: 0.6042075157165527 - Train Accuracy: 0.7112390458172962 - Validation Accuracy: 0.7097145093818039\n",
            "Epoch 24/50 :\n",
            "Train Loss: 0.5976125597953796 - Validation Loss: 0.607134997844696 - Train Accuracy: 0.7109400482745124 - Validation Accuracy: 0.7076351004232209\n",
            "Epoch 25/50 :\n",
            "Train Loss: 0.598805844783783 - Validation Loss: 0.6081207394599915 - Train Accuracy: 0.7105812512231717 - Validation Accuracy: 0.7068278004745945\n",
            "Epoch 26/50 :\n",
            "Train Loss: 0.6027294993400574 - Validation Loss: 0.6262447237968445 - Train Accuracy: 0.7068247548220149 - Validation Accuracy: 0.7007118917728796\n",
            "Epoch 27/50 :\n",
            "Train Loss: 0.6153647303581238 - Validation Loss: 0.6264818906784058 - Train Accuracy: 0.7044708287124622 - Validation Accuracy: 0.6922474741297062\n",
            "Epoch 28/50 :\n",
            "Train Loss: 0.6229549050331116 - Validation Loss: 0.6379143595695496 - Train Accuracy: 0.6919156500750212 - Validation Accuracy: 0.6967243192993615\n",
            "Epoch 29/50 :\n",
            "Train Loss: 0.6261976361274719 - Validation Loss: 0.6033527851104736 - Train Accuracy: 0.7010948746384847 - Validation Accuracy: 0.7104239547912029\n",
            "Epoch 30/50 :\n",
            "Train Loss: 0.5967105031013489 - Validation Loss: 0.6169926524162292 - Train Accuracy: 0.7116059973470763 - Validation Accuracy: 0.7003204736159698\n",
            "Epoch 31/50 :\n",
            "Train Loss: 0.6128871440887451 - Validation Loss: 0.6341385245323181 - Train Accuracy: 0.7004425163633201 - Validation Accuracy: 0.6961616556988037\n",
            "Epoch 32/50 :\n",
            "Train Loss: 0.6228257417678833 - Validation Loss: 0.6051569581031799 - Train Accuracy: 0.7008638310826972 - Validation Accuracy: 0.7078063458668689\n",
            "Epoch 33/50 :\n",
            "Train Loss: 0.5971476435661316 - Validation Loss: 0.6276612281799316 - Train Accuracy: 0.7107470589514427 - Validation Accuracy: 0.6911221469285906\n",
            "Epoch 34/50 :\n",
            "Train Loss: 0.6242147088050842 - Validation Loss: 0.6173060536384583 - Train Accuracy: 0.6909479853001935 - Validation Accuracy: 0.7035741370452822\n",
            "Epoch 35/50 :\n",
            "Train Loss: 0.6076257824897766 - Validation Loss: 0.6169978380203247 - Train Accuracy: 0.7070177441450844 - Validation Accuracy: 0.7037209188541234\n",
            "Epoch 36/50 :\n",
            "Train Loss: 0.606957733631134 - Validation Loss: 0.6153748631477356 - Train Accuracy: 0.7072596603387914 - Validation Accuracy: 0.7008831372165276\n",
            "Epoch 37/50 :\n",
            "Train Loss: 0.6105749607086182 - Validation Loss: 0.6037377119064331 - Train Accuracy: 0.7016194794180964 - Validation Accuracy: 0.7091518457812461\n",
            "Epoch 38/50 :\n",
            "Train Loss: 0.5974441170692444 - Validation Loss: 0.6187055706977844 - Train Accuracy: 0.7102985626372671 - Validation Accuracy: 0.7037209188541234\n",
            "Epoch 39/50 :\n",
            "Train Loss: 0.6085749864578247 - Validation Loss: 0.6044368147850037 - Train Accuracy: 0.7068682453736925 - Validation Accuracy: 0.7086136458154952\n",
            "Epoch 40/50 :\n",
            "Train Loss: 0.5959954261779785 - Validation Loss: 0.6127830147743225 - Train Accuracy: 0.7116657968556331 - Validation Accuracy: 0.7020084644176432\n",
            "Epoch 41/50 :\n",
            "Train Loss: 0.6073579788208008 - Validation Loss: 0.6025699973106384 - Train Accuracy: 0.7035847087220302 - Validation Accuracy: 0.7096411184773833\n",
            "Epoch 42/50 :\n",
            "Train Loss: 0.5946654677391052 - Validation Loss: 0.6135607957839966 - Train Accuracy: 0.7118479135407833 - Validation Accuracy: 0.7047483915160114\n",
            "Epoch 43/50 :\n",
            "Train Loss: 0.6035482287406921 - Validation Loss: 0.6018641591072083 - Train Accuracy: 0.7083224606954139 - Validation Accuracy: 0.7100325366342931\n",
            "Epoch 44/50 :\n",
            "Train Loss: 0.5940656661987305 - Validation Loss: 0.6078348755836487 - Train Accuracy: 0.7123235914497575 - Validation Accuracy: 0.7058981823519338\n",
            "Epoch 45/50 :\n",
            "Train Loss: 0.6017428040504456 - Validation Loss: 0.6026940941810608 - Train Accuracy: 0.7069742535934068 - Validation Accuracy: 0.7094698730337353\n",
            "Epoch 46/50 :\n",
            "Train Loss: 0.5940993428230286 - Validation Loss: 0.6087371110916138 - Train Accuracy: 0.7121795289973253 - Validation Accuracy: 0.7061672823348093\n",
            "Epoch 47/50 :\n",
            "Train Loss: 0.5990570783615112 - Validation Loss: 0.6009142994880676 - Train Accuracy: 0.7099316111074869 - Validation Accuracy: 0.7097389730166108\n",
            "Epoch 48/50 :\n",
            "Train Loss: 0.5935269594192505 - Validation Loss: 0.6038790941238403 - Train Accuracy: 0.71209254789397 - Validation Accuracy: 0.7082711549281993\n",
            "Epoch 49/50 :\n",
            "Train Loss: 0.5973110198974609 - Validation Loss: 0.6025882363319397 - Train Accuracy: 0.7095700958966664 - Validation Accuracy: 0.7091029185116324\n",
            "Epoch 50/50 :\n",
            "Train Loss: 0.5936230421066284 - Validation Loss: 0.6048474311828613 - Train Accuracy: 0.7123833909583143 - Validation Accuracy: 0.7078552731364827\n",
            "Epoch 1/50 :\n",
            "Train Loss: 0.5965814590454102 - Validation Loss: 0.5920788645744324 - Train Accuracy: 0.7110297475373475 - Validation Accuracy: 0.7115982092619322\n",
            "Epoch 2/50 :\n",
            "Train Loss: 0.5943145155906677 - Validation Loss: 0.5926638841629028 - Train Accuracy: 0.7118261682649445 - Validation Accuracy: 0.7121853364972968\n",
            "Epoch 3/50 :\n",
            "Train Loss: 0.5949946641921997 - Validation Loss: 0.5920047760009766 - Train Accuracy: 0.711056929132146 - Validation Accuracy: 0.7130904909851505\n",
            "Epoch 4/50 :\n",
            "Train Loss: 0.5942345857620239 - Validation Loss: 0.5915404558181763 - Train Accuracy: 0.7120816752560506 - Validation Accuracy: 0.7130415637155368\n",
            "Epoch 5/50 :\n",
            "Train Loss: 0.5935991406440735 - Validation Loss: 0.5917948484420776 - Train Accuracy: 0.7125111444538674 - Validation Accuracy: 0.712503363749786\n",
            "Epoch 6/50 :\n",
            "Train Loss: 0.593791127204895 - Validation Loss: 0.5905070304870605 - Train Accuracy: 0.7116712331745928 - Validation Accuracy: 0.712503363749786\n",
            "Epoch 7/50 :\n",
            "Train Loss: 0.592415988445282 - Validation Loss: 0.5915435552597046 - Train Accuracy: 0.7126633613847392 - Validation Accuracy: 0.71301710008073\n",
            "Epoch 8/50 :\n",
            "Train Loss: 0.5933395624160767 - Validation Loss: 0.5898851752281189 - Train Accuracy: 0.712388827277274 - Validation Accuracy: 0.7137510091249358\n",
            "Epoch 9/50 :\n",
            "Train Loss: 0.5916053056716919 - Validation Loss: 0.5912148356437683 - Train Accuracy: 0.713054776349838 - Validation Accuracy: 0.712478900114979\n",
            "Epoch 10/50 :\n",
            "Train Loss: 0.5928313732147217 - Validation Loss: 0.5894922018051147 - Train Accuracy: 0.7122121469110836 - Validation Accuracy: 0.7142158181862661\n",
            "Epoch 11/50 :\n",
            "Train Loss: 0.590932309627533 - Validation Loss: 0.590695858001709 - Train Accuracy: 0.7135440450562115 - Validation Accuracy: 0.7136042273160946\n",
            "Epoch 12/50 :\n",
            "Train Loss: 0.5920578241348267 - Validation Loss: 0.5891177654266357 - Train Accuracy: 0.7129351773327245 - Validation Accuracy: 0.7145583090735621\n",
            "Epoch 13/50 :\n",
            "Train Loss: 0.5905346870422363 - Validation Loss: 0.5898954272270203 - Train Accuracy: 0.7136011264052885 - Validation Accuracy: 0.7130904909851505\n",
            "Epoch 14/50 :\n",
            "Train Loss: 0.5912132859230042 - Validation Loss: 0.5893111228942871 - Train Accuracy: 0.7128590688672886 - Validation Accuracy: 0.7140935000122318\n",
            "Epoch 15/50 :\n",
            "Train Loss: 0.5904074907302856 - Validation Loss: 0.5891994833946228 - Train Accuracy: 0.7139327418618305 - Validation Accuracy: 0.7145583090735621\n",
            "Epoch 16/50 :\n",
            "Train Loss: 0.5902513265609741 - Validation Loss: 0.5891764163970947 - Train Accuracy: 0.7138756605127536 - Validation Accuracy: 0.7136042273160946\n",
            "Epoch 17/50 :\n",
            "Train Loss: 0.5902723073959351 - Validation Loss: 0.5884661674499512 - Train Accuracy: 0.7135413268967317 - Validation Accuracy: 0.7148518726912445\n",
            "Epoch 18/50 :\n",
            "Train Loss: 0.5894185900688171 - Validation Loss: 0.5891504287719727 - Train Accuracy: 0.7138892513101529 - Validation Accuracy: 0.7140935000122318\n",
            "Epoch 19/50 :\n",
            "Train Loss: 0.5899052619934082 - Validation Loss: 0.5882426500320435 - Train Accuracy: 0.7139898232109074 - Validation Accuracy: 0.714411527264721\n",
            "Epoch 20/50 :\n",
            "Train Loss: 0.5889770984649658 - Validation Loss: 0.5885456204414368 - Train Accuracy: 0.7142072759692957 - Validation Accuracy: 0.713702081855322\n",
            "Epoch 21/50 :\n",
            "Train Loss: 0.5892626047134399 - Validation Loss: 0.5882732272148132 - Train Accuracy: 0.7138946876291126 - Validation Accuracy: 0.714925263595665\n",
            "Epoch 22/50 :\n",
            "Train Loss: 0.5888283848762512 - Validation Loss: 0.5880575180053711 - Train Accuracy: 0.7142534846804531 - Validation Accuracy: 0.7147050908824033\n",
            "Epoch 23/50 :\n",
            "Train Loss: 0.5884855389595032 - Validation Loss: 0.5882368683815002 - Train Accuracy: 0.7146285906886729 - Validation Accuracy: 0.7139222545685838\n",
            "Epoch 24/50 :\n",
            "Train Loss: 0.5886223912239075 - Validation Loss: 0.5876880288124084 - Train Accuracy: 0.714071367995303 - Validation Accuracy: 0.7145338454387553\n",
            "Epoch 25/50 :\n",
            "Train Loss: 0.5879585146903992 - Validation Loss: 0.5879511833190918 - Train Accuracy: 0.7148270163307021 - Validation Accuracy: 0.7150965090393131\n",
            "Epoch 26/50 :\n",
            "Train Loss: 0.5881016254425049 - Validation Loss: 0.5876317620277405 - Train Accuracy: 0.7145497640637571 - Validation Accuracy: 0.7148518726912445\n",
            "Epoch 27/50 :\n",
            "Train Loss: 0.5877346992492676 - Validation Loss: 0.5874460935592651 - Train Accuracy: 0.7145986909343945 - Validation Accuracy: 0.7149007999608582\n",
            "Epoch 28/50 :\n",
            "Train Loss: 0.5874530076980591 - Validation Loss: 0.5875903367996216 - Train Accuracy: 0.7147916802574641 - Validation Accuracy: 0.714240281821073\n",
            "Epoch 29/50 :\n",
            "Train Loss: 0.5874825716018677 - Validation Loss: 0.5871576070785522 - Train Accuracy: 0.7148460434470612 - Validation Accuracy: 0.7147295545172102\n",
            "Epoch 30/50 :\n",
            "Train Loss: 0.5870168805122375 - Validation Loss: 0.5872045159339905 - Train Accuracy: 0.715145040989845 - Validation Accuracy: 0.7144849181691416\n",
            "Epoch 31/50 :\n",
            "Train Loss: 0.5869859457015991 - Validation Loss: 0.5871592164039612 - Train Accuracy: 0.7150471872485702 - Validation Accuracy: 0.714582772708369\n",
            "Epoch 32/50 :\n",
            "Train Loss: 0.5867928266525269 - Validation Loss: 0.5868724584579468 - Train Accuracy: 0.7151885315415226 - Validation Accuracy: 0.7145093818039484\n",
            "Epoch 33/50 :\n",
            "Train Loss: 0.586452066898346 - Validation Loss: 0.58689945936203 - Train Accuracy: 0.7154929654032661 - Validation Accuracy: 0.7149497272304719\n",
            "Epoch 34/50 :\n",
            "Train Loss: 0.5864460468292236 - Validation Loss: 0.5867199301719666 - Train Accuracy: 0.7153135668775958 - Validation Accuracy: 0.714925263595665\n",
            "Epoch 35/50 :\n",
            "Train Loss: 0.5861461758613586 - Validation Loss: 0.586565375328064 - Train Accuracy: 0.7155174288385848 - Validation Accuracy: 0.7147050908824033\n",
            "Epoch 36/50 :\n",
            "Train Loss: 0.5859283804893494 - Validation Loss: 0.5865217447280884 - Train Accuracy: 0.7156696457694566 - Validation Accuracy: 0.7153166817525748\n",
            "Epoch 37/50 :\n",
            "Train Loss: 0.5858619213104248 - Validation Loss: 0.5863365530967712 - Train Accuracy: 0.7155391741144237 - Validation Accuracy: 0.7149741908652788\n",
            "Epoch 38/50 :\n",
            "Train Loss: 0.5855674147605896 - Validation Loss: 0.586243212223053 - Train Accuracy: 0.7158055537434492 - Validation Accuracy: 0.714925263595665\n",
            "Epoch 39/50 :\n",
            "Train Loss: 0.5853951573371887 - Validation Loss: 0.5861799120903015 - Train Accuracy: 0.715718572640094 - Validation Accuracy: 0.7153656090221885\n",
            "Epoch 40/50 :\n",
            "Train Loss: 0.5852944254875183 - Validation Loss: 0.5860121846199036 - Train Accuracy: 0.7158436079761672 - Validation Accuracy: 0.7149497272304719\n",
            "Epoch 41/50 :\n",
            "Train Loss: 0.5850173234939575 - Validation Loss: 0.5859179496765137 - Train Accuracy: 0.7159006893252441 - Validation Accuracy: 0.7152432908481542\n",
            "Epoch 42/50 :\n",
            "Train Loss: 0.5848575234413147 - Validation Loss: 0.5858123898506165 - Train Accuracy: 0.7160719333724749 - Validation Accuracy: 0.7148029454216307\n",
            "Epoch 43/50 :\n",
            "Train Loss: 0.5847303867340088 - Validation Loss: 0.5856794118881226 - Train Accuracy: 0.7160447517776763 - Validation Accuracy: 0.7153411453873817\n",
            "Epoch 44/50 :\n",
            "Train Loss: 0.5844894647598267 - Validation Loss: 0.5855738520622253 - Train Accuracy: 0.7160637788940353 - Validation Accuracy: 0.715634709005064\n",
            "Epoch 45/50 :\n",
            "Train Loss: 0.5843107104301453 - Validation Loss: 0.5854751467704773 - Train Accuracy: 0.7161670689542697 - Validation Accuracy: 0.7151698999437336\n",
            "Epoch 46/50 :\n",
            "Train Loss: 0.584186851978302 - Validation Loss: 0.5853583812713623 - Train Accuracy: 0.7163247222041011 - Validation Accuracy: 0.7154879271962228\n",
            "Epoch 47/50 :\n",
            "Train Loss: 0.5839736461639404 - Validation Loss: 0.5852335691452026 - Train Accuracy: 0.7163111314067019 - Validation Accuracy: 0.7152677544829611\n",
            "Epoch 48/50 :\n",
            "Train Loss: 0.5837768316268921 - Validation Loss: 0.5851477384567261 - Train Accuracy: 0.7164008306695371 - Validation Accuracy: 0.7150965090393131\n",
            "Epoch 49/50 :\n",
            "Train Loss: 0.5836454033851624 - Validation Loss: 0.5850642323493958 - Train Accuracy: 0.7164796572944527 - Validation Accuracy: 0.7156102453702571\n",
            "Epoch 50/50 :\n",
            "Train Loss: 0.583468496799469 - Validation Loss: 0.5849239230155945 - Train Accuracy: 0.7166210015874052 - Validation Accuracy: 0.7156836362746777\n",
            "Epoch 1/50 :\n",
            "Train Loss: 0.5834375023841858 - Validation Loss: 0.5832255482673645 - Train Accuracy: 0.7163899580316176 - Validation Accuracy: 0.7174694816155784\n",
            "Epoch 2/50 :\n",
            "Train Loss: 0.5832774639129639 - Validation Loss: 0.5832051038742065 - Train Accuracy: 0.7164334485832953 - Validation Accuracy: 0.717029136189055\n",
            "Epoch 3/50 :\n",
            "Train Loss: 0.5831285715103149 - Validation Loss: 0.5831283926963806 - Train Accuracy: 0.7165911018331268 - Validation Accuracy: 0.7174939452503853\n",
            "Epoch 4/50 :\n",
            "Train Loss: 0.5829356908798218 - Validation Loss: 0.5830622315406799 - Train Accuracy: 0.7165014025702916 - Validation Accuracy: 0.7170535998238619\n",
            "Epoch 5/50 :\n",
            "Train Loss: 0.5827407240867615 - Validation Loss: 0.5830080509185791 - Train Accuracy: 0.7166808010959619 - Validation Accuracy: 0.7165643271277247\n",
            "Epoch 6/50 :\n",
            "Train Loss: 0.5825802683830261 - Validation Loss: 0.5829413533210754 - Train Accuracy: 0.7167460369234784 - Validation Accuracy: 0.7171514543630892\n",
            "Epoch 7/50 :\n",
            "Train Loss: 0.5824213624000549 - Validation Loss: 0.5828886032104492 - Train Accuracy: 0.7169335899275883 - Validation Accuracy: 0.7164664725884972\n",
            "Epoch 8/50 :\n",
            "Train Loss: 0.5822315812110901 - Validation Loss: 0.5828131437301636 - Train Accuracy: 0.71690097201383 - Validation Accuracy: 0.7173471634415441\n",
            "Epoch 9/50 :\n",
            "Train Loss: 0.5820358991622925 - Validation Loss: 0.5827699899673462 - Train Accuracy: 0.717066779742101 - Validation Accuracy: 0.716857890745407\n",
            "Epoch 10/50 :\n",
            "Train Loss: 0.5818655490875244 - Validation Loss: 0.5827563405036926 - Train Accuracy: 0.7172298693108922 - Validation Accuracy: 0.7164664725884972\n",
            "Epoch 11/50 :\n",
            "Train Loss: 0.5817059278488159 - Validation Loss: 0.5826976299285889 - Train Accuracy: 0.7172597690651706 - Validation Accuracy: 0.7169312816498276\n",
            "Epoch 12/50 :\n",
            "Train Loss: 0.5815354585647583 - Validation Loss: 0.5826476812362671 - Train Accuracy: 0.7174092678365626 - Validation Accuracy: 0.7167600362061796\n",
            "Epoch 13/50 :\n",
            "Train Loss: 0.5813524127006531 - Validation Loss: 0.5825774073600769 - Train Accuracy: 0.7173385956900863 - Validation Accuracy: 0.7167111089365658\n",
            "Epoch 14/50 :\n",
            "Train Loss: 0.5811682939529419 - Validation Loss: 0.5825249552726746 - Train Accuracy: 0.7175941026811925 - Validation Accuracy: 0.716515399858111\n",
            "Epoch 15/50 :\n",
            "Train Loss: 0.5809919238090515 - Validation Loss: 0.5824915766716003 - Train Accuracy: 0.7175832300432731 - Validation Accuracy: 0.7167111089365658\n",
            "Epoch 16/50 :\n",
            "Train Loss: 0.5808253884315491 - Validation Loss: 0.5824429988861084 - Train Accuracy: 0.7175723574053536 - Validation Accuracy: 0.7163930816840767\n",
            "Epoch 17/50 :\n",
            "Train Loss: 0.5806640982627869 - Validation Loss: 0.5824087858200073 - Train Accuracy: 0.7178142735990606 - Validation Accuracy: 0.7162707635100424\n",
            "Epoch 18/50 :\n",
            "Train Loss: 0.5805045366287231 - Validation Loss: 0.5823542475700378 - Train Accuracy: 0.7178006828016613 - Validation Accuracy: 0.7164909362233041\n",
            "Epoch 19/50 :\n",
            "Train Loss: 0.5803443789482117 - Validation Loss: 0.582308828830719 - Train Accuracy: 0.7179692086894123 - Validation Accuracy: 0.7162707635100424\n",
            "Epoch 20/50 :\n",
            "Train Loss: 0.5801838040351868 - Validation Loss: 0.5822483897209167 - Train Accuracy: 0.7179583360514928 - Validation Accuracy: 0.7163686180492698\n",
            "Epoch 21/50 :\n",
            "Train Loss: 0.5800230503082275 - Validation Loss: 0.5822180509567261 - Train Accuracy: 0.7181295800987235 - Validation Accuracy: 0.7159527362575532\n",
            "Epoch 22/50 :\n",
            "Train Loss: 0.5798650979995728 - Validation Loss: 0.5821607708930969 - Train Accuracy: 0.7182627699132363 - Validation Accuracy: 0.7164420089536904\n",
            "Epoch 23/50 :\n",
            "Train Loss: 0.5797170996665955 - Validation Loss: 0.5821706056594849 - Train Accuracy: 0.7182274338399982 - Validation Accuracy: 0.7156836362746777\n",
            "Epoch 24/50 :\n",
            "Train Loss: 0.5795876979827881 - Validation Loss: 0.5821371078491211 - Train Accuracy: 0.7182573335942767 - Validation Accuracy: 0.7159527362575532\n",
            "Epoch 25/50 :\n",
            "Train Loss: 0.5794862508773804 - Validation Loss: 0.5822274684906006 - Train Accuracy: 0.7182355883184378 - Validation Accuracy: 0.7163686180492698\n",
            "Epoch 26/50 :\n",
            "Train Loss: 0.5794451832771301 - Validation Loss: 0.5823155641555786 - Train Accuracy: 0.7182301519994782 - Validation Accuracy: 0.7163196907796561\n",
            "Epoch 27/50 :\n",
            "Train Loss: 0.5794885754585266 - Validation Loss: 0.5826791524887085 - Train Accuracy: 0.7180235718790093 - Validation Accuracy: 0.71597719989236\n",
            "Epoch 28/50 :\n",
            "Train Loss: 0.5796845555305481 - Validation Loss: 0.5829734206199646 - Train Accuracy: 0.7181920977667602 - Validation Accuracy: 0.714582772708369\n",
            "Epoch 29/50 :\n",
            "Train Loss: 0.5799648761749268 - Validation Loss: 0.5835779309272766 - Train Accuracy: 0.7178224280775002 - Validation Accuracy: 0.7159038089879395\n",
            "Epoch 30/50 :\n",
            "Train Loss: 0.5803484320640564 - Validation Loss: 0.5835627913475037 - Train Accuracy: 0.7175125578967969 - Validation Accuracy: 0.7143625999951073\n",
            "Epoch 31/50 :\n",
            "Train Loss: 0.5803854465484619 - Validation Loss: 0.5835779309272766 - Train Accuracy: 0.717327723052167 - Validation Accuracy: 0.7151209726741199\n",
            "Epoch 32/50 :\n",
            "Train Loss: 0.5801453590393066 - Validation Loss: 0.5826653242111206 - Train Accuracy: 0.7177272924957053 - Validation Accuracy: 0.7142892090906867\n",
            "Epoch 33/50 :\n",
            "Train Loss: 0.5793031454086304 - Validation Loss: 0.5820051431655884 - Train Accuracy: 0.7181839432883206 - Validation Accuracy: 0.7161239817012012\n",
            "Epoch 34/50 :\n",
            "Train Loss: 0.5784361362457275 - Validation Loss: 0.581489086151123 - Train Accuracy: 0.7187601930980494 - Validation Accuracy: 0.7163686180492698\n",
            "Epoch 35/50 :\n",
            "Train Loss: 0.5778990983963013 - Validation Loss: 0.5815411806106567 - Train Accuracy: 0.7189042555504817 - Validation Accuracy: 0.7155368544658365\n",
            "Epoch 36/50 :\n",
            "Train Loss: 0.5778881311416626 - Validation Loss: 0.5820073485374451 - Train Accuracy: 0.7189504642616391 - Validation Accuracy: 0.7161484453360081\n",
            "Epoch 37/50 :\n",
            "Train Loss: 0.5781986713409424 - Validation Loss: 0.5822392702102661 - Train Accuracy: 0.7187493204601301 - Validation Accuracy: 0.7142158181862661\n",
            "Epoch 38/50 :\n",
            "Train Loss: 0.5784646272659302 - Validation Loss: 0.5825526118278503 - Train Accuracy: 0.7184476047578664 - Validation Accuracy: 0.7160261271619738\n",
            "Epoch 39/50 :\n",
            "Train Loss: 0.5785583853721619 - Validation Loss: 0.5822570323944092 - Train Accuracy: 0.7185074042664231 - Validation Accuracy: 0.7139222545685838\n",
            "Epoch 40/50 :\n",
            "Train Loss: 0.5783163905143738 - Validation Loss: 0.5820838809013367 - Train Accuracy: 0.7185672037749798 - Validation Accuracy: 0.7159038089879395\n",
            "Epoch 41/50 :\n",
            "Train Loss: 0.5779356360435486 - Validation Loss: 0.5815677046775818 - Train Accuracy: 0.7186215669645769 - Validation Accuracy: 0.7150965090393131\n",
            "Epoch 42/50 :\n",
            "Train Loss: 0.5774263739585876 - Validation Loss: 0.5812816023826599 - Train Accuracy: 0.719102681192511 - Validation Accuracy: 0.7169802089194413\n",
            "Epoch 43/50 :\n",
            "Train Loss: 0.5769898891448975 - Validation Loss: 0.5810335874557495 - Train Accuracy: 0.7190510361623937 - Validation Accuracy: 0.7157814908139051\n",
            "Epoch 44/50 :\n",
            "Train Loss: 0.576680600643158 - Validation Loss: 0.5809629559516907 - Train Accuracy: 0.719469632722291 - Validation Accuracy: 0.7159527362575532\n",
            "Epoch 45/50 :\n",
            "Train Loss: 0.5765296816825867 - Validation Loss: 0.581049382686615 - Train Accuracy: 0.719472350881771 - Validation Accuracy: 0.7166377180321453\n",
            "Epoch 46/50 :\n",
            "Train Loss: 0.5765084028244019 - Validation Loss: 0.5811510682106018 - Train Accuracy: 0.7194506056059321 - Validation Accuracy: 0.7148274090564376\n",
            "Epoch 47/50 :\n",
            "Train Loss: 0.5765820145606995 - Validation Loss: 0.5814833641052246 - Train Accuracy: 0.7195729227825255 - Validation Accuracy: 0.7163930816840767\n",
            "Epoch 48/50 :\n",
            "Train Loss: 0.5767708420753479 - Validation Loss: 0.5817738771438599 - Train Accuracy: 0.7191896622958662 - Validation Accuracy: 0.714411527264721\n",
            "Epoch 49/50 :\n",
            "Train Loss: 0.5770924091339111 - Validation Loss: 0.5826482176780701 - Train Accuracy: 0.7190401635244743 - Validation Accuracy: 0.7159527362575532\n",
            "Epoch 50/50 :\n",
            "Train Loss: 0.5777509808540344 - Validation Loss: 0.5833551287651062 - Train Accuracy: 0.7186704938352143 - Validation Accuracy: 0.7132862000636054\n",
            "Epoch 1/50 :\n",
            "Train Loss: 0.5791900753974915 - Validation Loss: 0.5790714621543884 - Train Accuracy: 0.7171755061212951 - Validation Accuracy: 0.7170046725542482\n",
            "Epoch 2/50 :\n",
            "Train Loss: 0.5805711150169373 - Validation Loss: 0.5802589058876038 - Train Accuracy: 0.7172978232978885 - Validation Accuracy: 0.7165398634929178\n",
            "Epoch 3/50 :\n",
            "Train Loss: 0.5811758637428284 - Validation Loss: 0.5800736546516418 - Train Accuracy: 0.7160365972992367 - Validation Accuracy: 0.71597719989236\n",
            "Epoch 4/50 :\n",
            "Train Loss: 0.5812572836875916 - Validation Loss: 0.5782565474510193 - Train Accuracy: 0.7166699284580424 - Validation Accuracy: 0.7178364361376813\n",
            "Epoch 5/50 :\n",
            "Train Loss: 0.5788527727127075 - Validation Loss: 0.5757861137390137 - Train Accuracy: 0.7174908126209582 - Validation Accuracy: 0.717885363407295\n",
            "Epoch 6/50 :\n",
            "Train Loss: 0.5765551924705505 - Validation Loss: 0.5754667520523071 - Train Accuracy: 0.7193364429077783 - Validation Accuracy: 0.7182523179293979\n",
            "Epoch 7/50 :\n",
            "Train Loss: 0.5758817791938782 - Validation Loss: 0.576691746711731 - Train Accuracy: 0.7195892317394046 - Validation Accuracy: 0.7187171269907283\n",
            "Epoch 8/50 :\n",
            "Train Loss: 0.5769543051719666 - Validation Loss: 0.5777795314788818 - Train Accuracy: 0.7187765020549286 - Validation Accuracy: 0.716857890745407\n",
            "Epoch 9/50 :\n",
            "Train Loss: 0.5780475735664368 - Validation Loss: 0.5776398777961731 - Train Accuracy: 0.7184557592363059 - Validation Accuracy: 0.7183257088338185\n",
            "Epoch 10/50 :\n",
            "Train Loss: 0.5773729085922241 - Validation Loss: 0.5760881304740906 - Train Accuracy: 0.7181486072150826 - Validation Accuracy: 0.7172493089023168\n",
            "Epoch 11/50 :\n",
            "Train Loss: 0.5760458111763 - Validation Loss: 0.575761079788208 - Train Accuracy: 0.7194125513732141 - Validation Accuracy: 0.7179098270421019\n",
            "Epoch 12/50 :\n",
            "Train Loss: 0.5752245783805847 - Validation Loss: 0.5759763717651367 - Train Accuracy: 0.7199290016743862 - Validation Accuracy: 0.7192308633216723\n",
            "Epoch 13/50 :\n",
            "Train Loss: 0.575511634349823 - Validation Loss: 0.5767262578010559 - Train Accuracy: 0.7198202752951921 - Validation Accuracy: 0.7167355725713727\n",
            "Epoch 14/50 :\n",
            "Train Loss: 0.5762349963188171 - Validation Loss: 0.5772828459739685 - Train Accuracy: 0.719434296649053 - Validation Accuracy: 0.7183257088338185\n",
            "Epoch 15/50 :\n",
            "Train Loss: 0.5763539671897888 - Validation Loss: 0.5764963030815125 - Train Accuracy: 0.7187194207058517 - Validation Accuracy: 0.7169068180150207\n",
            "Epoch 16/50 :\n",
            "Train Loss: 0.5759033560752869 - Validation Loss: 0.5762023329734802 - Train Accuracy: 0.7195946680583644 - Validation Accuracy: 0.7183501724686254\n",
            "Epoch 17/50 :\n",
            "Train Loss: 0.5750328898429871 - Validation Loss: 0.5754334330558777 - Train Accuracy: 0.7199181290364668 - Validation Accuracy: 0.7176407270592264\n",
            "Epoch 18/50 :\n",
            "Train Loss: 0.5744537115097046 - Validation Loss: 0.5754919648170471 - Train Accuracy: 0.7203530345532433 - Validation Accuracy: 0.7174939452503853\n",
            "Epoch 19/50 :\n",
            "Train Loss: 0.57440584897995 - Validation Loss: 0.5761517286300659 - Train Accuracy: 0.7203013895231261 - Validation Accuracy: 0.7181544633901705\n",
            "Epoch 20/50 :\n",
            "Train Loss: 0.5747307538986206 - Validation Loss: 0.5763067007064819 - Train Accuracy: 0.7200023919803422 - Validation Accuracy: 0.7173226998067372\n",
            "Epoch 21/50 :\n",
            "Train Loss: 0.5751370787620544 - Validation Loss: 0.5769853591918945 - Train Accuracy: 0.7197686302650749 - Validation Accuracy: 0.7176896543288401\n",
            "Epoch 22/50 :\n",
            "Train Loss: 0.5752900838851929 - Validation Loss: 0.5769274830818176 - Train Accuracy: 0.7193174157914193 - Validation Accuracy: 0.7170535998238619\n",
            "Epoch 23/50 :\n",
            "Train Loss: 0.5753716826438904 - Validation Loss: 0.576967716217041 - Train Accuracy: 0.7198012481788332 - Validation Accuracy: 0.7176651906940333\n",
            "Epoch 24/50 :\n",
            "Train Loss: 0.5751541256904602 - Validation Loss: 0.5767725110054016 - Train Accuracy: 0.719415269532694 - Validation Accuracy: 0.716686645301759\n",
            "Epoch 25/50 :\n",
            "Train Loss: 0.574886679649353 - Validation Loss: 0.5764327049255371 - Train Accuracy: 0.7199589014286646 - Validation Accuracy: 0.7186437360863077\n",
            "Epoch 26/50 :\n",
            "Train Loss: 0.5744287967681885 - Validation Loss: 0.576072633266449 - Train Accuracy: 0.72004588253202 - Validation Accuracy: 0.7165887907625315\n",
            "Epoch 27/50 :\n",
            "Train Loss: 0.5740050077438354 - Validation Loss: 0.5758785009384155 - Train Accuracy: 0.7204671972513972 - Validation Accuracy: 0.7180810724857499\n",
            "Epoch 28/50 :\n",
            "Train Loss: 0.573595404624939 - Validation Loss: 0.5755571722984314 - Train Accuracy: 0.7206493139365473 - Validation Accuracy: 0.7165643271277247\n",
            "Epoch 29/50 :\n",
            "Train Loss: 0.5732983350753784 - Validation Loss: 0.5756133198738098 - Train Accuracy: 0.7208096853458587 - Validation Accuracy: 0.7170780634586686\n",
            "Epoch 30/50 :\n",
            "Train Loss: 0.5730863213539124 - Validation Loss: 0.5754546523094177 - Train Accuracy: 0.7208069671863787 - Validation Accuracy: 0.7177630452332607\n",
            "Epoch 31/50 :\n",
            "Train Loss: 0.5729463696479797 - Validation Loss: 0.5755089521408081 - Train Accuracy: 0.7209156935655728 - Validation Accuracy: 0.7169802089194413\n",
            "Epoch 32/50 :\n",
            "Train Loss: 0.5728735327720642 - Validation Loss: 0.575664222240448 - Train Accuracy: 0.7209347206819319 - Validation Accuracy: 0.7179342906769087\n",
            "Epoch 33/50 :\n",
            "Train Loss: 0.572864830493927 - Validation Loss: 0.5756998658180237 - Train Accuracy: 0.7209347206819319 - Validation Accuracy: 0.7166377180321453\n",
            "Epoch 34/50 :\n",
            "Train Loss: 0.5729436278343201 - Validation Loss: 0.5761870741844177 - Train Accuracy: 0.7209700567551699 - Validation Accuracy: 0.7176162634244196\n",
            "Epoch 35/50 :\n",
            "Train Loss: 0.5731556415557861 - Validation Loss: 0.5766485333442688 - Train Accuracy: 0.7206792136908257 - Validation Accuracy: 0.7165398634929178\n",
            "Epoch 36/50 :\n",
            "Train Loss: 0.5737406015396118 - Validation Loss: 0.5780719518661499 - Train Accuracy: 0.7205106878030748 - Validation Accuracy: 0.716857890745407\n",
            "Epoch 37/50 :\n",
            "Train Loss: 0.5749121904373169 - Validation Loss: 0.580764889717102 - Train Accuracy: 0.7193391610672581 - Validation Accuracy: 0.7155857817354503\n",
            "Epoch 38/50 :\n",
            "Train Loss: 0.5777572989463806 - Validation Loss: 0.5848093032836914 - Train Accuracy: 0.7187031117489725 - Validation Accuracy: 0.7118917728796145\n",
            "Epoch 39/50 :\n",
            "Train Loss: 0.581529974937439 - Validation Loss: 0.5909163951873779 - Train Accuracy: 0.7150172874942918 - Validation Accuracy: 0.7106196638696578\n",
            "Epoch 40/50 :\n",
            "Train Loss: 0.5878750681877136 - Validation Loss: 0.5884516835212708 - Train Accuracy: 0.7141012677495814 - Validation Accuracy: 0.7106441275044646\n",
            "Epoch 41/50 :\n",
            "Train Loss: 0.5850040912628174 - Validation Loss: 0.5816333889961243 - Train Accuracy: 0.7130275947550395 - Validation Accuracy: 0.7143625999951073\n",
            "Epoch 42/50 :\n",
            "Train Loss: 0.5784730911254883 - Validation Loss: 0.5758181810379028 - Train Accuracy: 0.7178333007154196 - Validation Accuracy: 0.7169312816498276\n",
            "Epoch 43/50 :\n",
            "Train Loss: 0.5723907351493835 - Validation Loss: 0.5800538063049316 - Train Accuracy: 0.7213234174875508 - Validation Accuracy: 0.7165643271277247\n",
            "Epoch 44/50 :\n",
            "Train Loss: 0.5765736103057861 - Validation Loss: 0.5839717388153076 - Train Accuracy: 0.718896101072042 - Validation Accuracy: 0.7135063727768672\n",
            "Epoch 45/50 :\n",
            "Train Loss: 0.5806963443756104 - Validation Loss: 0.5779482126235962 - Train Accuracy: 0.7170260073499032 - Validation Accuracy: 0.7173960907111578\n",
            "Epoch 46/50 :\n",
            "Train Loss: 0.5742943286895752 - Validation Loss: 0.5764856934547424 - Train Accuracy: 0.7200295735751407 - Validation Accuracy: 0.7171514543630892\n",
            "Epoch 47/50 :\n",
            "Train Loss: 0.5726966261863708 - Validation Loss: 0.5806750655174255 - Train Accuracy: 0.7211249918455216 - Validation Accuracy: 0.7146561636127896\n",
            "Epoch 48/50 :\n",
            "Train Loss: 0.577001690864563 - Validation Loss: 0.5790197849273682 - Train Accuracy: 0.7189613368995585 - Validation Accuracy: 0.7167355725713727\n",
            "Epoch 49/50 :\n",
            "Train Loss: 0.5750252604484558 - Validation Loss: 0.5758268237113953 - Train Accuracy: 0.719379933459456 - Validation Accuracy: 0.7166132543973384\n",
            "Epoch 50/50 :\n",
            "Train Loss: 0.5718241930007935 - Validation Loss: 0.5774713158607483 - Train Accuracy: 0.7214321438667449 - Validation Accuracy: 0.7157814908139051\n",
            "Epoch 1/50 :\n",
            "Train Loss: 0.57431960105896 - Validation Loss: 0.5718874335289001 - Train Accuracy: 0.7193717789810163 - Validation Accuracy: 0.7226802358294395\n",
            "Epoch 2/50 :\n",
            "Train Loss: 0.5752863883972168 - Validation Loss: 0.5694118142127991 - Train Accuracy: 0.7191271446278296 - Validation Accuracy: 0.7233407539692247\n",
            "Epoch 3/50 :\n",
            "Train Loss: 0.5730454325675964 - Validation Loss: 0.5688520669937134 - Train Accuracy: 0.7204889425272359 - Validation Accuracy: 0.7237077084913276\n",
            "Epoch 4/50 :\n",
            "Train Loss: 0.5722951889038086 - Validation Loss: 0.5706914663314819 - Train Accuracy: 0.7207716311131407 - Validation Accuracy: 0.7228759449078944\n",
            "Epoch 5/50 :\n",
            "Train Loss: 0.5739261507987976 - Validation Loss: 0.5705438256263733 - Train Accuracy: 0.7198338660925914 - Validation Accuracy: 0.7231939721603836\n",
            "Epoch 6/50 :\n",
            "Train Loss: 0.5738288760185242 - Validation Loss: 0.5689560174942017 - Train Accuracy: 0.7199126927175071 - Validation Accuracy: 0.7229004085427013\n",
            "Epoch 7/50 :\n",
            "Train Loss: 0.5719301104545593 - Validation Loss: 0.5691658854484558 - Train Accuracy: 0.7209347206819319 - Validation Accuracy: 0.721921863150427\n",
            "Epoch 8/50 :\n",
            "Train Loss: 0.5720848441123962 - Validation Loss: 0.5704718232154846 - Train Accuracy: 0.7209537477982908 - Validation Accuracy: 0.7231450448907699\n",
            "Epoch 9/50 :\n",
            "Train Loss: 0.5732877850532532 - Validation Loss: 0.5700430274009705 - Train Accuracy: 0.720247026333529 - Validation Accuracy: 0.7222154267681092\n",
            "Epoch 10/50 :\n",
            "Train Loss: 0.5726282596588135 - Validation Loss: 0.568839430809021 - Train Accuracy: 0.7206302868201883 - Validation Accuracy: 0.7223622085769503\n",
            "Epoch 11/50 :\n",
            "Train Loss: 0.5714120268821716 - Validation Loss: 0.569061815738678 - Train Accuracy: 0.7213152630091113 - Validation Accuracy: 0.7228759449078944\n",
            "Epoch 12/50 :\n",
            "Train Loss: 0.571395754814148 - Validation Loss: 0.5699191093444824 - Train Accuracy: 0.7211902276730381 - Validation Accuracy: 0.72189739951562\n",
            "Epoch 13/50 :\n",
            "Train Loss: 0.5721114277839661 - Validation Loss: 0.5700706839561462 - Train Accuracy: 0.7209537477982908 - Validation Accuracy: 0.7230471903515424\n",
            "Epoch 14/50 :\n",
            "Train Loss: 0.572182834148407 - Validation Loss: 0.5693925023078918 - Train Accuracy: 0.7207960945484594 - Validation Accuracy: 0.7234141448736453\n",
            "Epoch 15/50 :\n",
            "Train Loss: 0.5712977647781372 - Validation Loss: 0.5688347220420837 - Train Accuracy: 0.7211684823971992 - Validation Accuracy: 0.7220197176896543\n",
            "Epoch 16/50 :\n",
            "Train Loss: 0.5707358121871948 - Validation Loss: 0.5692649483680725 - Train Accuracy: 0.7217719138017266 - Validation Accuracy: 0.7228025540034738\n",
            "Epoch 17/50 :\n",
            "Train Loss: 0.570974588394165 - Validation Loss: 0.5697417855262756 - Train Accuracy: 0.7213777806771479 - Validation Accuracy: 0.7227291630990532\n",
            "Epoch 18/50 :\n",
            "Train Loss: 0.5713319182395935 - Validation Loss: 0.5697113275527954 - Train Accuracy: 0.7211902276730381 - Validation Accuracy: 0.7229248721775081\n",
            "Epoch 19/50 :\n",
            "Train Loss: 0.5711895823478699 - Validation Loss: 0.5693588256835938 - Train Accuracy: 0.7212636179789941 - Validation Accuracy: 0.7223377449421435\n",
            "Epoch 20/50 :\n",
            "Train Loss: 0.5706176161766052 - Validation Loss: 0.5690421462059021 - Train Accuracy: 0.7213179811685911 - Validation Accuracy: 0.7217016904371651\n",
            "Epoch 21/50 :\n",
            "Train Loss: 0.570245087146759 - Validation Loss: 0.5692717432975769 - Train Accuracy: 0.7218588949050818 - Validation Accuracy: 0.7221175722288817\n",
            "Epoch 22/50 :\n",
            "Train Loss: 0.5702616572380066 - Validation Loss: 0.5695798993110657 - Train Accuracy: 0.7218126861939244 - Validation Accuracy: 0.7210167086625731\n",
            "Epoch 23/50 :\n",
            "Train Loss: 0.5704537034034729 - Validation Loss: 0.5697707533836365 - Train Accuracy: 0.7215327157674996 - Validation Accuracy: 0.7221909631333023\n",
            "Epoch 24/50 :\n",
            "Train Loss: 0.5705442428588867 - Validation Loss: 0.5697892308235168 - Train Accuracy: 0.7217202687716093 - Validation Accuracy: 0.7215793722631308\n",
            "Epoch 25/50 :\n",
            "Train Loss: 0.5703598260879517 - Validation Loss: 0.569469690322876 - Train Accuracy: 0.7216142605518951 - Validation Accuracy: 0.7210167086625731\n",
            "Epoch 26/50 :\n",
            "Train Loss: 0.5700418949127197 - Validation Loss: 0.5693814754486084 - Train Accuracy: 0.7219513123273968 - Validation Accuracy: 0.7226313085598258\n",
            "Epoch 27/50 :\n",
            "Train Loss: 0.5697306990623474 - Validation Loss: 0.5692399144172668 - Train Accuracy: 0.7219540304868767 - Validation Accuracy: 0.721726154071972\n",
            "Epoch 28/50 :\n",
            "Train Loss: 0.569554328918457 - Validation Loss: 0.5693621635437012 - Train Accuracy: 0.7221823558831844 - Validation Accuracy: 0.7216527631675514\n",
            "Epoch 29/50 :\n",
            "Train Loss: 0.5695164799690247 - Validation Loss: 0.5695605278015137 - Train Accuracy: 0.7221633287668254 - Validation Accuracy: 0.7211145632018006\n",
            "Epoch 30/50 :\n",
            "Train Loss: 0.5695600509643555 - Validation Loss: 0.5696779489517212 - Train Accuracy: 0.7220845021419097 - Validation Accuracy: 0.7209922450277663\n",
            "Epoch 31/50 :\n",
            "Train Loss: 0.5696341395378113 - Validation Loss: 0.5699378848075867 - Train Accuracy: 0.7222149737969427 - Validation Accuracy: 0.7222643540377229\n",
            "Epoch 32/50 :\n",
            "Train Loss: 0.5696702003479004 - Validation Loss: 0.5699264407157898 - Train Accuracy: 0.7219730576032357 - Validation Accuracy: 0.7214570540890965\n",
            "Epoch 33/50 :\n",
            "Train Loss: 0.5696726441383362 - Validation Loss: 0.5700864195823669 - Train Accuracy: 0.7221443016504664 - Validation Accuracy: 0.7219463267852337\n",
            "Epoch 34/50 :\n",
            "Train Loss: 0.569602906703949 - Validation Loss: 0.5700451135635376 - Train Accuracy: 0.7220002391980342 - Validation Accuracy: 0.7218484722460063\n",
            "Epoch 35/50 :\n",
            "Train Loss: 0.5695431232452393 - Validation Loss: 0.5701298117637634 - Train Accuracy: 0.7221823558831844 - Validation Accuracy: 0.7213102722802553\n",
            "Epoch 36/50 :\n",
            "Train Loss: 0.5694538950920105 - Validation Loss: 0.5701664686203003 - Train Accuracy: 0.7220953747798291 - Validation Accuracy: 0.7219707904200406\n",
            "Epoch 37/50 :\n",
            "Train Loss: 0.5694186687469482 - Validation Loss: 0.5702307820320129 - Train Accuracy: 0.7222530280296605 - Validation Accuracy: 0.7211390268366074\n",
            "Epoch 38/50 :\n",
            "Train Loss: 0.569366455078125 - Validation Loss: 0.5703470706939697 - Train Accuracy: 0.7222503098701807 - Validation Accuracy: 0.7216038358979378\n",
            "Epoch 39/50 :\n",
            "Train Loss: 0.5693961977958679 - Validation Loss: 0.5704778432846069 - Train Accuracy: 0.7222611825081001 - Validation Accuracy: 0.7209188541233457\n",
            "Epoch 40/50 :\n",
            "Train Loss: 0.5694243907928467 - Validation Loss: 0.5707096457481384 - Train Accuracy: 0.7222530280296605 - Validation Accuracy: 0.7220441813244612\n",
            "Epoch 41/50 :\n",
            "Train Loss: 0.5695886611938477 - Validation Loss: 0.5710405111312866 - Train Accuracy: 0.7220926566203493 - Validation Accuracy: 0.7208943904885388\n",
            "Epoch 42/50 :\n",
            "Train Loss: 0.5697787404060364 - Validation Loss: 0.5714960098266602 - Train Accuracy: 0.721820840672364 - Validation Accuracy: 0.7217506177067788\n",
            "Epoch 43/50 :\n",
            "Train Loss: 0.5702289342880249 - Validation Loss: 0.5721374154090881 - Train Accuracy: 0.7219241307325983 - Validation Accuracy: 0.7216527631675514\n",
            "Epoch 44/50 :\n",
            "Train Loss: 0.5706760883331299 - Validation Loss: 0.5728947520256042 - Train Accuracy: 0.7215734881596974 - Validation Accuracy: 0.7213102722802553\n",
            "Epoch 45/50 :\n",
            "Train Loss: 0.5715177655220032 - Validation Loss: 0.5735615491867065 - Train Accuracy: 0.7211793550351187 - Validation Accuracy: 0.7205274359664359\n",
            "Epoch 46/50 :\n",
            "Train Loss: 0.5719272494316101 - Validation Loss: 0.5739235281944275 - Train Accuracy: 0.7209211298845326 - Validation Accuracy: 0.7207231450448908\n",
            "Epoch 47/50 :\n",
            "Train Loss: 0.5724441409111023 - Validation Loss: 0.5733675956726074 - Train Accuracy: 0.7206085415443495 - Validation Accuracy: 0.7205274359664359\n",
            "Epoch 48/50 :\n",
            "Train Loss: 0.5716132521629333 - Validation Loss: 0.5720794796943665 - Train Accuracy: 0.7211413008024007 - Validation Accuracy: 0.7216527631675514\n",
            "Epoch 49/50 :\n",
            "Train Loss: 0.5704309344291687 - Validation Loss: 0.5705884695053101 - Train Accuracy: 0.7216468784656533 - Validation Accuracy: 0.7205029723316291\n",
            "Epoch 50/50 :\n",
            "Train Loss: 0.5687403082847595 - Validation Loss: 0.5697115063667297 - Train Accuracy: 0.7225764890077631 - Validation Accuracy: 0.721383663184676\n",
            "Epoch 1/50 :\n",
            "Train Loss: 0.5681726336479187 - Validation Loss: 0.5662810802459717 - Train Accuracy: 0.7230385761193381 - Validation Accuracy: 0.7225334540205984\n",
            "Epoch 2/50 :\n",
            "Train Loss: 0.5682047605514526 - Validation Loss: 0.5673178434371948 - Train Accuracy: 0.7228618957531476 - Validation Accuracy: 0.7202338723487536\n",
            "Epoch 3/50 :\n",
            "Train Loss: 0.5688697099685669 - Validation Loss: 0.5678095817565918 - Train Accuracy: 0.7226607519516385 - Validation Accuracy: 0.7221664994984955\n",
            "Epoch 4/50 :\n",
            "Train Loss: 0.5696110725402832 - Validation Loss: 0.5686333179473877 - Train Accuracy: 0.7222421553917412 - Validation Accuracy: 0.7198913814614576\n",
            "Epoch 5/50 :\n",
            "Train Loss: 0.5697510242462158 - Validation Loss: 0.5680567622184753 - Train Accuracy: 0.7223617544088546 - Validation Accuracy: 0.721383663184676\n",
            "Epoch 6/50 :\n",
            "Train Loss: 0.5695173144340515 - Validation Loss: 0.5679135322570801 - Train Accuracy: 0.722410681279492 - Validation Accuracy: 0.7196956723830027\n",
            "Epoch 7/50 :\n",
            "Train Loss: 0.5687186121940613 - Validation Loss: 0.567063570022583 - Train Accuracy: 0.7227721964903124 - Validation Accuracy: 0.7213102722802553\n",
            "Epoch 8/50 :\n",
            "Train Loss: 0.5679967403411865 - Validation Loss: 0.5669488310813904 - Train Accuracy: 0.7231608932959315 - Validation Accuracy: 0.7210167086625731\n",
            "Epoch 9/50 :\n",
            "Train Loss: 0.5675044059753418 - Validation Loss: 0.5669625401496887 - Train Accuracy: 0.7232723378346054 - Validation Accuracy: 0.7205763632360496\n",
            "Epoch 10/50 :\n",
            "Train Loss: 0.5673643350601196 - Validation Loss: 0.5671399235725403 - Train Accuracy: 0.7235523082610303 - Validation Accuracy: 0.721921863150427\n",
            "Epoch 11/50 :\n",
            "Train Loss: 0.5674998164176941 - Validation Loss: 0.5678175687789917 - Train Accuracy: 0.7232424380803271 - Validation Accuracy: 0.7200870905399124\n",
            "Epoch 12/50 :\n",
            "Train Loss: 0.5677777528762817 - Validation Loss: 0.5680620670318604 - Train Accuracy: 0.7233022375888838 - Validation Accuracy: 0.7208209995841182\n",
            "Epoch 13/50 :\n",
            "Train Loss: 0.5681958198547363 - Validation Loss: 0.56905597448349 - Train Accuracy: 0.7230929393089351 - Validation Accuracy: 0.7188394451647626\n",
            "Epoch 14/50 :\n",
            "Train Loss: 0.5686072707176208 - Validation Loss: 0.5694211721420288 - Train Accuracy: 0.7227939417661513 - Validation Accuracy: 0.7206986814100839\n",
            "Epoch 15/50 :\n",
            "Train Loss: 0.5692850947380066 - Validation Loss: 0.5706372857093811 - Train Accuracy: 0.7227477330549938 - Validation Accuracy: 0.7194265724001272\n",
            "Epoch 16/50 :\n",
            "Train Loss: 0.569797158241272 - Validation Loss: 0.5709847807884216 - Train Accuracy: 0.72207906582295 - Validation Accuracy: 0.7202094087139467\n",
            "Epoch 17/50 :\n",
            "Train Loss: 0.5706414580345154 - Validation Loss: 0.5718114972114563 - Train Accuracy: 0.7217855045991258 - Validation Accuracy: 0.718056608850943\n",
            "Epoch 18/50 :\n",
            "Train Loss: 0.5706438422203064 - Validation Loss: 0.5712816119194031 - Train Accuracy: 0.7217990953965251 - Validation Accuracy: 0.7196222814785821\n",
            "Epoch 19/50 :\n",
            "Train Loss: 0.5706601142883301 - Validation Loss: 0.5707639455795288 - Train Accuracy: 0.7218969491377998 - Validation Accuracy: 0.7187171269907283\n",
            "Epoch 20/50 :\n",
            "Train Loss: 0.5693879127502441 - Validation Loss: 0.5690493583679199 - Train Accuracy: 0.722595516124122 - Validation Accuracy: 0.7202094087139467\n",
            "Epoch 21/50 :\n",
            "Train Loss: 0.5680075287818909 - Validation Loss: 0.5681567788124084 - Train Accuracy: 0.723022267162459 - Validation Accuracy: 0.7198669178266507\n",
            "Epoch 22/50 :\n",
            "Train Loss: 0.5667515993118286 - Validation Loss: 0.5678941607475281 - Train Accuracy: 0.7239681866614478 - Validation Accuracy: 0.7208454632189251\n",
            "Epoch 23/50 :\n",
            "Train Loss: 0.5663911700248718 - Validation Loss: 0.5683156847953796 - Train Accuracy: 0.7240171135320852 - Validation Accuracy: 0.7207965359493114\n",
            "Epoch 24/50 :\n",
            "Train Loss: 0.5668726563453674 - Validation Loss: 0.5695635676383972 - Train Accuracy: 0.7236392893643856 - Validation Accuracy: 0.7182523179293979\n",
            "Epoch 25/50 :\n",
            "Train Loss: 0.5676146149635315 - Validation Loss: 0.5699104070663452 - Train Accuracy: 0.7233756278948399 - Validation Accuracy: 0.7198913814614576\n",
            "Epoch 26/50 :\n",
            "Train Loss: 0.5682520866394043 - Validation Loss: 0.570499837398529 - Train Accuracy: 0.7231201209037337 - Validation Accuracy: 0.7183012451990116\n",
            "Epoch 27/50 :\n",
            "Train Loss: 0.5682189464569092 - Validation Loss: 0.5698665976524353 - Train Accuracy: 0.7230249853219388 - Validation Accuracy: 0.7198913814614576\n",
            "Epoch 28/50 :\n",
            "Train Loss: 0.5678883790969849 - Validation Loss: 0.5696117877960205 - Train Accuracy: 0.7232832104725249 - Validation Accuracy: 0.7184969542774665\n",
            "Epoch 29/50 :\n",
            "Train Loss: 0.5671162605285645 - Validation Loss: 0.5687429308891296 - Train Accuracy: 0.7236447256833453 - Validation Accuracy: 0.7203561905227879\n",
            "Epoch 30/50 :\n",
            "Train Loss: 0.566422700881958 - Validation Loss: 0.5685498714447021 - Train Accuracy: 0.7237751973383783 - Validation Accuracy: 0.7200381632702987\n",
            "Epoch 31/50 :\n",
            "Train Loss: 0.5658988952636719 - Validation Loss: 0.5683379769325256 - Train Accuracy: 0.7243378563507078 - Validation Accuracy: 0.7198669178266507\n",
            "Epoch 32/50 :\n",
            "Train Loss: 0.5656808018684387 - Validation Loss: 0.5684710144996643 - Train Accuracy: 0.7244955096005393 - Validation Accuracy: 0.720160481444333\n",
            "Epoch 33/50 :\n",
            "Train Loss: 0.5657188892364502 - Validation Loss: 0.5688963532447815 - Train Accuracy: 0.7243541653075869 - Validation Accuracy: 0.7195978178437752\n",
            "Epoch 34/50 :\n",
            "Train Loss: 0.5659264922142029 - Validation Loss: 0.5690881013870239 - Train Accuracy: 0.7242101028551547 - Validation Accuracy: 0.7206497541404702\n",
            "Epoch 35/50 :\n",
            "Train Loss: 0.5662797093391418 - Validation Loss: 0.5699726343154907 - Train Accuracy: 0.7240877856785614 - Validation Accuracy: 0.7186681997211145\n",
            "Epoch 36/50 :\n",
            "Train Loss: 0.566709578037262 - Validation Loss: 0.5702998638153076 - Train Accuracy: 0.7239844956183269 - Validation Accuracy: 0.7196222814785821\n",
            "Epoch 37/50 :\n",
            "Train Loss: 0.5674194693565369 - Validation Loss: 0.571641206741333 - Train Accuracy: 0.7236066714506274 - Validation Accuracy: 0.7179587543117156\n",
            "Epoch 38/50 :\n",
            "Train Loss: 0.5680776238441467 - Validation Loss: 0.5722776055335999 - Train Accuracy: 0.7232206928044882 - Validation Accuracy: 0.7192553269564792\n",
            "Epoch 39/50 :\n",
            "Train Loss: 0.5692873001098633 - Validation Loss: 0.573718786239624 - Train Accuracy: 0.7225737708482832 - Validation Accuracy: 0.7157080999094846\n",
            "Epoch 40/50 :\n",
            "Train Loss: 0.5698996782302856 - Validation Loss: 0.57399582862854 - Train Accuracy: 0.7221986648400635 - Validation Accuracy: 0.718766054260342\n",
            "Epoch 41/50 :\n",
            "Train Loss: 0.5708503723144531 - Validation Loss: 0.5738190412521362 - Train Accuracy: 0.7216849326983713 - Validation Accuracy: 0.7156591726398708\n",
            "Epoch 42/50 :\n",
            "Train Loss: 0.56989586353302 - Validation Loss: 0.5718362331390381 - Train Accuracy: 0.7221986648400635 - Validation Accuracy: 0.7190106906084106\n",
            "Epoch 43/50 :\n",
            "Train Loss: 0.5684254765510559 - Validation Loss: 0.569982647895813 - Train Accuracy: 0.7228319959988693 - Validation Accuracy: 0.7183746361034322\n",
            "Epoch 44/50 :\n",
            "Train Loss: 0.566114604473114 - Validation Loss: 0.5687173008918762 - Train Accuracy: 0.7242807750016309 - Validation Accuracy: 0.7202827996183673\n",
            "Epoch 45/50 :\n",
            "Train Loss: 0.5649294257164001 - Validation Loss: 0.5691478848457336 - Train Accuracy: 0.72503642333703 - Validation Accuracy: 0.7203806541575948\n",
            "Epoch 46/50 :\n",
            "Train Loss: 0.5653253197669983 - Validation Loss: 0.5706659555435181 - Train Accuracy: 0.7245091003979386 - Validation Accuracy: 0.7171025270934756\n",
            "Epoch 47/50 :\n",
            "Train Loss: 0.5664632320404053 - Validation Loss: 0.5712111592292786 - Train Accuracy: 0.7241475851871181 - Validation Accuracy: 0.7187415906255351\n",
            "Epoch 48/50 :\n",
            "Train Loss: 0.5673272013664246 - Validation Loss: 0.571429967880249 - Train Accuracy: 0.7235903624937482 - Validation Accuracy: 0.7174205543459647\n",
            "Epoch 49/50 :\n",
            "Train Loss: 0.5669428110122681 - Validation Loss: 0.5701932311058044 - Train Accuracy: 0.7239627503424881 - Validation Accuracy: 0.7198669178266507\n",
            "Epoch 50/50 :\n",
            "Train Loss: 0.566082239151001 - Validation Loss: 0.5696067214012146 - Train Accuracy: 0.7243297018722682 - Validation Accuracy: 0.7185703451818871\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Plotting the losses\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(train_loss, label='Train Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plotting the accuracies\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(train_accuracy, label='Train Accuracy')\n",
        "plt.plot(val_accuracy, label='Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 957
        },
        "id": "KO6yjMr_oKcV",
        "outputId": "fbd67cfd-b77f-4c6d-85b3-654cad9bb2c6"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "biopy",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}