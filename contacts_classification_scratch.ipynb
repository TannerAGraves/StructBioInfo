{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ewVXNIEM7IV_",
        "outputId": "921ed94f-72b9-47ff-df94-fbec982de685",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.1.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.6.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n"
          ]
        }
      ],
      "source": [
        "!pip3 install scikit-learn\n",
        "!pip3 install torch\n",
        "!pip3 install torchinfo\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "AKx-1SDs7IWH",
        "outputId": "a6992666-c74d-43b9-d71e-eb5fd8e86d08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-colab in /usr/local/lib/python3.10/dist-packages (1.0.0)\n",
            "Requirement already satisfied: google-auth==2.17.3 in /usr/local/lib/python3.10/dist-packages (from google-colab) (2.17.3)\n",
            "Requirement already satisfied: ipykernel==5.5.6 in /usr/local/lib/python3.10/dist-packages (from google-colab) (5.5.6)\n",
            "Requirement already satisfied: ipython==7.34.0 in /usr/local/lib/python3.10/dist-packages (from google-colab) (7.34.0)\n",
            "Requirement already satisfied: notebook==6.4.8 in /usr/local/lib/python3.10/dist-packages (from google-colab) (6.4.8)\n",
            "Requirement already satisfied: pandas==1.5.3 in /usr/local/lib/python3.10/dist-packages (from google-colab) (1.5.3)\n",
            "Requirement already satisfied: portpicker==1.5.2 in /usr/local/lib/python3.10/dist-packages (from google-colab) (1.5.2)\n",
            "Requirement already satisfied: requests==2.27.1 in /usr/local/lib/python3.10/dist-packages (from google-colab) (2.27.1)\n",
            "Requirement already satisfied: tornado==6.3.1 in /usr/local/lib/python3.10/dist-packages (from google-colab) (6.3.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth==2.17.3->google-colab) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth==2.17.3->google-colab) (0.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth==2.17.3->google-colab) (1.16.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth==2.17.3->google-colab) (4.9)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.10/dist-packages (from ipykernel==5.5.6->google-colab) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel==5.5.6->google-colab) (5.7.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel==5.5.6->google-colab) (6.1.12)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython==7.34.0->google-colab) (67.7.2)\n",
            "Collecting jedi>=0.16 (from ipython==7.34.0->google-colab)\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython==7.34.0->google-colab) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython==7.34.0->google-colab) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython==7.34.0->google-colab) (3.0.38)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython==7.34.0->google-colab) (2.14.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython==7.34.0->google-colab) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython==7.34.0->google-colab) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython==7.34.0->google-colab) (4.8.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from notebook==6.4.8->google-colab) (3.1.2)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.10/dist-packages (from notebook==6.4.8->google-colab) (23.2.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook==6.4.8->google-colab) (21.3.0)\n",
            "Requirement already satisfied: jupyter-core>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from notebook==6.4.8->google-colab) (5.3.1)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from notebook==6.4.8->google-colab) (5.9.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.10/dist-packages (from notebook==6.4.8->google-colab) (6.5.4)\n",
            "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook==6.4.8->google-colab) (1.5.6)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook==6.4.8->google-colab) (1.8.2)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook==6.4.8->google-colab) (0.17.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook==6.4.8->google-colab) (0.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas==1.5.3->google-colab) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas==1.5.3->google-colab) (2022.7.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas==1.5.3->google-colab) (1.22.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from portpicker==1.5.2->google-colab) (5.9.5)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests==2.27.1->google-colab) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests==2.27.1->google-colab) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests==2.27.1->google-colab) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests==2.27.1->google-colab) (3.4)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython==7.34.0->google-colab) (0.8.3)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.6.1->notebook==6.4.8->google-colab) (3.7.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython==7.34.0->google-colab) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython==7.34.0->google-colab) (0.2.6)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth==2.17.3->google-colab) (0.5.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook==6.4.8->google-colab) (21.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->notebook==6.4.8->google-colab) (2.1.3)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nbconvert->notebook==6.4.8->google-colab) (4.9.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert->notebook==6.4.8->google-colab) (4.11.2)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from nbconvert->notebook==6.4.8->google-colab) (6.0.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert->notebook==6.4.8->google-colab) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert->notebook==6.4.8->google-colab) (0.4)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert->notebook==6.4.8->google-colab) (0.2.2)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->notebook==6.4.8->google-colab) (0.8.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert->notebook==6.4.8->google-colab) (0.8.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from nbconvert->notebook==6.4.8->google-colab) (23.1)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->notebook==6.4.8->google-colab) (1.5.0)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert->notebook==6.4.8->google-colab) (1.2.1)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook==6.4.8->google-colab) (2.17.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook==6.4.8->google-colab) (4.3.3)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook==6.4.8->google-colab) (23.1.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook==6.4.8->google-colab) (0.19.3)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook==6.4.8->google-colab) (1.15.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert->notebook==6.4.8->google-colab) (2.4.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->nbconvert->notebook==6.4.8->google-colab) (0.5.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook==6.4.8->google-colab) (2.21)\n",
            "Installing collected packages: jedi\n",
            "Successfully installed jedi-0.18.2\n"
          ]
        }
      ],
      "source": [
        "!pip3 install google-colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "i1nJM4827IWE"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchinfo import summary\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "_GVRc7Ky7IWG",
        "outputId": "f048a4be-20aa-4d0c-c0c6-a529daa72a70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-fc9aba1876fc>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# only for running locally\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'features_ring'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'.tsv'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mdfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'features_ring/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'features_ring'"
          ]
        }
      ],
      "source": [
        "# only for running locally\n",
        "dfs = []\n",
        "for filename in os.listdir('features_ring'):\n",
        "    if filename[-4:] == '.tsv':\n",
        "        dfs.append(pd.read_csv('features_ring/' + filename, sep='\\t'))\n",
        "df = pd.concat(dfs)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "rmKCVbWQ7IWG",
        "outputId": "6ba5d29d-3053-489e-fb00-b703a129a1e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-d8f7e0c96dbd>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# don't need to execute - only to export df for training in cloud\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'contact_df.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ],
      "source": [
        "# don't need to execute - only to export df for training in cloud\n",
        "df.to_csv('contact_df.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "FO0jpYz27IWI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1805a2d9-ec7e-4d6a-fdd0-611c219b8701"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# only for running on drive for training\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "df = pd.read_csv('drive/MyDrive/StructuralBioinformatics/data/contact_df.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "PcBk80rJ7IWI",
        "outputId": "df01a244-cf21-421d-e14f-a73ed7185478",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0               VDW\n",
              "1             HBOND\n",
              "2             HBOND\n",
              "3         PIPISTACK\n",
              "4             HBOND\n",
              "            ...    \n",
              "454188          VDW\n",
              "454189        HBOND\n",
              "454190          VDW\n",
              "454191        HBOND\n",
              "454192        HBOND\n",
              "Name: Interaction, Length: 454193, dtype: category\n",
              "Categories (6, object): ['HBOND', 'IONIC', 'PICATION', 'PIPISTACK', 'SSBOND', 'VDW']"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "df.dropna(inplace=True)\n",
        "\n",
        "# Define ground truth values\n",
        "y = df['Interaction'].astype('category')\n",
        "y_oneHot = pd.get_dummies(y)\n",
        "y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "God_1B2t7IWJ",
        "outputId": "e43a6a16-d6f4-4f1f-8ab7-fc2dfcd216d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           s_rsa      s_up    s_down     s_phi     s_psi      s_a1      s_a2  \\\n",
              "0      -0.612926  1.212548  1.272426 -0.080637  1.435561  1.032979  0.438314   \n",
              "1       0.235709  0.077481 -0.558473  0.268180 -0.783304  1.337499 -1.430106   \n",
              "2       1.797971 -1.341352 -0.009203  0.266785 -0.772920  0.928827  0.998308   \n",
              "3      -0.096994  1.070665 -0.741563 -1.206618  1.219451 -1.006413 -0.511333   \n",
              "4      -0.096994  1.070665 -0.741563 -1.206618  1.219451 -1.006413 -0.511333   \n",
              "...          ...       ...       ...       ...       ...       ...       ...   \n",
              "454188  1.161494 -2.050769  0.173887 -0.373643 -0.294621 -0.389438  1.875560   \n",
              "454189 -0.786511  0.503131 -0.558473  0.021218  1.453084 -1.006413 -0.511333   \n",
              "454190 -0.878125  0.645015 -0.009203 -0.975003  1.163638 -1.237531 -0.465554   \n",
              "454191  1.682248 -1.341352 -1.107742 -1.269405 -0.158335  1.807671 -0.480459   \n",
              "454192  1.209712 -1.341352  0.906247  0.183069  1.325884 -1.019308 -0.933990   \n",
              "\n",
              "            s_a3      s_a4      s_a5     t_rsa      t_up    t_down     t_phi  \\\n",
              "0      -1.675155 -0.535573 -1.967293 -0.926898  0.482516  1.366067 -1.502723   \n",
              "1       0.702567 -0.124882 -0.467409 -0.118231 -0.267989 -0.712127  0.257241   \n",
              "2       0.620114 -0.436212  0.636456  1.398591 -1.318697  0.500153  0.283161   \n",
              "3       0.894341 -0.687926  0.311533 -0.926898  0.932819  1.192884 -1.816354   \n",
              "4       0.894341 -0.687926  0.311533 -0.926898  0.932819  1.192884 -1.816354   \n",
              "...          ...       ...       ...       ...       ...       ...       ...   \n",
              "454188  0.634473  0.904054  1.341807  0.854911 -1.618899  1.019702  0.564392   \n",
              "454189  0.894341 -0.687926  0.311533  1.901152 -2.219303 -0.538944  4.190592   \n",
              "454190  1.005515  0.184240  0.563489 -0.433474  1.082920 -1.404858 -1.406819   \n",
              "454191  0.265285 -0.555445  1.082368  2.335182 -2.369404 -1.058493  3.708481   \n",
              "454192 -0.678763  1.148039 -0.514183 -0.675617  0.482516  1.192884 -0.590341   \n",
              "\n",
              "           t_psi      t_a1      t_a2      t_a3      t_a4      t_a5  \n",
              "0       1.362867 -0.045132  0.558611  1.029760  0.741296  0.813673  \n",
              "1      -0.791289  1.476577  0.135358  0.690168  0.232221  1.818554  \n",
              "2      -0.812362  1.003587  0.531949 -1.773429 -0.528128 -2.075994  \n",
              "3       1.560677 -0.989173 -0.458974  0.875965 -0.678240  0.242084  \n",
              "4       1.560677 -0.989173 -0.458974  0.875965 -0.678240  0.242084  \n",
              "...          ...       ...       ...       ...       ...       ...  \n",
              "454188 -0.796048 -1.001773 -0.900002 -0.746055  1.130717 -0.597855  \n",
              "454189 -0.494914 -0.386305  2.031665  0.608016  0.890320  1.290104  \n",
              "454190  1.223517  0.237886  1.118505  1.451982 -1.157946  0.939918  \n",
              "454191 -0.372558 -0.386305  2.031665  0.608016  0.890320  1.290104  \n",
              "454192 -0.099295  1.003587  0.531949 -1.773429 -0.528128 -2.075994  \n",
              "\n",
              "[454193 rows x 20 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-090f714a-abc6-4835-816a-ff057f5e17af\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>s_rsa</th>\n",
              "      <th>s_up</th>\n",
              "      <th>s_down</th>\n",
              "      <th>s_phi</th>\n",
              "      <th>s_psi</th>\n",
              "      <th>s_a1</th>\n",
              "      <th>s_a2</th>\n",
              "      <th>s_a3</th>\n",
              "      <th>s_a4</th>\n",
              "      <th>s_a5</th>\n",
              "      <th>t_rsa</th>\n",
              "      <th>t_up</th>\n",
              "      <th>t_down</th>\n",
              "      <th>t_phi</th>\n",
              "      <th>t_psi</th>\n",
              "      <th>t_a1</th>\n",
              "      <th>t_a2</th>\n",
              "      <th>t_a3</th>\n",
              "      <th>t_a4</th>\n",
              "      <th>t_a5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.612926</td>\n",
              "      <td>1.212548</td>\n",
              "      <td>1.272426</td>\n",
              "      <td>-0.080637</td>\n",
              "      <td>1.435561</td>\n",
              "      <td>1.032979</td>\n",
              "      <td>0.438314</td>\n",
              "      <td>-1.675155</td>\n",
              "      <td>-0.535573</td>\n",
              "      <td>-1.967293</td>\n",
              "      <td>-0.926898</td>\n",
              "      <td>0.482516</td>\n",
              "      <td>1.366067</td>\n",
              "      <td>-1.502723</td>\n",
              "      <td>1.362867</td>\n",
              "      <td>-0.045132</td>\n",
              "      <td>0.558611</td>\n",
              "      <td>1.029760</td>\n",
              "      <td>0.741296</td>\n",
              "      <td>0.813673</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.235709</td>\n",
              "      <td>0.077481</td>\n",
              "      <td>-0.558473</td>\n",
              "      <td>0.268180</td>\n",
              "      <td>-0.783304</td>\n",
              "      <td>1.337499</td>\n",
              "      <td>-1.430106</td>\n",
              "      <td>0.702567</td>\n",
              "      <td>-0.124882</td>\n",
              "      <td>-0.467409</td>\n",
              "      <td>-0.118231</td>\n",
              "      <td>-0.267989</td>\n",
              "      <td>-0.712127</td>\n",
              "      <td>0.257241</td>\n",
              "      <td>-0.791289</td>\n",
              "      <td>1.476577</td>\n",
              "      <td>0.135358</td>\n",
              "      <td>0.690168</td>\n",
              "      <td>0.232221</td>\n",
              "      <td>1.818554</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.797971</td>\n",
              "      <td>-1.341352</td>\n",
              "      <td>-0.009203</td>\n",
              "      <td>0.266785</td>\n",
              "      <td>-0.772920</td>\n",
              "      <td>0.928827</td>\n",
              "      <td>0.998308</td>\n",
              "      <td>0.620114</td>\n",
              "      <td>-0.436212</td>\n",
              "      <td>0.636456</td>\n",
              "      <td>1.398591</td>\n",
              "      <td>-1.318697</td>\n",
              "      <td>0.500153</td>\n",
              "      <td>0.283161</td>\n",
              "      <td>-0.812362</td>\n",
              "      <td>1.003587</td>\n",
              "      <td>0.531949</td>\n",
              "      <td>-1.773429</td>\n",
              "      <td>-0.528128</td>\n",
              "      <td>-2.075994</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.096994</td>\n",
              "      <td>1.070665</td>\n",
              "      <td>-0.741563</td>\n",
              "      <td>-1.206618</td>\n",
              "      <td>1.219451</td>\n",
              "      <td>-1.006413</td>\n",
              "      <td>-0.511333</td>\n",
              "      <td>0.894341</td>\n",
              "      <td>-0.687926</td>\n",
              "      <td>0.311533</td>\n",
              "      <td>-0.926898</td>\n",
              "      <td>0.932819</td>\n",
              "      <td>1.192884</td>\n",
              "      <td>-1.816354</td>\n",
              "      <td>1.560677</td>\n",
              "      <td>-0.989173</td>\n",
              "      <td>-0.458974</td>\n",
              "      <td>0.875965</td>\n",
              "      <td>-0.678240</td>\n",
              "      <td>0.242084</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.096994</td>\n",
              "      <td>1.070665</td>\n",
              "      <td>-0.741563</td>\n",
              "      <td>-1.206618</td>\n",
              "      <td>1.219451</td>\n",
              "      <td>-1.006413</td>\n",
              "      <td>-0.511333</td>\n",
              "      <td>0.894341</td>\n",
              "      <td>-0.687926</td>\n",
              "      <td>0.311533</td>\n",
              "      <td>-0.926898</td>\n",
              "      <td>0.932819</td>\n",
              "      <td>1.192884</td>\n",
              "      <td>-1.816354</td>\n",
              "      <td>1.560677</td>\n",
              "      <td>-0.989173</td>\n",
              "      <td>-0.458974</td>\n",
              "      <td>0.875965</td>\n",
              "      <td>-0.678240</td>\n",
              "      <td>0.242084</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>454188</th>\n",
              "      <td>1.161494</td>\n",
              "      <td>-2.050769</td>\n",
              "      <td>0.173887</td>\n",
              "      <td>-0.373643</td>\n",
              "      <td>-0.294621</td>\n",
              "      <td>-0.389438</td>\n",
              "      <td>1.875560</td>\n",
              "      <td>0.634473</td>\n",
              "      <td>0.904054</td>\n",
              "      <td>1.341807</td>\n",
              "      <td>0.854911</td>\n",
              "      <td>-1.618899</td>\n",
              "      <td>1.019702</td>\n",
              "      <td>0.564392</td>\n",
              "      <td>-0.796048</td>\n",
              "      <td>-1.001773</td>\n",
              "      <td>-0.900002</td>\n",
              "      <td>-0.746055</td>\n",
              "      <td>1.130717</td>\n",
              "      <td>-0.597855</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>454189</th>\n",
              "      <td>-0.786511</td>\n",
              "      <td>0.503131</td>\n",
              "      <td>-0.558473</td>\n",
              "      <td>0.021218</td>\n",
              "      <td>1.453084</td>\n",
              "      <td>-1.006413</td>\n",
              "      <td>-0.511333</td>\n",
              "      <td>0.894341</td>\n",
              "      <td>-0.687926</td>\n",
              "      <td>0.311533</td>\n",
              "      <td>1.901152</td>\n",
              "      <td>-2.219303</td>\n",
              "      <td>-0.538944</td>\n",
              "      <td>4.190592</td>\n",
              "      <td>-0.494914</td>\n",
              "      <td>-0.386305</td>\n",
              "      <td>2.031665</td>\n",
              "      <td>0.608016</td>\n",
              "      <td>0.890320</td>\n",
              "      <td>1.290104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>454190</th>\n",
              "      <td>-0.878125</td>\n",
              "      <td>0.645015</td>\n",
              "      <td>-0.009203</td>\n",
              "      <td>-0.975003</td>\n",
              "      <td>1.163638</td>\n",
              "      <td>-1.237531</td>\n",
              "      <td>-0.465554</td>\n",
              "      <td>1.005515</td>\n",
              "      <td>0.184240</td>\n",
              "      <td>0.563489</td>\n",
              "      <td>-0.433474</td>\n",
              "      <td>1.082920</td>\n",
              "      <td>-1.404858</td>\n",
              "      <td>-1.406819</td>\n",
              "      <td>1.223517</td>\n",
              "      <td>0.237886</td>\n",
              "      <td>1.118505</td>\n",
              "      <td>1.451982</td>\n",
              "      <td>-1.157946</td>\n",
              "      <td>0.939918</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>454191</th>\n",
              "      <td>1.682248</td>\n",
              "      <td>-1.341352</td>\n",
              "      <td>-1.107742</td>\n",
              "      <td>-1.269405</td>\n",
              "      <td>-0.158335</td>\n",
              "      <td>1.807671</td>\n",
              "      <td>-0.480459</td>\n",
              "      <td>0.265285</td>\n",
              "      <td>-0.555445</td>\n",
              "      <td>1.082368</td>\n",
              "      <td>2.335182</td>\n",
              "      <td>-2.369404</td>\n",
              "      <td>-1.058493</td>\n",
              "      <td>3.708481</td>\n",
              "      <td>-0.372558</td>\n",
              "      <td>-0.386305</td>\n",
              "      <td>2.031665</td>\n",
              "      <td>0.608016</td>\n",
              "      <td>0.890320</td>\n",
              "      <td>1.290104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>454192</th>\n",
              "      <td>1.209712</td>\n",
              "      <td>-1.341352</td>\n",
              "      <td>0.906247</td>\n",
              "      <td>0.183069</td>\n",
              "      <td>1.325884</td>\n",
              "      <td>-1.019308</td>\n",
              "      <td>-0.933990</td>\n",
              "      <td>-0.678763</td>\n",
              "      <td>1.148039</td>\n",
              "      <td>-0.514183</td>\n",
              "      <td>-0.675617</td>\n",
              "      <td>0.482516</td>\n",
              "      <td>1.192884</td>\n",
              "      <td>-0.590341</td>\n",
              "      <td>-0.099295</td>\n",
              "      <td>1.003587</td>\n",
              "      <td>0.531949</td>\n",
              "      <td>-1.773429</td>\n",
              "      <td>-0.528128</td>\n",
              "      <td>-2.075994</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>454193 rows × 20 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-090f714a-abc6-4835-816a-ff057f5e17af')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-090f714a-abc6-4835-816a-ff057f5e17af button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-090f714a-abc6-4835-816a-ff057f5e17af');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "# Define training features\n",
        "X = df[['s_rsa', 's_up', 's_down', 's_phi', 's_psi', 's_a1', 's_a2', 's_a3', 's_a4', 's_a5',\n",
        "        't_rsa', 't_up', 't_down', 't_phi', 't_psi', 't_a1', 't_a2', 't_a3', 't_a4', 't_a5']]\n",
        "\n",
        "#is this working?\n",
        "X = X.fillna({col: X[col].mode()[0] for col in X.columns})\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_scaled = pd.DataFrame(X_scaled, columns=X.columns)\n",
        "X_scaled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "tPxPV5w_7IWK"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_oneHot, test_size=0.1, random_state=0)\n",
        "kf = KFold(n_splits=10, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "u0Y845Xj7IWL",
        "outputId": "e2eacd05-d5a2-4552-e83f-b62c36b25f33",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "=================================================================\n",
              "Layer (type:depth-idx)                   Param #\n",
              "=================================================================\n",
              "ContactNet                               --\n",
              "├─ModuleList: 1-1                        --\n",
              "│    └─Linear: 2-1                       1,344\n",
              "│    └─Linear: 2-2                       4,160\n",
              "│    └─Linear: 2-3                       6,240\n",
              "│    └─Linear: 2-4                       9,312\n",
              "│    └─Linear: 2-5                       9,312\n",
              "│    └─Linear: 2-6                       12,416\n",
              "│    └─Linear: 2-7                       16,512\n",
              "│    └─Linear: 2-8                       16,512\n",
              "│    └─Linear: 2-9                       16,512\n",
              "│    └─Linear: 2-10                      774\n",
              "=================================================================\n",
              "Total params: 93,094\n",
              "Trainable params: 93,094\n",
              "Non-trainable params: 0\n",
              "================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "class ContactNet(nn.Module):\n",
        "    def __init__(self, input_dim, num_classes, hidden_layers_dim=[]):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList()\n",
        "        if len(hidden_layers_dim) == 0:\n",
        "            self.layers = self.layers.append(nn.Linear(input_dim, num_classes))\n",
        "        else:\n",
        "            for layer_idx in range(len(hidden_layers_dim)):\n",
        "                if layer_idx == 0:  # first layer, from input to hidden\n",
        "                    self.layers = self.layers.append(nn.Linear(input_dim, hidden_layers_dim[layer_idx]))\n",
        "                else:  # hidden layers, depending on the input\n",
        "                    self.layers = self.layers.append(nn.Linear(hidden_layers_dim[layer_idx-1], hidden_layers_dim[layer_idx]))\n",
        "            self.layers = self.layers.append(nn.Linear(hidden_layers_dim[-1], num_classes))  # final output layer\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, nn.Linear):\n",
        "            module.weight.data.normal_(mean=0.0, std=.1)\n",
        "            if module.bias is not None:\n",
        "                module.bias.data.zero_()\n",
        "\n",
        "    def forward(self, x):\n",
        "        if not isinstance(x, torch.Tensor):\n",
        "            x = torch.Tensor(x)\n",
        "        if x.dtype != torch.float32:\n",
        "            x = x.float()\n",
        "        if len(self.layers) == 1:\n",
        "            return self.layers[0](x)\n",
        "        else:\n",
        "            for layer in self.layers[:-1]:\n",
        "                x = F.relu(layer(x))\n",
        "        return F.log_softmax(x, dim=1)#self.layers[-1](x)\n",
        "\n",
        "input_size = X.shape[1]  # The number of input features\n",
        "num_classes = y_oneHot.shape[1] # The number of output classes\n",
        "\n",
        "model = ContactNet(input_size, num_classes, [64, 64, 96, 96, 96, 128, 128, 128, 128])\n",
        "\n",
        "# Criterion and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "\n",
        "summary(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "Ik79A97A7IWM"
      },
      "outputs": [],
      "source": [
        "class EarlyStopping:\n",
        "    def __init__(self, tolerance, min_delta):\n",
        "        self.tolerance = tolerance\n",
        "        self.min_delta = min_delta\n",
        "        self.counter = 0\n",
        "        self.early_stop = False\n",
        "\n",
        "    def __call__(self, train_loss, validation_loss):\n",
        "        if (validation_loss - train_loss) > self.min_delta:\n",
        "            self.counter +=1\n",
        "            if self.counter >= self.tolerance:\n",
        "                self.early_stop = True\n",
        "\n",
        "\n",
        "\n",
        "def train(model, optimizer, num_epochs):\n",
        "\n",
        "  early_stopping = EarlyStopping(tolerance=5, min_delta=0.01)\n",
        "\n",
        "  for train_index, val_index in kf.split(X_train):\n",
        "      X_train_fold = X_train.values[train_index]\n",
        "      y_train_fold = y_train.values[train_index]\n",
        "      X_val_fold = X_train.values[val_index]\n",
        "      y_val_fold = y_train.values[val_index]\n",
        "\n",
        "      for epoch in range(num_epochs):\n",
        "          out = model(torch.tensor(X_train_fold))\n",
        "          y_train_fold_labels = np.argmax(y_train_fold, axis=1)\n",
        "          loss = criterion(out, torch.tensor(y_train_fold_labels).long())\n",
        "          #loss = criterion(out, torch.tensor(y_train_fold))\n",
        "          optimizer.zero_grad()\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "          print (f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}')\n",
        "\n",
        "          val_outputs = model(X_val_fold)\n",
        "          y_val_fold_labels = np.argmax(y_val_fold, axis=1)\n",
        "          val_loss =  criterion(val_outputs, torch.tensor(y_val_fold_labels).long())\n",
        "          _, val_preds = torch.max(val_outputs, 1)\n",
        "          val_accuracy = accuracy_score(y_val_fold_labels, val_preds)\n",
        "\n",
        "          print(f'Validation Loss: {val_loss.item()}, Validation Accuracy: {val_accuracy}') #validation accuracy does not update\n",
        "\n",
        "          # Check for early stopping\n",
        "          early_stopping(loss.item(), val_loss.item())\n",
        "          if early_stopping.early_stop:\n",
        "              print('Early stopping triggered...')\n",
        "              break\n",
        "\n",
        "  # This would break the training loop even at the first kf split.\n",
        "      # If early stopping was triggered, break the outer loop as well\n",
        "      if early_stopping.early_stop:\n",
        "          break\n",
        "  return loss, val_loss, val_accuracy # to also return train accuracy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 40\n",
        "\n",
        "train_loss, val_loss, val_accuracy = train(model, optimizer, num_epochs=EPOCHS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ywIQxX5ZhY8e",
        "outputId": "bdf28333-6800-4dc9-c0ab-535bdb617240"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40, Loss: 2.196084976196289\n",
            "Validation Loss: 2.1894829273223877, Validation Accuracy: 0.656587895689613\n",
            "Epoch 2/40, Loss: 2.1956958770751953\n",
            "Validation Loss: 2.1889805793762207, Validation Accuracy: 0.656587895689613\n",
            "Epoch 3/40, Loss: 2.1951868534088135\n",
            "Validation Loss: 2.1882941722869873, Validation Accuracy: 0.656587895689613\n",
            "Epoch 4/40, Loss: 2.1945221424102783\n",
            "Validation Loss: 2.1875553131103516, Validation Accuracy: 0.656587895689613\n",
            "Epoch 5/40, Loss: 2.1938247680664062\n",
            "Validation Loss: 2.1869328022003174, Validation Accuracy: 0.656587895689613\n",
            "Epoch 6/40, Loss: 2.1932454109191895\n",
            "Validation Loss: 2.1864709854125977, Validation Accuracy: 0.656587895689613\n",
            "Epoch 7/40, Loss: 2.192814588546753\n",
            "Validation Loss: 2.186068296432495, Validation Accuracy: 0.656587895689613\n",
            "Epoch 8/40, Loss: 2.1924188137054443\n",
            "Validation Loss: 2.1855971813201904, Validation Accuracy: 0.656587895689613\n",
            "Epoch 9/40, Loss: 2.191929340362549\n",
            "Validation Loss: 2.185044765472412, Validation Accuracy: 0.656587895689613\n",
            "Epoch 10/40, Loss: 2.191335916519165\n",
            "Validation Loss: 2.184504985809326, Validation Accuracy: 0.656587895689613\n",
            "Epoch 11/40, Loss: 2.1907382011413574\n",
            "Validation Loss: 2.184056043624878, Validation Accuracy: 0.656587895689613\n",
            "Epoch 12/40, Loss: 2.1902244091033936\n",
            "Validation Loss: 2.183673858642578, Validation Accuracy: 0.656587895689613\n",
            "Epoch 13/40, Loss: 2.1897857189178467\n",
            "Validation Loss: 2.1832687854766846, Validation Accuracy: 0.656587895689613\n",
            "Epoch 14/40, Loss: 2.189342737197876\n",
            "Validation Loss: 2.1827845573425293, Validation Accuracy: 0.656587895689613\n",
            "Epoch 15/40, Loss: 2.1888396739959717\n",
            "Validation Loss: 2.182246446609497, Validation Accuracy: 0.656587895689613\n",
            "Epoch 16/40, Loss: 2.1883039474487305\n",
            "Validation Loss: 2.1817352771759033, Validation Accuracy: 0.656587895689613\n",
            "Epoch 17/40, Loss: 2.187804698944092\n",
            "Validation Loss: 2.181295871734619, Validation Accuracy: 0.656587895689613\n",
            "Epoch 18/40, Loss: 2.1873743534088135\n",
            "Validation Loss: 2.180887460708618, Validation Accuracy: 0.656587895689613\n",
            "Epoch 19/40, Loss: 2.186967611312866\n",
            "Validation Loss: 2.1804537773132324, Validation Accuracy: 0.656587895689613\n",
            "Epoch 20/40, Loss: 2.186516284942627\n",
            "Validation Loss: 2.1799886226654053, Validation Accuracy: 0.656587895689613\n",
            "Epoch 21/40, Loss: 2.1860198974609375\n",
            "Validation Loss: 2.1795437335968018, Validation Accuracy: 0.656587895689613\n",
            "Epoch 22/40, Loss: 2.185535430908203\n",
            "Validation Loss: 2.1791436672210693, Validation Accuracy: 0.656587895689613\n",
            "Epoch 23/40, Loss: 2.185096263885498\n",
            "Validation Loss: 2.1787478923797607, Validation Accuracy: 0.656587895689613\n",
            "Epoch 24/40, Loss: 2.184671401977539\n",
            "Validation Loss: 2.1783089637756348, Validation Accuracy: 0.656587895689613\n",
            "Epoch 25/40, Loss: 2.1842174530029297\n",
            "Validation Loss: 2.1778335571289062, Validation Accuracy: 0.656587895689613\n",
            "Epoch 26/40, Loss: 2.1837399005889893\n",
            "Validation Loss: 2.177368640899658, Validation Accuracy: 0.656587895689613\n",
            "Epoch 27/40, Loss: 2.183279037475586\n",
            "Validation Loss: 2.1769354343414307, Validation Accuracy: 0.656587895689613\n",
            "Epoch 28/40, Loss: 2.1828484535217285\n",
            "Validation Loss: 2.1765074729919434, Validation Accuracy: 0.656587895689613\n",
            "Epoch 29/40, Loss: 2.18241548538208\n",
            "Validation Loss: 2.176058053970337, Validation Accuracy: 0.656587895689613\n",
            "Epoch 30/40, Loss: 2.181952953338623\n",
            "Validation Loss: 2.175602436065674, Validation Accuracy: 0.656587895689613\n",
            "Epoch 31/40, Loss: 2.1814756393432617\n",
            "Validation Loss: 2.175161361694336, Validation Accuracy: 0.656587895689613\n",
            "Epoch 32/40, Loss: 2.1810102462768555\n",
            "Validation Loss: 2.1747188568115234, Validation Accuracy: 0.656587895689613\n",
            "Epoch 33/40, Loss: 2.180551767349243\n",
            "Validation Loss: 2.174248695373535, Validation Accuracy: 0.656587895689613\n",
            "Epoch 34/40, Loss: 2.1800758838653564\n",
            "Validation Loss: 2.173759937286377, Validation Accuracy: 0.656587895689613\n",
            "Epoch 35/40, Loss: 2.179586887359619\n",
            "Validation Loss: 2.1732771396636963, Validation Accuracy: 0.656587895689613\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wAiRWwz87IWN",
        "outputId": "bfeafafd-8ee0-40ca-a2d9-338de7150d66"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([241,   0,   0,  ..., 241,   0,  10])"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "val_preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i1JJDijI7IWN",
        "outputId": "b59b6a0e-8a84-4865-92de-ef5a95421251"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 1],\n",
              "       [1, 0, 0, 0, 0, 0],\n",
              "       ...,\n",
              "       [1, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 1],\n",
              "       [1, 0, 0, 0, 0, 0]], dtype=uint8)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_val_fold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qy996kmi7IWO",
        "outputId": "1ff859fb-ad81-4a26-bd0d-762404ecb49c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[     0      1      2 ... 408770 408771 408772]\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "cross_entropy_loss(): argument 'target' (position 2) must be Tensor, not numpy.ndarray",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[40], line 27\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_epochs):\n\u001b[0;32m     26\u001b[0m     out \u001b[39m=\u001b[39m model(torch\u001b[39m.\u001b[39mfrom_numpy(X_train_fold)\u001b[39m.\u001b[39mfloat())\n\u001b[1;32m---> 27\u001b[0m     loss \u001b[39m=\u001b[39m criterion(out, y_train_fold)\n\u001b[0;32m     31\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m     32\u001b[0m     loss\u001b[39m.\u001b[39mbackward()\n",
            "File \u001b[1;32mc:\\Source\\Anaconda\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[1;32mc:\\Source\\Anaconda\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\loss.py:1174\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1173\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor, target: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m-> 1174\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mcross_entropy(\u001b[39minput\u001b[39;49m, target, weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight,\n\u001b[0;32m   1175\u001b[0m                            ignore_index\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mignore_index, reduction\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreduction,\n\u001b[0;32m   1176\u001b[0m                            label_smoothing\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlabel_smoothing)\n",
            "File \u001b[1;32mc:\\Source\\Anaconda\\envs\\torch\\lib\\site-packages\\torch\\nn\\functional.py:3026\u001b[0m, in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   3024\u001b[0m \u001b[39mif\u001b[39;00m size_average \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m reduce \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   3025\u001b[0m     reduction \u001b[39m=\u001b[39m _Reduction\u001b[39m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3026\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_nn\u001b[39m.\u001b[39;49mcross_entropy_loss(\u001b[39minput\u001b[39;49m, target, weight, _Reduction\u001b[39m.\u001b[39;49mget_enum(reduction), ignore_index, label_smoothing)\n",
            "\u001b[1;31mTypeError\u001b[0m: cross_entropy_loss(): argument 'target' (position 2) must be Tensor, not numpy.ndarray"
          ]
        }
      ],
      "source": [
        "class EarlyStopping:\n",
        "    def __init__(self, tolerance, min_delta):\n",
        "        self.tolerance = tolerance\n",
        "        self.min_delta = min_delta\n",
        "        self.counter = 0\n",
        "        self.early_stop = False\n",
        "\n",
        "    def __call__(self, train_loss, validation_loss):\n",
        "        if (validation_loss - train_loss) > self.min_delta:\n",
        "            self.counter +=1\n",
        "            if self.counter >= self.tolerance:\n",
        "                self.early_stop = True\n",
        "\n",
        "early_stopping = EarlyStopping(tolerance=5, min_delta=0.01)\n",
        "\n",
        "# training\n",
        "num_epochs = 20\n",
        "for train_index, val_index in kf.split(X_train):\n",
        "    print(train_index)\n",
        "    X_train_fold = X_train.values[train_index]\n",
        "    y_train_fold = y_train.values[train_index]\n",
        "    X_val_fold = X_train.values[val_index]\n",
        "    y_val_fold = y_train.values[val_index]\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        out = model(torch.from_numpy(X_train_fold).float())\n",
        "        loss = criterion(out, y_train_fold)\n",
        "\n",
        "\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        print (f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}')\n",
        "\n",
        "        with torch.no_grad():  # Evaluation mode, no need to compute gradients\n",
        "            val_outputs = model(X_val_fold)\n",
        "            # val_loss = criterion(val_outputs, y_val_fold)\n",
        "            val_loss = criterion(val_outputs, torch.from_numpy(y_val_fold).long())\n",
        "\n",
        "            _, val_preds = torch.max(val_outputs, 1)\n",
        "            val_accuracy = accuracy_score(y_val_fold.cpu(), val_preds.cpu())\n",
        "\n",
        "            print(f'Validation Loss: {val_loss.item()}, Validation Accuracy: {val_accuracy}')\n",
        "\n",
        "            # Check for early stopping\n",
        "            early_stopping(loss.item(), val_loss.item())\n",
        "            if early_stopping.early_stop:\n",
        "                print('Early stopping triggered...')\n",
        "                break\n",
        "\n",
        "    # If early stopping was triggered, break the outer loop as well\n",
        "    if early_stopping.early_stop:\n",
        "        break\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "biopy",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}