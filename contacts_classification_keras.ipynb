{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "t046f2EBMgQA"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import InstanceHardnessThreshold\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Input, Dense, Dropout\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xm9MkQXVMOwf",
        "outputId": "c6f03ff6-1f83-462b-b9dd-49d2dd1405c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "'''CONFIG FOR LOCAL / CLOUD RUNNING'''\n",
        "running_local = 'content' not in os.getcwd()\n",
        "if running_local:\n",
        "    path = ''\n",
        "else:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    path = 'drive/MyDrive/StructuralBioinformatics/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "wtZwXpERMea9",
        "outputId": "6c47b2cc-08fe-4ea8-96fe-832f60d1233c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-44a2290f-883e-4b3d-a089-ff1903299a6a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pdb_id</th>\n",
              "      <th>s_ch</th>\n",
              "      <th>s_resi</th>\n",
              "      <th>s_ins</th>\n",
              "      <th>s_resn</th>\n",
              "      <th>s_ss8</th>\n",
              "      <th>s_rsa</th>\n",
              "      <th>s_up</th>\n",
              "      <th>s_down</th>\n",
              "      <th>s_phi</th>\n",
              "      <th>...</th>\n",
              "      <th>t_down</th>\n",
              "      <th>t_phi</th>\n",
              "      <th>t_psi</th>\n",
              "      <th>t_ss3</th>\n",
              "      <th>t_a1</th>\n",
              "      <th>t_a2</th>\n",
              "      <th>t_a3</th>\n",
              "      <th>t_a4</th>\n",
              "      <th>t_a5</th>\n",
              "      <th>Interaction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6hqc</td>\n",
              "      <td>A</td>\n",
              "      <td>158</td>\n",
              "      <td></td>\n",
              "      <td>G</td>\n",
              "      <td>E</td>\n",
              "      <td>0.190</td>\n",
              "      <td>16.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>2.718</td>\n",
              "      <td>...</td>\n",
              "      <td>23.0</td>\n",
              "      <td>-2.075</td>\n",
              "      <td>2.395</td>\n",
              "      <td>H</td>\n",
              "      <td>1.538</td>\n",
              "      <td>-0.055</td>\n",
              "      <td>1.502</td>\n",
              "      <td>0.440</td>\n",
              "      <td>2.897</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6hqc</td>\n",
              "      <td>A</td>\n",
              "      <td>142</td>\n",
              "      <td></td>\n",
              "      <td>I</td>\n",
              "      <td>E</td>\n",
              "      <td>0.533</td>\n",
              "      <td>9.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>-2.019</td>\n",
              "      <td>...</td>\n",
              "      <td>19.0</td>\n",
              "      <td>-2.173</td>\n",
              "      <td>2.344</td>\n",
              "      <td>H</td>\n",
              "      <td>-1.019</td>\n",
              "      <td>-0.987</td>\n",
              "      <td>-1.505</td>\n",
              "      <td>1.266</td>\n",
              "      <td>-0.912</td>\n",
              "      <td>HBOND</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6hqc</td>\n",
              "      <td>A</td>\n",
              "      <td>141</td>\n",
              "      <td></td>\n",
              "      <td>Q</td>\n",
              "      <td>E</td>\n",
              "      <td>0.525</td>\n",
              "      <td>7.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>-1.418</td>\n",
              "      <td>...</td>\n",
              "      <td>13.0</td>\n",
              "      <td>-0.895</td>\n",
              "      <td>-0.620</td>\n",
              "      <td>H</td>\n",
              "      <td>1.050</td>\n",
              "      <td>0.302</td>\n",
              "      <td>-3.656</td>\n",
              "      <td>-0.259</td>\n",
              "      <td>-3.242</td>\n",
              "      <td>VDW</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6hqc</td>\n",
              "      <td>A</td>\n",
              "      <td>90</td>\n",
              "      <td></td>\n",
              "      <td>T</td>\n",
              "      <td>E</td>\n",
              "      <td>0.521</td>\n",
              "      <td>10.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>-2.336</td>\n",
              "      <td>...</td>\n",
              "      <td>23.0</td>\n",
              "      <td>-2.075</td>\n",
              "      <td>2.395</td>\n",
              "      <td>H</td>\n",
              "      <td>1.538</td>\n",
              "      <td>-0.055</td>\n",
              "      <td>1.502</td>\n",
              "      <td>0.440</td>\n",
              "      <td>2.897</td>\n",
              "      <td>VDW</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6hqc</td>\n",
              "      <td>A</td>\n",
              "      <td>93</td>\n",
              "      <td></td>\n",
              "      <td>S</td>\n",
              "      <td>S</td>\n",
              "      <td>0.146</td>\n",
              "      <td>13.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>-1.529</td>\n",
              "      <td>...</td>\n",
              "      <td>16.0</td>\n",
              "      <td>-2.596</td>\n",
              "      <td>2.664</td>\n",
              "      <td>H</td>\n",
              "      <td>-0.591</td>\n",
              "      <td>-1.302</td>\n",
              "      <td>-0.733</td>\n",
              "      <td>1.570</td>\n",
              "      <td>-0.146</td>\n",
              "      <td>HBOND</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>733</th>\n",
              "      <td>6fuc</td>\n",
              "      <td>A</td>\n",
              "      <td>192</td>\n",
              "      <td></td>\n",
              "      <td>L</td>\n",
              "      <td>G</td>\n",
              "      <td>0.012</td>\n",
              "      <td>17.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>-0.918</td>\n",
              "      <td>...</td>\n",
              "      <td>15.0</td>\n",
              "      <td>-1.254</td>\n",
              "      <td>-0.575</td>\n",
              "      <td>H</td>\n",
              "      <td>-0.032</td>\n",
              "      <td>0.326</td>\n",
              "      <td>2.213</td>\n",
              "      <td>0.908</td>\n",
              "      <td>1.313</td>\n",
              "      <td>HBOND</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>734</th>\n",
              "      <td>6fuc</td>\n",
              "      <td>A</td>\n",
              "      <td>192</td>\n",
              "      <td></td>\n",
              "      <td>L</td>\n",
              "      <td>G</td>\n",
              "      <td>0.012</td>\n",
              "      <td>17.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>-0.918</td>\n",
              "      <td>...</td>\n",
              "      <td>15.0</td>\n",
              "      <td>-1.254</td>\n",
              "      <td>-0.575</td>\n",
              "      <td>H</td>\n",
              "      <td>-0.032</td>\n",
              "      <td>0.326</td>\n",
              "      <td>2.213</td>\n",
              "      <td>0.908</td>\n",
              "      <td>1.313</td>\n",
              "      <td>VDW</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>735</th>\n",
              "      <td>6fuc</td>\n",
              "      <td>A</td>\n",
              "      <td>104</td>\n",
              "      <td></td>\n",
              "      <td>R</td>\n",
              "      <td>H</td>\n",
              "      <td>0.468</td>\n",
              "      <td>9.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>-1.043</td>\n",
              "      <td>...</td>\n",
              "      <td>10.0</td>\n",
              "      <td>-1.289</td>\n",
              "      <td>-0.738</td>\n",
              "      <td>H</td>\n",
              "      <td>-0.595</td>\n",
              "      <td>0.009</td>\n",
              "      <td>0.672</td>\n",
              "      <td>-2.128</td>\n",
              "      <td>-0.184</td>\n",
              "      <td>VDW</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>736</th>\n",
              "      <td>6fuc</td>\n",
              "      <td>A</td>\n",
              "      <td>100</td>\n",
              "      <td></td>\n",
              "      <td>A</td>\n",
              "      <td>H</td>\n",
              "      <td>0.434</td>\n",
              "      <td>10.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>-1.007</td>\n",
              "      <td>...</td>\n",
              "      <td>19.0</td>\n",
              "      <td>-1.126</td>\n",
              "      <td>-0.671</td>\n",
              "      <td>H</td>\n",
              "      <td>-1.019</td>\n",
              "      <td>-0.987</td>\n",
              "      <td>-1.505</td>\n",
              "      <td>1.266</td>\n",
              "      <td>-0.912</td>\n",
              "      <td>HBOND</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>737</th>\n",
              "      <td>6fuc</td>\n",
              "      <td>A</td>\n",
              "      <td>182</td>\n",
              "      <td></td>\n",
              "      <td>Q</td>\n",
              "      <td>S</td>\n",
              "      <td>0.444</td>\n",
              "      <td>10.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>-2.491</td>\n",
              "      <td>...</td>\n",
              "      <td>13.0</td>\n",
              "      <td>-1.120</td>\n",
              "      <td>-0.798</td>\n",
              "      <td>H</td>\n",
              "      <td>1.538</td>\n",
              "      <td>-0.055</td>\n",
              "      <td>1.502</td>\n",
              "      <td>0.440</td>\n",
              "      <td>2.897</td>\n",
              "      <td>VDW</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>743058 rows × 34 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-44a2290f-883e-4b3d-a089-ff1903299a6a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-705be9e9-8ae7-43a7-91a8-14ad04b8f4c6\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-705be9e9-8ae7-43a7-91a8-14ad04b8f4c6')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-705be9e9-8ae7-43a7-91a8-14ad04b8f4c6 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-44a2290f-883e-4b3d-a089-ff1903299a6a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-44a2290f-883e-4b3d-a089-ff1903299a6a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "    pdb_id s_ch  s_resi s_ins s_resn s_ss8  s_rsa  s_up  s_down  s_phi  ...  \\\n",
              "0     6hqc    A     158            G     E  0.190  16.0    14.0  2.718  ...   \n",
              "1     6hqc    A     142            I     E  0.533   9.0     8.0 -2.019  ...   \n",
              "2     6hqc    A     141            Q     E  0.525   7.0    12.0 -1.418  ...   \n",
              "3     6hqc    A      90            T     E  0.521  10.0    12.0 -2.336  ...   \n",
              "4     6hqc    A      93            S     S  0.146  13.0     9.0 -1.529  ...   \n",
              "..     ...  ...     ...   ...    ...   ...    ...   ...     ...    ...  ...   \n",
              "733   6fuc    A     192            L     G  0.012  17.0    20.0 -0.918  ...   \n",
              "734   6fuc    A     192            L     G  0.012  17.0    20.0 -0.918  ...   \n",
              "735   6fuc    A     104            R     H  0.468   9.0    21.0 -1.043  ...   \n",
              "736   6fuc    A     100            A     H  0.434  10.0    14.0 -1.007  ...   \n",
              "737   6fuc    A     182            Q     S  0.444  10.0    16.0 -2.491  ...   \n",
              "\n",
              "     t_down  t_phi  t_psi  t_ss3   t_a1   t_a2   t_a3   t_a4   t_a5  \\\n",
              "0      23.0 -2.075  2.395      H  1.538 -0.055  1.502  0.440  2.897   \n",
              "1      19.0 -2.173  2.344      H -1.019 -0.987 -1.505  1.266 -0.912   \n",
              "2      13.0 -0.895 -0.620      H  1.050  0.302 -3.656 -0.259 -3.242   \n",
              "3      23.0 -2.075  2.395      H  1.538 -0.055  1.502  0.440  2.897   \n",
              "4      16.0 -2.596  2.664      H -0.591 -1.302 -0.733  1.570 -0.146   \n",
              "..      ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
              "733    15.0 -1.254 -0.575      H -0.032  0.326  2.213  0.908  1.313   \n",
              "734    15.0 -1.254 -0.575      H -0.032  0.326  2.213  0.908  1.313   \n",
              "735    10.0 -1.289 -0.738      H -0.595  0.009  0.672 -2.128 -0.184   \n",
              "736    19.0 -1.126 -0.671      H -1.019 -0.987 -1.505  1.266 -0.912   \n",
              "737    13.0 -1.120 -0.798      H  1.538 -0.055  1.502  0.440  2.897   \n",
              "\n",
              "    Interaction  \n",
              "0           NaN  \n",
              "1         HBOND  \n",
              "2           VDW  \n",
              "3           VDW  \n",
              "4         HBOND  \n",
              "..          ...  \n",
              "733       HBOND  \n",
              "734         VDW  \n",
              "735         VDW  \n",
              "736       HBOND  \n",
              "737         VDW  \n",
              "\n",
              "[743058 rows x 34 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dfs = []\n",
        "for filename in os.listdir(path + 'data/features_ring'):\n",
        "    if filename[-4:] == '.tsv':\n",
        "        dfs.append(pd.read_csv(path + 'data/features_ring/' + filename, sep='\\t'))\n",
        "df = pd.concat(dfs)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        },
        "id": "dSaRPGy3O8WG",
        "outputId": "16b41ce1-00b7-4769-aab1-e198df2835e8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-5-2f63f796d806>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  y.replace(contact_dict, inplace=True)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-ab8d89fa-46d7-41be-a116-cd4b5fc1f4d1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>s_up</th>\n",
              "      <th>s_down</th>\n",
              "      <th>s_phi</th>\n",
              "      <th>s_psi</th>\n",
              "      <th>s_a1</th>\n",
              "      <th>s_a2</th>\n",
              "      <th>s_a3</th>\n",
              "      <th>s_a4</th>\n",
              "      <th>s_a5</th>\n",
              "      <th>t_up</th>\n",
              "      <th>t_down</th>\n",
              "      <th>t_phi</th>\n",
              "      <th>t_psi</th>\n",
              "      <th>t_a1</th>\n",
              "      <th>t_a2</th>\n",
              "      <th>t_a3</th>\n",
              "      <th>t_a4</th>\n",
              "      <th>t_a5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>-2.019</td>\n",
              "      <td>-0.059</td>\n",
              "      <td>-1.239</td>\n",
              "      <td>-0.547</td>\n",
              "      <td>2.131</td>\n",
              "      <td>0.393</td>\n",
              "      <td>0.816</td>\n",
              "      <td>8.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>-2.173</td>\n",
              "      <td>2.344</td>\n",
              "      <td>-1.019</td>\n",
              "      <td>-0.987</td>\n",
              "      <td>-1.505</td>\n",
              "      <td>1.266</td>\n",
              "      <td>-0.912</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>-1.418</td>\n",
              "      <td>2.219</td>\n",
              "      <td>0.931</td>\n",
              "      <td>-0.179</td>\n",
              "      <td>-3.005</td>\n",
              "      <td>-0.503</td>\n",
              "      <td>-1.853</td>\n",
              "      <td>2.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>-0.895</td>\n",
              "      <td>-0.620</td>\n",
              "      <td>1.050</td>\n",
              "      <td>0.302</td>\n",
              "      <td>-3.656</td>\n",
              "      <td>-0.259</td>\n",
              "      <td>-3.242</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>-2.336</td>\n",
              "      <td>2.279</td>\n",
              "      <td>-0.032</td>\n",
              "      <td>0.326</td>\n",
              "      <td>2.213</td>\n",
              "      <td>0.908</td>\n",
              "      <td>1.313</td>\n",
              "      <td>9.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>-2.075</td>\n",
              "      <td>2.395</td>\n",
              "      <td>1.538</td>\n",
              "      <td>-0.055</td>\n",
              "      <td>1.502</td>\n",
              "      <td>0.440</td>\n",
              "      <td>2.897</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>13.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>-1.529</td>\n",
              "      <td>2.821</td>\n",
              "      <td>-0.228</td>\n",
              "      <td>1.399</td>\n",
              "      <td>-4.760</td>\n",
              "      <td>0.670</td>\n",
              "      <td>-2.647</td>\n",
              "      <td>5.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>-2.596</td>\n",
              "      <td>2.664</td>\n",
              "      <td>-0.591</td>\n",
              "      <td>-1.302</td>\n",
              "      <td>-0.733</td>\n",
              "      <td>1.570</td>\n",
              "      <td>-0.146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>19.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>-1.733</td>\n",
              "      <td>1.989</td>\n",
              "      <td>-1.019</td>\n",
              "      <td>-0.987</td>\n",
              "      <td>-1.505</td>\n",
              "      <td>1.266</td>\n",
              "      <td>-0.912</td>\n",
              "      <td>18.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>-1.574</td>\n",
              "      <td>-0.723</td>\n",
              "      <td>-1.239</td>\n",
              "      <td>-0.547</td>\n",
              "      <td>2.131</td>\n",
              "      <td>0.393</td>\n",
              "      <td>0.816</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>733</th>\n",
              "      <td>17.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>-0.918</td>\n",
              "      <td>-0.626</td>\n",
              "      <td>-1.019</td>\n",
              "      <td>-0.987</td>\n",
              "      <td>-1.505</td>\n",
              "      <td>1.266</td>\n",
              "      <td>-0.912</td>\n",
              "      <td>16.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>-1.254</td>\n",
              "      <td>-0.575</td>\n",
              "      <td>-0.032</td>\n",
              "      <td>0.326</td>\n",
              "      <td>2.213</td>\n",
              "      <td>0.908</td>\n",
              "      <td>1.313</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>734</th>\n",
              "      <td>17.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>-0.918</td>\n",
              "      <td>-0.626</td>\n",
              "      <td>-1.019</td>\n",
              "      <td>-0.987</td>\n",
              "      <td>-1.505</td>\n",
              "      <td>1.266</td>\n",
              "      <td>-0.912</td>\n",
              "      <td>16.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>-1.254</td>\n",
              "      <td>-0.575</td>\n",
              "      <td>-0.032</td>\n",
              "      <td>0.326</td>\n",
              "      <td>2.213</td>\n",
              "      <td>0.908</td>\n",
              "      <td>1.313</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>735</th>\n",
              "      <td>9.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>-1.043</td>\n",
              "      <td>-0.689</td>\n",
              "      <td>1.538</td>\n",
              "      <td>-0.055</td>\n",
              "      <td>1.502</td>\n",
              "      <td>0.440</td>\n",
              "      <td>2.897</td>\n",
              "      <td>12.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>-1.289</td>\n",
              "      <td>-0.738</td>\n",
              "      <td>-0.595</td>\n",
              "      <td>0.009</td>\n",
              "      <td>0.672</td>\n",
              "      <td>-2.128</td>\n",
              "      <td>-0.184</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>736</th>\n",
              "      <td>10.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>-1.007</td>\n",
              "      <td>-0.674</td>\n",
              "      <td>-0.591</td>\n",
              "      <td>-1.302</td>\n",
              "      <td>-0.733</td>\n",
              "      <td>1.570</td>\n",
              "      <td>-0.146</td>\n",
              "      <td>20.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>-1.126</td>\n",
              "      <td>-0.671</td>\n",
              "      <td>-1.019</td>\n",
              "      <td>-0.987</td>\n",
              "      <td>-1.505</td>\n",
              "      <td>1.266</td>\n",
              "      <td>-0.912</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>737</th>\n",
              "      <td>10.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>-2.491</td>\n",
              "      <td>1.433</td>\n",
              "      <td>0.931</td>\n",
              "      <td>-0.179</td>\n",
              "      <td>-3.005</td>\n",
              "      <td>-0.503</td>\n",
              "      <td>-1.853</td>\n",
              "      <td>16.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>-1.120</td>\n",
              "      <td>-0.798</td>\n",
              "      <td>1.538</td>\n",
              "      <td>-0.055</td>\n",
              "      <td>1.502</td>\n",
              "      <td>0.440</td>\n",
              "      <td>2.897</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>515076 rows × 18 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ab8d89fa-46d7-41be-a116-cd4b5fc1f4d1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-eb3c7b6f-d096-473d-a831-10891f4eb633\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-eb3c7b6f-d096-473d-a831-10891f4eb633')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-eb3c7b6f-d096-473d-a831-10891f4eb633 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ab8d89fa-46d7-41be-a116-cd4b5fc1f4d1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ab8d89fa-46d7-41be-a116-cd4b5fc1f4d1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "     s_up  s_down  s_phi  s_psi   s_a1   s_a2   s_a3   s_a4   s_a5  t_up  \\\n",
              "1     9.0     8.0 -2.019 -0.059 -1.239 -0.547  2.131  0.393  0.816   8.0   \n",
              "2     7.0    12.0 -1.418  2.219  0.931 -0.179 -3.005 -0.503 -1.853   2.0   \n",
              "3    10.0    12.0 -2.336  2.279 -0.032  0.326  2.213  0.908  1.313   9.0   \n",
              "4    13.0     9.0 -1.529  2.821 -0.228  1.399 -4.760  0.670 -2.647   5.0   \n",
              "6    19.0    21.0 -1.733  1.989 -1.019 -0.987 -1.505  1.266 -0.912  18.0   \n",
              "..    ...     ...    ...    ...    ...    ...    ...    ...    ...   ...   \n",
              "733  17.0    20.0 -0.918 -0.626 -1.019 -0.987 -1.505  1.266 -0.912  16.0   \n",
              "734  17.0    20.0 -0.918 -0.626 -1.019 -0.987 -1.505  1.266 -0.912  16.0   \n",
              "735   9.0    21.0 -1.043 -0.689  1.538 -0.055  1.502  0.440  2.897  12.0   \n",
              "736  10.0    14.0 -1.007 -0.674 -0.591 -1.302 -0.733  1.570 -0.146  20.0   \n",
              "737  10.0    16.0 -2.491  1.433  0.931 -0.179 -3.005 -0.503 -1.853  16.0   \n",
              "\n",
              "     t_down  t_phi  t_psi   t_a1   t_a2   t_a3   t_a4   t_a5  \n",
              "1      19.0 -2.173  2.344 -1.019 -0.987 -1.505  1.266 -0.912  \n",
              "2      13.0 -0.895 -0.620  1.050  0.302 -3.656 -0.259 -3.242  \n",
              "3      23.0 -2.075  2.395  1.538 -0.055  1.502  0.440  2.897  \n",
              "4      16.0 -2.596  2.664 -0.591 -1.302 -0.733  1.570 -0.146  \n",
              "6       9.0 -1.574 -0.723 -1.239 -0.547  2.131  0.393  0.816  \n",
              "..      ...    ...    ...    ...    ...    ...    ...    ...  \n",
              "733    15.0 -1.254 -0.575 -0.032  0.326  2.213  0.908  1.313  \n",
              "734    15.0 -1.254 -0.575 -0.032  0.326  2.213  0.908  1.313  \n",
              "735    10.0 -1.289 -0.738 -0.595  0.009  0.672 -2.128 -0.184  \n",
              "736    19.0 -1.126 -0.671 -1.019 -0.987 -1.505  1.266 -0.912  \n",
              "737    13.0 -1.120 -0.798  1.538 -0.055  1.502  0.440  2.897  \n",
              "\n",
              "[515076 rows x 18 columns]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = df[df.Interaction.notna()]\n",
        "contact_dict = {\"HBOND\": 0, \"IONIC\": 1, \"PICATION\": 2, \"PIPISTACK\": 3, \"SSBOND\": 4, \"VDW\": 5}\n",
        "y = df['Interaction']\n",
        "cat_names = list(y.astype('category').cat.categories)\n",
        "y.replace(contact_dict, inplace=True)\n",
        "X = df[['s_up', 's_down', 's_phi', 's_psi', 's_a1', 's_a2', 's_a3', 's_a4', 's_a5', 't_up', 't_down', 't_phi', 't_psi', 't_a1', 't_a2', 't_a3', 't_a4', 't_a5']]\n",
        "X = X.apply(lambda x: x.fillna(x.mean()) if x.dtype.kind in 'biufc' else x)\n",
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        },
        "id": "bA2TfRLHTQw2",
        "outputId": "f8076dff-11c6-4c95-e33f-821978460d40"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SelectFromModel(estimator=LogisticRegression(max_iter=1000))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SelectFromModel</label><div class=\"sk-toggleable__content\"><pre>SelectFromModel(estimator=LogisticRegression(max_iter=1000))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "SelectFromModel(estimator=LogisticRegression(max_iter=1000))"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Now using full features\n",
        "\n",
        "#feature_sel = SelectFromModel(LogisticRegression(max_iter=1000))\n",
        "#X=feature_sel.fit(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "PYW86VGxJzwu"
      },
      "outputs": [],
      "source": [
        "minMax = MinMaxScaler()\n",
        "minMax.fit(X)\n",
        "X_scaled = minMax.transform(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVcpmCRh5PIy",
        "outputId": "457a519f-0722-420f-de3f-45046b4f0fef"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.2       , 0.15555556, 0.17860554, ..., 0.41428026, 0.9177934 ,\n",
              "        0.37954064],\n",
              "       [0.15555556, 0.24444444, 0.27427571, ..., 0.14051165, 0.50540833,\n",
              "        0.        ],\n",
              "       [0.22222222, 0.24444444, 0.1281439 , ..., 0.79699631, 0.69442942,\n",
              "        1.        ],\n",
              "       ...,\n",
              "       [0.2       , 0.44444444, 0.33397007, ..., 0.69135802, 0.        ,\n",
              "        0.49812673],\n",
              "       [0.22222222, 0.28888889, 0.33970073, ..., 0.41428026, 0.9177934 ,\n",
              "        0.37954064],\n",
              "       [0.22222222, 0.33333333, 0.10347023, ..., 0.79699631, 0.69442942,\n",
              "        1.        ]])"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_scaled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLALZoteZZZo",
        "outputId": "f9dd6f87-9226-4fe7-8d3f-fc75d69c34d4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "18"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input_dim = X_scaled.shape[1]\n",
        "num_classes = len(cat_names)\n",
        "input_dim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "3qG3oOoLQ47L"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, stratify=y, test_size=0.1, random_state=100)\n",
        "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=100)\n",
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)\n",
        "X_test = np.array(X_test)\n",
        "y_test = np.array(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "V4P5HP07tOAa"
      },
      "outputs": [],
      "source": [
        "def balance(X, y, n_samples):\n",
        "    _, counts = np.unique(y, return_counts=True)\n",
        "    under_classes = {}\n",
        "    over_classes = {}\n",
        "\n",
        "    for i, count in enumerate(counts):\n",
        "        if n_samples[i] < count:\n",
        "            under_classes[i] = n_samples[i]\n",
        "        else:\n",
        "            over_classes[i] = n_samples[i]\n",
        "\n",
        "    print(\"Applying undersampling\")\n",
        "    if under_classes:  # Check if under_classes dict is not empty\n",
        "        undersample = InstanceHardnessThreshold(estimator=AdaBoostClassifier(), sampling_strategy=under_classes)\n",
        "        X, y = undersample.fit_resample(X, y)\n",
        "\n",
        "    print(\"Applying oversampling\")\n",
        "    if over_classes:  # Check if over_classes dict is not empty\n",
        "        oversample = SMOTE(sampling_strategy=over_classes)\n",
        "        X, y = oversample.fit_resample(X, y)\n",
        "\n",
        "    return X, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rl0Rxmh0e7EP",
        "outputId": "151e168f-f792-4086-9a99-29e06da429da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Over\n"
          ]
        }
      ],
      "source": [
        "'''make small adjustments'''\n",
        "print(\"Over\")\n",
        "oversample = SMOTE(sampling_strategy={2:20000,3:10000,4:10000})\n",
        "X_bal, y_bal = oversample.fit_resample(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2jWgHZqZZ74E",
        "outputId": "49b2bf9f-8930-4291-e141-4a51b207554c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Under\n",
            "Over\n"
          ]
        }
      ],
      "source": [
        "'''mdl is very sensitive to undersampeling, using only over for now'''\n",
        "\n",
        "#Not using this\n",
        "\n",
        "#print(\"Under\")\n",
        "#undersample = InstanceHardnessThreshold(estimator=AdaBoostClassifier(),sampling_strategy={0:70000,5:80000})\n",
        "#X_bal, y_bal = undersample.fit_resample(X_train, y_train)\n",
        "#print(\"Over\")\n",
        "#oversample = SMOTE(sampling_strategy={1:20000,3:10000,2:20000,4:10000})\n",
        "#X_bal, y_bal = oversample.fit_resample(X_bal, y_bal)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "CNaQ4jBC5hDZ"
      },
      "outputs": [],
      "source": [
        "'''do not execute unless you want to skip balancing alltogether'''\n",
        "X_bal, y_bal = X_train, y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9x4B_nTTBOk",
        "outputId": "c7f7255d-da00-4a90-a0fe-0bdfc46d8ec3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Applying undersampling\n",
            "Applying oversampling\n"
          ]
        }
      ],
      "source": [
        "# balancing is only applied to training data\n",
        "'''currently not using this implementation - do not execute'''\n",
        "X_bal, y_bal = balance(X_train, y_train, [50000,50000,50000,50000,50000,50000])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "lAWVtfNjdf9k"
      },
      "outputs": [],
      "source": [
        "y_cat = to_categorical(y_bal, num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "wfTaZc0XYyX8"
      },
      "outputs": [],
      "source": [
        "def init():\n",
        "  model = Sequential()\n",
        "  model.add(Input(input_dim))\n",
        "  model.add(Dense(units=128, activation='relu', kernel_initializer=\"glorot_normal\"))\n",
        "  #model.add(Dropout(0.5))\n",
        "  model.add(Dense(units=128, activation='relu', kernel_initializer=\"glorot_normal\"))\n",
        "  #model.add(Dropout(0.5))\n",
        "  model.add(Dense(units=128, activation='relu', kernel_initializer=\"glorot_normal\"))\n",
        "  #model.add(Dropout(0.5))\n",
        "  model.add(Dense(units=128, activation='relu', kernel_initializer=\"glorot_normal\"))\n",
        "  #model.add(Dropout(0.5))\n",
        "  model.add(Dense(units=128, activation='relu', kernel_initializer=\"glorot_normal\"))\n",
        "  #model.add(Dropout(0.5))\n",
        "  model.add(Dense(units=num_classes, activation='softmax', kernel_initializer=\"glorot_normal\"))\n",
        "  model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['AUC'])\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svriUEfPbiUw",
        "outputId": "886c2997-f7b4-4773-e888-22d338b38806"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 128)               2432      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 6)                 774       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 69,254\n",
            "Trainable params: 69,254\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "mdl = init()\n",
        "mdl.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ms5F3jUDb-AN",
        "outputId": "4c2b5be9-40ec-41bb-e0ea-050c256064e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 1/10\n",
            "Epoch 1/500\n",
            "28/28 [==============================] - 8s 246ms/step - loss: 1.1379 - auc: 0.8731 - val_loss: 0.9668 - val_auc: 0.9095\n",
            "Epoch 2/500\n",
            "28/28 [==============================] - 4s 159ms/step - loss: 0.8961 - auc: 0.9178 - val_loss: 0.8374 - val_auc: 0.9265\n",
            "Epoch 3/500\n",
            "28/28 [==============================] - 5s 166ms/step - loss: 0.7882 - auc: 0.9330 - val_loss: 0.7277 - val_auc: 0.9409\n",
            "Epoch 4/500\n",
            "28/28 [==============================] - 6s 212ms/step - loss: 0.6871 - auc: 0.9448 - val_loss: 0.6562 - val_auc: 0.9481\n",
            "Epoch 5/500\n",
            "28/28 [==============================] - 4s 152ms/step - loss: 0.6472 - auc: 0.9488 - val_loss: 0.6354 - val_auc: 0.9503\n",
            "Epoch 6/500\n",
            "28/28 [==============================] - 5s 176ms/step - loss: 0.6307 - auc: 0.9509 - val_loss: 0.6205 - val_auc: 0.9525\n",
            "Epoch 7/500\n",
            "28/28 [==============================] - 6s 216ms/step - loss: 0.6200 - auc: 0.9524 - val_loss: 0.6108 - val_auc: 0.9541\n",
            "Epoch 8/500\n",
            "28/28 [==============================] - 4s 151ms/step - loss: 0.6102 - auc: 0.9539 - val_loss: 0.6036 - val_auc: 0.9549\n",
            "Epoch 9/500\n",
            "28/28 [==============================] - 5s 189ms/step - loss: 0.6048 - auc: 0.9546 - val_loss: 0.5969 - val_auc: 0.9558\n",
            "Epoch 10/500\n",
            "28/28 [==============================] - 5s 191ms/step - loss: 0.6011 - auc: 0.9551 - val_loss: 0.5931 - val_auc: 0.9563\n",
            "Epoch 11/500\n",
            "28/28 [==============================] - 4s 161ms/step - loss: 0.5946 - auc: 0.9560 - val_loss: 0.5915 - val_auc: 0.9565\n",
            "Epoch 12/500\n",
            "28/28 [==============================] - 6s 210ms/step - loss: 0.5923 - auc: 0.9563 - val_loss: 0.5876 - val_auc: 0.9571\n",
            "Epoch 13/500\n",
            "28/28 [==============================] - 5s 171ms/step - loss: 0.5917 - auc: 0.9564 - val_loss: 0.5849 - val_auc: 0.9574\n",
            "Epoch 14/500\n",
            "28/28 [==============================] - 4s 154ms/step - loss: 0.5879 - auc: 0.9569 - val_loss: 0.5902 - val_auc: 0.9566\n",
            "Epoch 15/500\n",
            "28/28 [==============================] - 6s 233ms/step - loss: 0.5874 - auc: 0.9570 - val_loss: 0.5807 - val_auc: 0.9579\n",
            "Epoch 16/500\n",
            "28/28 [==============================] - 4s 158ms/step - loss: 0.5887 - auc: 0.9567 - val_loss: 0.5814 - val_auc: 0.9578\n",
            "Epoch 17/500\n",
            "28/28 [==============================] - 4s 161ms/step - loss: 0.5844 - auc: 0.9574 - val_loss: 0.5820 - val_auc: 0.9579\n",
            "Epoch 18/500\n",
            "28/28 [==============================] - 6s 229ms/step - loss: 0.5848 - auc: 0.9573 - val_loss: 0.5782 - val_auc: 0.9583\n",
            "Epoch 19/500\n",
            "28/28 [==============================] - 4s 152ms/step - loss: 0.5830 - auc: 0.9576 - val_loss: 0.5796 - val_auc: 0.9581\n",
            "Epoch 20/500\n",
            "28/28 [==============================] - 6s 222ms/step - loss: 0.5807 - auc: 0.9579 - val_loss: 0.5831 - val_auc: 0.9576\n",
            "Epoch 21/500\n",
            "28/28 [==============================] - 7s 237ms/step - loss: 0.5818 - auc: 0.9578 - val_loss: 0.5813 - val_auc: 0.9580\n",
            "Epoch 22/500\n",
            "28/28 [==============================] - 4s 156ms/step - loss: 0.5798 - auc: 0.9581 - val_loss: 0.5761 - val_auc: 0.9586\n",
            "Epoch 23/500\n",
            "28/28 [==============================] - 5s 165ms/step - loss: 0.5816 - auc: 0.9577 - val_loss: 0.5751 - val_auc: 0.9587\n",
            "Epoch 24/500\n",
            "28/28 [==============================] - 6s 216ms/step - loss: 0.5772 - auc: 0.9584 - val_loss: 0.5734 - val_auc: 0.9590\n",
            "Epoch 25/500\n",
            "28/28 [==============================] - 4s 160ms/step - loss: 0.5763 - auc: 0.9586 - val_loss: 0.5728 - val_auc: 0.9591\n",
            "Epoch 26/500\n",
            "28/28 [==============================] - 5s 182ms/step - loss: 0.5755 - auc: 0.9587 - val_loss: 0.5719 - val_auc: 0.9592\n",
            "Epoch 27/500\n",
            "28/28 [==============================] - 6s 194ms/step - loss: 0.5751 - auc: 0.9587 - val_loss: 0.5735 - val_auc: 0.9589\n",
            "Epoch 28/500\n",
            "28/28 [==============================] - 4s 161ms/step - loss: 0.5771 - auc: 0.9584 - val_loss: 0.5735 - val_auc: 0.9590\n",
            "Epoch 29/500\n",
            "28/28 [==============================] - 6s 204ms/step - loss: 0.5739 - auc: 0.9589 - val_loss: 0.5697 - val_auc: 0.9595\n",
            "Epoch 30/500\n",
            "28/28 [==============================] - 5s 183ms/step - loss: 0.5742 - auc: 0.9588 - val_loss: 0.5763 - val_auc: 0.9588\n",
            "Epoch 31/500\n",
            "28/28 [==============================] - 4s 155ms/step - loss: 0.5750 - auc: 0.9587 - val_loss: 0.5700 - val_auc: 0.9594\n",
            "Epoch 32/500\n",
            "28/28 [==============================] - 6s 228ms/step - loss: 0.5727 - auc: 0.9591 - val_loss: 0.5696 - val_auc: 0.9595\n",
            "Epoch 33/500\n",
            "28/28 [==============================] - 4s 154ms/step - loss: 0.5725 - auc: 0.9590 - val_loss: 0.5693 - val_auc: 0.9596\n",
            "Epoch 34/500\n",
            "28/28 [==============================] - 4s 161ms/step - loss: 0.5703 - auc: 0.9594 - val_loss: 0.5701 - val_auc: 0.9594\n",
            "Epoch 35/500\n",
            "28/28 [==============================] - 6s 231ms/step - loss: 0.5700 - auc: 0.9594 - val_loss: 0.5682 - val_auc: 0.9597\n",
            "Epoch 36/500\n",
            "28/28 [==============================] - 4s 158ms/step - loss: 0.5697 - auc: 0.9595 - val_loss: 0.5672 - val_auc: 0.9598\n",
            "Epoch 37/500\n",
            "28/28 [==============================] - 4s 156ms/step - loss: 0.5696 - auc: 0.9595 - val_loss: 0.5676 - val_auc: 0.9598\n",
            "Epoch 38/500\n",
            "28/28 [==============================] - 6s 232ms/step - loss: 0.5675 - auc: 0.9598 - val_loss: 0.5648 - val_auc: 0.9602\n",
            "Epoch 39/500\n",
            "28/28 [==============================] - 4s 154ms/step - loss: 0.5676 - auc: 0.9598 - val_loss: 0.5762 - val_auc: 0.9591\n",
            "Epoch 40/500\n",
            "28/28 [==============================] - 4s 154ms/step - loss: 0.5708 - auc: 0.9594 - val_loss: 0.5651 - val_auc: 0.9601\n",
            "Epoch 41/500\n",
            "28/28 [==============================] - 6s 230ms/step - loss: 0.5668 - auc: 0.9599 - val_loss: 0.5661 - val_auc: 0.9600\n",
            "Epoch 42/500\n",
            "28/28 [==============================] - 4s 161ms/step - loss: 0.5666 - auc: 0.9599 - val_loss: 0.5649 - val_auc: 0.9601\n",
            "Epoch 43/500\n",
            "28/28 [==============================] - 5s 165ms/step - loss: 0.5658 - auc: 0.9600 - val_loss: 0.5638 - val_auc: 0.9603\n",
            "Epoch 44/500\n",
            "28/28 [==============================] - 6s 215ms/step - loss: 0.5662 - auc: 0.9599 - val_loss: 0.5659 - val_auc: 0.9600\n",
            "Epoch 45/500\n",
            "28/28 [==============================] - 4s 160ms/step - loss: 0.5647 - auc: 0.9602 - val_loss: 0.5650 - val_auc: 0.9602\n",
            "Epoch 46/500\n",
            "28/28 [==============================] - 5s 187ms/step - loss: 0.5648 - auc: 0.9602 - val_loss: 0.5647 - val_auc: 0.9603\n",
            "Epoch 47/500\n",
            "28/28 [==============================] - 6s 200ms/step - loss: 0.5660 - auc: 0.9600 - val_loss: 0.5653 - val_auc: 0.9601\n",
            "Epoch 48/500\n",
            "28/28 [==============================] - 4s 157ms/step - loss: 0.5642 - auc: 0.9602 - val_loss: 0.5650 - val_auc: 0.9602\n",
            "Epoch 49/500\n",
            "28/28 [==============================] - 6s 227ms/step - loss: 0.5644 - auc: 0.9602 - val_loss: 0.5649 - val_auc: 0.9601\n",
            "Epoch 50/500\n",
            "28/28 [==============================] - 5s 181ms/step - loss: 0.5650 - auc: 0.9601 - val_loss: 0.5621 - val_auc: 0.9605\n",
            "Epoch 51/500\n",
            "28/28 [==============================] - 5s 161ms/step - loss: 0.5629 - auc: 0.9604 - val_loss: 0.5670 - val_auc: 0.9598\n",
            "Epoch 52/500\n",
            "28/28 [==============================] - 7s 243ms/step - loss: 0.5636 - auc: 0.9603 - val_loss: 0.5640 - val_auc: 0.9603\n",
            "Epoch 53/500\n",
            "28/28 [==============================] - 4s 159ms/step - loss: 0.5630 - auc: 0.9604 - val_loss: 0.5646 - val_auc: 0.9602\n",
            "Epoch 54/500\n",
            "28/28 [==============================] - 5s 165ms/step - loss: 0.5622 - auc: 0.9605 - val_loss: 0.5626 - val_auc: 0.9604\n",
            "Epoch 55/500\n",
            "28/28 [==============================] - 7s 239ms/step - loss: 0.5616 - auc: 0.9606 - val_loss: 0.5665 - val_auc: 0.9599\n",
            "Epoch 56/500\n",
            "28/28 [==============================] - 5s 164ms/step - loss: 0.5659 - auc: 0.9600 - val_loss: 0.5636 - val_auc: 0.9603\n",
            "Epoch 57/500\n",
            "28/28 [==============================] - 5s 179ms/step - loss: 0.5623 - auc: 0.9605 - val_loss: 0.5615 - val_auc: 0.9606\n",
            "Epoch 58/500\n",
            "28/28 [==============================] - 6s 215ms/step - loss: 0.5611 - auc: 0.9607 - val_loss: 0.5616 - val_auc: 0.9606\n",
            "Epoch 59/500\n",
            "28/28 [==============================] - 5s 162ms/step - loss: 0.5616 - auc: 0.9606 - val_loss: 0.5593 - val_auc: 0.9609\n",
            "Epoch 60/500\n",
            "28/28 [==============================] - 6s 199ms/step - loss: 0.5594 - auc: 0.9609 - val_loss: 0.5586 - val_auc: 0.9610\n",
            "Epoch 61/500\n",
            "28/28 [==============================] - 5s 191ms/step - loss: 0.5593 - auc: 0.9609 - val_loss: 0.5661 - val_auc: 0.9603\n",
            "Epoch 62/500\n",
            "28/28 [==============================] - 4s 151ms/step - loss: 0.5628 - auc: 0.9604 - val_loss: 0.5609 - val_auc: 0.9607\n",
            "Epoch 63/500\n",
            "28/28 [==============================] - 6s 213ms/step - loss: 0.5591 - auc: 0.9610 - val_loss: 0.5576 - val_auc: 0.9611\n",
            "Epoch 64/500\n",
            "28/28 [==============================] - 7s 236ms/step - loss: 0.5597 - auc: 0.9608 - val_loss: 0.5618 - val_auc: 0.9606\n",
            "Epoch 65/500\n",
            "28/28 [==============================] - 4s 159ms/step - loss: 0.5621 - auc: 0.9605 - val_loss: 0.5580 - val_auc: 0.9611\n",
            "Epoch 66/500\n",
            "28/28 [==============================] - 6s 226ms/step - loss: 0.5580 - auc: 0.9611 - val_loss: 0.5586 - val_auc: 0.9610\n",
            "Epoch 67/500\n",
            "28/28 [==============================] - 4s 152ms/step - loss: 0.5582 - auc: 0.9611 - val_loss: 0.5567 - val_auc: 0.9612\n",
            "Epoch 68/500\n",
            "28/28 [==============================] - 5s 175ms/step - loss: 0.5585 - auc: 0.9610 - val_loss: 0.5583 - val_auc: 0.9609\n",
            "Epoch 69/500\n",
            "28/28 [==============================] - 6s 203ms/step - loss: 0.5601 - auc: 0.9608 - val_loss: 0.5608 - val_auc: 0.9607\n",
            "Epoch 70/500\n",
            "28/28 [==============================] - 4s 153ms/step - loss: 0.5569 - auc: 0.9612 - val_loss: 0.5572 - val_auc: 0.9612\n",
            "Epoch 71/500\n",
            "28/28 [==============================] - 5s 187ms/step - loss: 0.5572 - auc: 0.9612 - val_loss: 0.5631 - val_auc: 0.9603\n",
            "Epoch 72/500\n",
            "28/28 [==============================] - 5s 189ms/step - loss: 0.5596 - auc: 0.9609 - val_loss: 0.5578 - val_auc: 0.9611\n",
            "Epoch 73/500\n",
            "28/28 [==============================] - 4s 158ms/step - loss: 0.5574 - auc: 0.9612 - val_loss: 0.5556 - val_auc: 0.9614\n",
            "Epoch 74/500\n",
            "28/28 [==============================] - 5s 198ms/step - loss: 0.5565 - auc: 0.9613 - val_loss: 0.5576 - val_auc: 0.9611\n",
            "Epoch 75/500\n",
            "28/28 [==============================] - 5s 185ms/step - loss: 0.5564 - auc: 0.9613 - val_loss: 0.5571 - val_auc: 0.9612\n",
            "Epoch 76/500\n",
            "28/28 [==============================] - 4s 155ms/step - loss: 0.5563 - auc: 0.9613 - val_loss: 0.5556 - val_auc: 0.9614\n",
            "Epoch 77/500\n",
            "28/28 [==============================] - 6s 213ms/step - loss: 0.5563 - auc: 0.9613 - val_loss: 0.5558 - val_auc: 0.9613\n",
            "Epoch 78/500\n",
            "28/28 [==============================] - 5s 171ms/step - loss: 0.5553 - auc: 0.9615 - val_loss: 0.5589 - val_auc: 0.9609\n",
            "Epoch 79/500\n",
            "28/28 [==============================] - 4s 154ms/step - loss: 0.5549 - auc: 0.9615 - val_loss: 0.5553 - val_auc: 0.9614\n",
            "Epoch 80/500\n",
            "28/28 [==============================] - 6s 231ms/step - loss: 0.5550 - auc: 0.9615 - val_loss: 0.5551 - val_auc: 0.9614\n",
            "Epoch 81/500\n",
            "28/28 [==============================] - 4s 155ms/step - loss: 0.5544 - auc: 0.9616 - val_loss: 0.5590 - val_auc: 0.9610\n",
            "Epoch 82/500\n",
            "28/28 [==============================] - 4s 160ms/step - loss: 0.5551 - auc: 0.9615 - val_loss: 0.5555 - val_auc: 0.9614\n",
            "Epoch 83/500\n",
            "28/28 [==============================] - 6s 229ms/step - loss: 0.5541 - auc: 0.9616 - val_loss: 0.5554 - val_auc: 0.9614\n",
            "Epoch 84/500\n",
            "28/28 [==============================] - 4s 152ms/step - loss: 0.5557 - auc: 0.9614 - val_loss: 0.5590 - val_auc: 0.9609\n",
            "Epoch 85/500\n",
            "28/28 [==============================] - 4s 159ms/step - loss: 0.5554 - auc: 0.9614 - val_loss: 0.5539 - val_auc: 0.9616\n",
            "Epoch 86/500\n",
            "28/28 [==============================] - 6s 231ms/step - loss: 0.5558 - auc: 0.9614 - val_loss: 0.5548 - val_auc: 0.9615\n",
            "Epoch 87/500\n",
            "28/28 [==============================] - 4s 152ms/step - loss: 0.5538 - auc: 0.9617 - val_loss: 0.5606 - val_auc: 0.9607\n",
            "Epoch 88/500\n",
            "28/28 [==============================] - 4s 159ms/step - loss: 0.5538 - auc: 0.9617 - val_loss: 0.5543 - val_auc: 0.9615\n",
            "Epoch 89/500\n",
            "28/28 [==============================] - 6s 229ms/step - loss: 0.5535 - auc: 0.9617 - val_loss: 0.5584 - val_auc: 0.9612\n",
            "Epoch 90/500\n",
            "28/28 [==============================] - 4s 154ms/step - loss: 0.5551 - auc: 0.9615 - val_loss: 0.5558 - val_auc: 0.9614\n",
            "Epoch 91/500\n",
            "28/28 [==============================] - 4s 161ms/step - loss: 0.5529 - auc: 0.9618 - val_loss: 0.5559 - val_auc: 0.9613\n",
            "Epoch 92/500\n",
            "28/28 [==============================] - 6s 224ms/step - loss: 0.5522 - auc: 0.9619 - val_loss: 0.5528 - val_auc: 0.9617\n",
            "Epoch 93/500\n",
            "28/28 [==============================] - 4s 155ms/step - loss: 0.5535 - auc: 0.9617 - val_loss: 0.5543 - val_auc: 0.9615\n",
            "Epoch 94/500\n",
            "28/28 [==============================] - 5s 182ms/step - loss: 0.5515 - auc: 0.9620 - val_loss: 0.5531 - val_auc: 0.9618\n",
            "Epoch 95/500\n",
            "28/28 [==============================] - 6s 203ms/step - loss: 0.5516 - auc: 0.9619 - val_loss: 0.5527 - val_auc: 0.9617\n",
            "Epoch 96/500\n",
            "28/28 [==============================] - 4s 153ms/step - loss: 0.5513 - auc: 0.9620 - val_loss: 0.5521 - val_auc: 0.9618\n",
            "Epoch 97/500\n",
            "28/28 [==============================] - 6s 198ms/step - loss: 0.5520 - auc: 0.9619 - val_loss: 0.5563 - val_auc: 0.9612\n",
            "Epoch 98/500\n",
            "28/28 [==============================] - 5s 187ms/step - loss: 0.5519 - auc: 0.9619 - val_loss: 0.5525 - val_auc: 0.9618\n",
            "Epoch 99/500\n",
            "28/28 [==============================] - 4s 154ms/step - loss: 0.5527 - auc: 0.9618 - val_loss: 0.5550 - val_auc: 0.9615\n",
            "Epoch 100/500\n",
            "28/28 [==============================] - 6s 219ms/step - loss: 0.5521 - auc: 0.9619 - val_loss: 0.5524 - val_auc: 0.9618\n",
            "Epoch 101/500\n",
            "28/28 [==============================] - 5s 165ms/step - loss: 0.5498 - auc: 0.9622 - val_loss: 0.5521 - val_auc: 0.9618\n",
            "Epoch 102/500\n",
            "28/28 [==============================] - 4s 153ms/step - loss: 0.5496 - auc: 0.9622 - val_loss: 0.5555 - val_auc: 0.9614\n",
            "Epoch 103/500\n",
            "28/28 [==============================] - 6s 230ms/step - loss: 0.5571 - auc: 0.9612 - val_loss: 0.5558 - val_auc: 0.9614\n",
            "Epoch 104/500\n",
            "28/28 [==============================] - 4s 155ms/step - loss: 0.5516 - auc: 0.9620 - val_loss: 0.5562 - val_auc: 0.9612\n",
            "Epoch 105/500\n",
            "28/28 [==============================] - 4s 160ms/step - loss: 0.5501 - auc: 0.9621 - val_loss: 0.5518 - val_auc: 0.9619\n",
            "Epoch 106/500\n",
            "28/28 [==============================] - 7s 262ms/step - loss: 0.5489 - auc: 0.9623 - val_loss: 0.5518 - val_auc: 0.9618\n",
            "Epoch 107/500\n",
            "28/28 [==============================] - 6s 197ms/step - loss: 0.5498 - auc: 0.9622 - val_loss: 0.5537 - val_auc: 0.9616\n",
            "Epoch 108/500\n",
            "28/28 [==============================] - 4s 160ms/step - loss: 0.5494 - auc: 0.9622 - val_loss: 0.5535 - val_auc: 0.9616\n",
            "Epoch 109/500\n",
            "28/28 [==============================] - 6s 221ms/step - loss: 0.5498 - auc: 0.9622 - val_loss: 0.5520 - val_auc: 0.9618\n",
            "Epoch 110/500\n",
            "28/28 [==============================] - 4s 154ms/step - loss: 0.5485 - auc: 0.9624 - val_loss: 0.5531 - val_auc: 0.9617\n",
            "Epoch 111/500\n",
            "28/28 [==============================] - 5s 172ms/step - loss: 0.5483 - auc: 0.9624 - val_loss: 0.5495 - val_auc: 0.9622\n",
            "Epoch 112/500\n",
            "28/28 [==============================] - 6s 212ms/step - loss: 0.5494 - auc: 0.9622 - val_loss: 0.5536 - val_auc: 0.9616\n",
            "Epoch 113/500\n",
            "28/28 [==============================] - 4s 161ms/step - loss: 0.5504 - auc: 0.9621 - val_loss: 0.5544 - val_auc: 0.9616\n",
            "Epoch 114/500\n",
            "28/28 [==============================] - 6s 200ms/step - loss: 0.5490 - auc: 0.9623 - val_loss: 0.5563 - val_auc: 0.9615\n",
            "Epoch 115/500\n",
            "28/28 [==============================] - 5s 180ms/step - loss: 0.5493 - auc: 0.9623 - val_loss: 0.5506 - val_auc: 0.9621\n",
            "Epoch 116/500\n",
            "28/28 [==============================] - 4s 153ms/step - loss: 0.5470 - auc: 0.9625 - val_loss: 0.5503 - val_auc: 0.9621\n",
            "Epoch 117/500\n",
            "28/28 [==============================] - 6s 211ms/step - loss: 0.5483 - auc: 0.9624 - val_loss: 0.5496 - val_auc: 0.9621\n",
            "Epoch 118/500\n",
            "28/28 [==============================] - 5s 172ms/step - loss: 0.5481 - auc: 0.9624 - val_loss: 0.5522 - val_auc: 0.9617\n",
            "Epoch 119/500\n",
            "28/28 [==============================] - 4s 155ms/step - loss: 0.5477 - auc: 0.9625 - val_loss: 0.5571 - val_auc: 0.9615\n",
            "Epoch 120/500\n",
            "28/28 [==============================] - 6s 230ms/step - loss: 0.5494 - auc: 0.9623 - val_loss: 0.5492 - val_auc: 0.9622\n",
            "Epoch 121/500\n",
            "28/28 [==============================] - 4s 154ms/step - loss: 0.5474 - auc: 0.9625 - val_loss: 0.5499 - val_auc: 0.9621\n",
            "Fold 2/10\n",
            "Epoch 1/500\n",
            "28/28 [==============================] - 4s 155ms/step - loss: 0.5471 - auc: 0.9625 - val_loss: 0.5455 - val_auc: 0.9628\n",
            "Epoch 2/500\n",
            "28/28 [==============================] - 6s 234ms/step - loss: 0.5484 - auc: 0.9624 - val_loss: 0.5454 - val_auc: 0.9628\n",
            "Epoch 3/500\n",
            "28/28 [==============================] - 4s 154ms/step - loss: 0.5502 - auc: 0.9621 - val_loss: 0.5465 - val_auc: 0.9627\n",
            "Epoch 4/500\n",
            "28/28 [==============================] - 4s 159ms/step - loss: 0.5463 - auc: 0.9626 - val_loss: 0.5447 - val_auc: 0.9629\n",
            "Epoch 5/500\n",
            "28/28 [==============================] - 6s 229ms/step - loss: 0.5466 - auc: 0.9626 - val_loss: 0.5459 - val_auc: 0.9628\n",
            "Epoch 6/500\n",
            "28/28 [==============================] - 4s 154ms/step - loss: 0.5472 - auc: 0.9625 - val_loss: 0.5563 - val_auc: 0.9613\n",
            "Epoch 7/500\n",
            "28/28 [==============================] - 4s 152ms/step - loss: 0.5485 - auc: 0.9623 - val_loss: 0.5457 - val_auc: 0.9628\n",
            "Epoch 8/500\n",
            "28/28 [==============================] - 7s 234ms/step - loss: 0.5477 - auc: 0.9624 - val_loss: 0.5487 - val_auc: 0.9625\n",
            "Epoch 9/500\n",
            "28/28 [==============================] - 4s 153ms/step - loss: 0.5475 - auc: 0.9625 - val_loss: 0.5462 - val_auc: 0.9627\n",
            "Fold 3/10\n",
            "Epoch 1/500\n",
            "28/28 [==============================] - 5s 171ms/step - loss: 0.5451 - auc: 0.9628 - val_loss: 0.5499 - val_auc: 0.9621\n",
            "Epoch 2/500\n",
            "28/28 [==============================] - 6s 208ms/step - loss: 0.5459 - auc: 0.9627 - val_loss: 0.5489 - val_auc: 0.9620\n",
            "Epoch 3/500\n",
            "28/28 [==============================] - 4s 160ms/step - loss: 0.5454 - auc: 0.9628 - val_loss: 0.5518 - val_auc: 0.9616\n",
            "Epoch 4/500\n",
            "28/28 [==============================] - 5s 193ms/step - loss: 0.5463 - auc: 0.9627 - val_loss: 0.5489 - val_auc: 0.9620\n",
            "Epoch 5/500\n",
            "28/28 [==============================] - 5s 186ms/step - loss: 0.5444 - auc: 0.9629 - val_loss: 0.5476 - val_auc: 0.9622\n",
            "Epoch 6/500\n",
            "28/28 [==============================] - 4s 160ms/step - loss: 0.5438 - auc: 0.9630 - val_loss: 0.5490 - val_auc: 0.9621\n",
            "Epoch 7/500\n",
            "28/28 [==============================] - 6s 213ms/step - loss: 0.5441 - auc: 0.9629 - val_loss: 0.5510 - val_auc: 0.9619\n",
            "Epoch 8/500\n",
            "28/28 [==============================] - 5s 173ms/step - loss: 0.5452 - auc: 0.9628 - val_loss: 0.5469 - val_auc: 0.9623\n",
            "Epoch 9/500\n",
            "28/28 [==============================] - 4s 161ms/step - loss: 0.5435 - auc: 0.9630 - val_loss: 0.5463 - val_auc: 0.9624\n",
            "Epoch 10/500\n",
            "28/28 [==============================] - 6s 234ms/step - loss: 0.5443 - auc: 0.9629 - val_loss: 0.5479 - val_auc: 0.9622\n",
            "Epoch 11/500\n",
            "28/28 [==============================] - 4s 155ms/step - loss: 0.5440 - auc: 0.9629 - val_loss: 0.5485 - val_auc: 0.9622\n",
            "Epoch 12/500\n",
            "28/28 [==============================] - 4s 160ms/step - loss: 0.5448 - auc: 0.9628 - val_loss: 0.5480 - val_auc: 0.9623\n",
            "Epoch 13/500\n",
            "28/28 [==============================] - 7s 237ms/step - loss: 0.5469 - auc: 0.9625 - val_loss: 0.5533 - val_auc: 0.9616\n",
            "Epoch 14/500\n",
            "28/28 [==============================] - 4s 154ms/step - loss: 0.5474 - auc: 0.9625 - val_loss: 0.5475 - val_auc: 0.9622\n",
            "Fold 4/10\n",
            "Epoch 1/500\n",
            "28/28 [==============================] - 4s 152ms/step - loss: 0.5434 - auc: 0.9630 - val_loss: 0.5415 - val_auc: 0.9632\n",
            "Epoch 2/500\n",
            "28/28 [==============================] - 8s 276ms/step - loss: 0.5425 - auc: 0.9631 - val_loss: 0.5430 - val_auc: 0.9630\n",
            "Epoch 3/500\n",
            "28/28 [==============================] - 5s 184ms/step - loss: 0.5433 - auc: 0.9630 - val_loss: 0.5535 - val_auc: 0.9616\n",
            "Epoch 4/500\n",
            "28/28 [==============================] - 4s 156ms/step - loss: 0.5483 - auc: 0.9624 - val_loss: 0.5450 - val_auc: 0.9627\n",
            "Epoch 5/500\n",
            "28/28 [==============================] - 6s 211ms/step - loss: 0.5432 - auc: 0.9630 - val_loss: 0.5432 - val_auc: 0.9630\n",
            "Epoch 6/500\n",
            "28/28 [==============================] - 5s 170ms/step - loss: 0.5436 - auc: 0.9630 - val_loss: 0.5428 - val_auc: 0.9631\n",
            "Epoch 7/500\n",
            "28/28 [==============================] - 4s 160ms/step - loss: 0.5458 - auc: 0.9627 - val_loss: 0.5482 - val_auc: 0.9623\n",
            "Fold 5/10\n",
            "Epoch 1/500\n",
            "28/28 [==============================] - 6s 234ms/step - loss: 0.5436 - auc: 0.9630 - val_loss: 0.5444 - val_auc: 0.9629\n",
            "Epoch 2/500\n",
            "28/28 [==============================] - 4s 156ms/step - loss: 0.5428 - auc: 0.9631 - val_loss: 0.5472 - val_auc: 0.9625\n",
            "Epoch 3/500\n",
            "28/28 [==============================] - 4s 156ms/step - loss: 0.5421 - auc: 0.9632 - val_loss: 0.5445 - val_auc: 0.9628\n",
            "Epoch 4/500\n",
            "28/28 [==============================] - 6s 231ms/step - loss: 0.5413 - auc: 0.9633 - val_loss: 0.5433 - val_auc: 0.9630\n",
            "Epoch 5/500\n",
            "28/28 [==============================] - 4s 154ms/step - loss: 0.5412 - auc: 0.9633 - val_loss: 0.5467 - val_auc: 0.9626\n",
            "Epoch 6/500\n",
            "28/28 [==============================] - 4s 154ms/step - loss: 0.5422 - auc: 0.9632 - val_loss: 0.5454 - val_auc: 0.9628\n",
            "Epoch 7/500\n",
            "28/28 [==============================] - 7s 237ms/step - loss: 0.5406 - auc: 0.9634 - val_loss: 0.5434 - val_auc: 0.9630\n",
            "Epoch 8/500\n",
            "28/28 [==============================] - 4s 155ms/step - loss: 0.5445 - auc: 0.9629 - val_loss: 0.5451 - val_auc: 0.9627\n",
            "Epoch 9/500\n",
            "28/28 [==============================] - 4s 156ms/step - loss: 0.5418 - auc: 0.9632 - val_loss: 0.5462 - val_auc: 0.9626\n",
            "Epoch 10/500\n",
            "28/28 [==============================] - 6s 230ms/step - loss: 0.5407 - auc: 0.9634 - val_loss: 0.5440 - val_auc: 0.9629\n",
            "Epoch 11/500\n",
            "28/28 [==============================] - 4s 161ms/step - loss: 0.5396 - auc: 0.9635 - val_loss: 0.5453 - val_auc: 0.9628\n",
            "Epoch 12/500\n",
            "28/28 [==============================] - 5s 172ms/step - loss: 0.5398 - auc: 0.9635 - val_loss: 0.5469 - val_auc: 0.9626\n",
            "Epoch 13/500\n",
            "28/28 [==============================] - 6s 216ms/step - loss: 0.5432 - auc: 0.9630 - val_loss: 0.5514 - val_auc: 0.9619\n",
            "Epoch 14/500\n",
            "28/28 [==============================] - 5s 161ms/step - loss: 0.5411 - auc: 0.9633 - val_loss: 0.5505 - val_auc: 0.9620\n",
            "Epoch 15/500\n",
            "28/28 [==============================] - 5s 197ms/step - loss: 0.5428 - auc: 0.9631 - val_loss: 0.5446 - val_auc: 0.9628\n",
            "Epoch 16/500\n",
            "28/28 [==============================] - 5s 180ms/step - loss: 0.5433 - auc: 0.9630 - val_loss: 0.5503 - val_auc: 0.9622\n",
            "Fold 6/10\n",
            "Epoch 1/500\n",
            "28/28 [==============================] - 5s 162ms/step - loss: 0.5430 - auc: 0.9631 - val_loss: 0.5409 - val_auc: 0.9635\n",
            "Epoch 2/500\n",
            "28/28 [==============================] - 4s 155ms/step - loss: 0.5427 - auc: 0.9631 - val_loss: 0.5402 - val_auc: 0.9636\n",
            "Epoch 3/500\n",
            "28/28 [==============================] - 7s 239ms/step - loss: 0.5425 - auc: 0.9631 - val_loss: 0.5380 - val_auc: 0.9640\n",
            "Epoch 4/500\n",
            "28/28 [==============================] - 4s 155ms/step - loss: 0.5406 - auc: 0.9634 - val_loss: 0.5378 - val_auc: 0.9639\n",
            "Epoch 5/500\n",
            "28/28 [==============================] - 5s 163ms/step - loss: 0.5401 - auc: 0.9634 - val_loss: 0.5388 - val_auc: 0.9638\n",
            "Epoch 6/500\n",
            "28/28 [==============================] - 7s 236ms/step - loss: 0.5419 - auc: 0.9632 - val_loss: 0.5390 - val_auc: 0.9637\n",
            "Epoch 7/500\n",
            "28/28 [==============================] - 4s 160ms/step - loss: 0.5396 - auc: 0.9635 - val_loss: 0.5365 - val_auc: 0.9640\n",
            "Epoch 8/500\n",
            "28/28 [==============================] - 7s 272ms/step - loss: 0.5398 - auc: 0.9635 - val_loss: 0.5383 - val_auc: 0.9638\n",
            "Epoch 9/500\n",
            "28/28 [==============================] - 6s 194ms/step - loss: 0.5402 - auc: 0.9634 - val_loss: 0.5390 - val_auc: 0.9638\n",
            "Epoch 10/500\n",
            "28/28 [==============================] - 4s 158ms/step - loss: 0.5400 - auc: 0.9634 - val_loss: 0.5429 - val_auc: 0.9631\n",
            "Epoch 11/500\n",
            "28/28 [==============================] - 6s 213ms/step - loss: 0.5390 - auc: 0.9636 - val_loss: 0.5374 - val_auc: 0.9640\n",
            "Epoch 12/500\n",
            "28/28 [==============================] - 5s 172ms/step - loss: 0.5389 - auc: 0.9636 - val_loss: 0.5381 - val_auc: 0.9638\n",
            "Epoch 13/500\n",
            "28/28 [==============================] - 4s 155ms/step - loss: 0.5410 - auc: 0.9633 - val_loss: 0.5507 - val_auc: 0.9621\n",
            "Epoch 14/500\n",
            "28/28 [==============================] - 6s 232ms/step - loss: 0.5404 - auc: 0.9634 - val_loss: 0.5412 - val_auc: 0.9634\n",
            "Epoch 15/500\n",
            "28/28 [==============================] - 4s 156ms/step - loss: 0.5382 - auc: 0.9637 - val_loss: 0.5391 - val_auc: 0.9637\n",
            "Epoch 16/500\n",
            "28/28 [==============================] - 5s 162ms/step - loss: 0.5378 - auc: 0.9637 - val_loss: 0.5395 - val_auc: 0.9638\n",
            "Epoch 17/500\n",
            "28/28 [==============================] - 6s 232ms/step - loss: 0.5405 - auc: 0.9634 - val_loss: 0.5370 - val_auc: 0.9640\n",
            "Epoch 18/500\n",
            "28/28 [==============================] - 5s 161ms/step - loss: 0.5406 - auc: 0.9634 - val_loss: 0.5431 - val_auc: 0.9631\n",
            "Epoch 19/500\n",
            "28/28 [==============================] - 4s 156ms/step - loss: 0.5397 - auc: 0.9635 - val_loss: 0.5371 - val_auc: 0.9640\n",
            "Epoch 20/500\n",
            "28/28 [==============================] - 7s 237ms/step - loss: 0.5378 - auc: 0.9637 - val_loss: 0.5372 - val_auc: 0.9639\n",
            "Epoch 21/500\n",
            "28/28 [==============================] - 5s 161ms/step - loss: 0.5384 - auc: 0.9636 - val_loss: 0.5406 - val_auc: 0.9636\n",
            "Fold 7/10\n",
            "Epoch 1/500\n",
            "28/28 [==============================] - 5s 178ms/step - loss: 0.5388 - auc: 0.9636 - val_loss: 0.5402 - val_auc: 0.9634\n",
            "Epoch 2/500\n",
            "28/28 [==============================] - 6s 213ms/step - loss: 0.5376 - auc: 0.9637 - val_loss: 0.5397 - val_auc: 0.9635\n",
            "Epoch 3/500\n",
            "28/28 [==============================] - 4s 156ms/step - loss: 0.5375 - auc: 0.9638 - val_loss: 0.5437 - val_auc: 0.9630\n",
            "Epoch 4/500\n",
            "28/28 [==============================] - 5s 198ms/step - loss: 0.5370 - auc: 0.9639 - val_loss: 0.5410 - val_auc: 0.9633\n",
            "Epoch 5/500\n",
            "28/28 [==============================] - 5s 191ms/step - loss: 0.5371 - auc: 0.9638 - val_loss: 0.5449 - val_auc: 0.9628\n",
            "Epoch 6/500\n",
            "28/28 [==============================] - 4s 157ms/step - loss: 0.5380 - auc: 0.9637 - val_loss: 0.5476 - val_auc: 0.9626\n",
            "Epoch 7/500\n",
            "28/28 [==============================] - 6s 224ms/step - loss: 0.5388 - auc: 0.9636 - val_loss: 0.5400 - val_auc: 0.9634\n",
            "Epoch 8/500\n",
            "28/28 [==============================] - 5s 160ms/step - loss: 0.5359 - auc: 0.9640 - val_loss: 0.5431 - val_auc: 0.9630\n",
            "Epoch 9/500\n",
            "28/28 [==============================] - 5s 162ms/step - loss: 0.5393 - auc: 0.9636 - val_loss: 0.5479 - val_auc: 0.9625\n",
            "Epoch 10/500\n",
            "28/28 [==============================] - 7s 238ms/step - loss: 0.5389 - auc: 0.9636 - val_loss: 0.5414 - val_auc: 0.9632\n",
            "Epoch 11/500\n",
            "28/28 [==============================] - 4s 156ms/step - loss: 0.5362 - auc: 0.9639 - val_loss: 0.5422 - val_auc: 0.9631\n",
            "Epoch 12/500\n",
            "28/28 [==============================] - 5s 162ms/step - loss: 0.5360 - auc: 0.9640 - val_loss: 0.5422 - val_auc: 0.9632\n",
            "Epoch 13/500\n",
            "28/28 [==============================] - 6s 233ms/step - loss: 0.5368 - auc: 0.9639 - val_loss: 0.5415 - val_auc: 0.9632\n",
            "Fold 8/10\n",
            "Epoch 1/500\n",
            "28/28 [==============================] - 4s 156ms/step - loss: 0.5386 - auc: 0.9636 - val_loss: 0.5369 - val_auc: 0.9639\n",
            "Epoch 2/500\n",
            "28/28 [==============================] - 5s 194ms/step - loss: 0.5385 - auc: 0.9636 - val_loss: 0.5374 - val_auc: 0.9638\n",
            "Epoch 3/500\n",
            "28/28 [==============================] - 5s 189ms/step - loss: 0.5361 - auc: 0.9639 - val_loss: 0.5348 - val_auc: 0.9641\n",
            "Epoch 4/500\n",
            "28/28 [==============================] - 4s 154ms/step - loss: 0.5351 - auc: 0.9641 - val_loss: 0.5393 - val_auc: 0.9637\n",
            "Epoch 5/500\n",
            "28/28 [==============================] - 6s 207ms/step - loss: 0.5382 - auc: 0.9637 - val_loss: 0.5366 - val_auc: 0.9639\n",
            "Epoch 6/500\n",
            "28/28 [==============================] - 5s 175ms/step - loss: 0.5365 - auc: 0.9639 - val_loss: 0.5397 - val_auc: 0.9635\n",
            "Epoch 7/500\n",
            "28/28 [==============================] - 4s 155ms/step - loss: 0.5409 - auc: 0.9634 - val_loss: 0.5371 - val_auc: 0.9639\n",
            "Epoch 8/500\n",
            "28/28 [==============================] - 6s 228ms/step - loss: 0.5348 - auc: 0.9641 - val_loss: 0.5350 - val_auc: 0.9641\n",
            "Epoch 9/500\n",
            "28/28 [==============================] - 4s 155ms/step - loss: 0.5358 - auc: 0.9640 - val_loss: 0.5354 - val_auc: 0.9641\n",
            "Epoch 10/500\n",
            "28/28 [==============================] - 4s 160ms/step - loss: 0.5379 - auc: 0.9637 - val_loss: 0.5394 - val_auc: 0.9636\n",
            "Epoch 11/500\n",
            "28/28 [==============================] - 6s 232ms/step - loss: 0.5357 - auc: 0.9640 - val_loss: 0.5369 - val_auc: 0.9639\n",
            "Epoch 12/500\n",
            "28/28 [==============================] - 5s 162ms/step - loss: 0.5350 - auc: 0.9641 - val_loss: 0.5370 - val_auc: 0.9639\n",
            "Epoch 13/500\n",
            "28/28 [==============================] - 4s 156ms/step - loss: 0.5346 - auc: 0.9641 - val_loss: 0.5356 - val_auc: 0.9640\n",
            "Epoch 14/500\n",
            "28/28 [==============================] - 6s 234ms/step - loss: 0.5346 - auc: 0.9641 - val_loss: 0.5403 - val_auc: 0.9635\n",
            "Epoch 15/500\n",
            "28/28 [==============================] - 4s 156ms/step - loss: 0.5383 - auc: 0.9637 - val_loss: 0.5375 - val_auc: 0.9638\n",
            "Epoch 16/500\n",
            "28/28 [==============================] - 4s 156ms/step - loss: 0.5353 - auc: 0.9641 - val_loss: 0.5393 - val_auc: 0.9636\n",
            "Epoch 17/500\n",
            "28/28 [==============================] - 7s 238ms/step - loss: 0.5332 - auc: 0.9643 - val_loss: 0.5375 - val_auc: 0.9638\n",
            "Epoch 18/500\n",
            "28/28 [==============================] - 4s 157ms/step - loss: 0.5371 - auc: 0.9638 - val_loss: 0.5372 - val_auc: 0.9638\n",
            "Epoch 19/500\n",
            "28/28 [==============================] - 5s 184ms/step - loss: 0.5343 - auc: 0.9642 - val_loss: 0.5383 - val_auc: 0.9638\n",
            "Epoch 20/500\n",
            "28/28 [==============================] - 6s 215ms/step - loss: 0.5332 - auc: 0.9643 - val_loss: 0.5403 - val_auc: 0.9636\n",
            "Epoch 21/500\n",
            "28/28 [==============================] - 5s 162ms/step - loss: 0.5339 - auc: 0.9642 - val_loss: 0.5377 - val_auc: 0.9639\n",
            "Epoch 22/500\n",
            "28/28 [==============================] - 6s 204ms/step - loss: 0.5335 - auc: 0.9643 - val_loss: 0.5406 - val_auc: 0.9634\n",
            "Fold 9/10\n",
            "Epoch 1/500\n",
            "28/28 [==============================] - 5s 163ms/step - loss: 0.5363 - auc: 0.9639 - val_loss: 0.5329 - val_auc: 0.9645\n",
            "Epoch 2/500\n",
            "28/28 [==============================] - 6s 216ms/step - loss: 0.5358 - auc: 0.9640 - val_loss: 0.5338 - val_auc: 0.9644\n",
            "Epoch 3/500\n",
            "28/28 [==============================] - 5s 168ms/step - loss: 0.5337 - auc: 0.9643 - val_loss: 0.5318 - val_auc: 0.9646\n",
            "Epoch 4/500\n",
            "28/28 [==============================] - 5s 162ms/step - loss: 0.5353 - auc: 0.9640 - val_loss: 0.5350 - val_auc: 0.9643\n",
            "Epoch 5/500\n",
            "28/28 [==============================] - 6s 230ms/step - loss: 0.5392 - auc: 0.9636 - val_loss: 0.5376 - val_auc: 0.9639\n",
            "Epoch 6/500\n",
            "28/28 [==============================] - 5s 161ms/step - loss: 0.5353 - auc: 0.9641 - val_loss: 0.5338 - val_auc: 0.9644\n",
            "Epoch 7/500\n",
            "28/28 [==============================] - 4s 155ms/step - loss: 0.5334 - auc: 0.9643 - val_loss: 0.5336 - val_auc: 0.9644\n",
            "Epoch 8/500\n",
            "28/28 [==============================] - 7s 237ms/step - loss: 0.5328 - auc: 0.9644 - val_loss: 0.5349 - val_auc: 0.9642\n",
            "Epoch 9/500\n",
            "28/28 [==============================] - 4s 155ms/step - loss: 0.5340 - auc: 0.9642 - val_loss: 0.5361 - val_auc: 0.9640\n",
            "Epoch 10/500\n",
            "28/28 [==============================] - 4s 157ms/step - loss: 0.5353 - auc: 0.9640 - val_loss: 0.5372 - val_auc: 0.9640\n",
            "Epoch 11/500\n",
            "28/28 [==============================] - 7s 239ms/step - loss: 0.5354 - auc: 0.9640 - val_loss: 0.5350 - val_auc: 0.9643\n",
            "Epoch 12/500\n",
            "28/28 [==============================] - 4s 155ms/step - loss: 0.5391 - auc: 0.9636 - val_loss: 0.5449 - val_auc: 0.9631\n",
            "Epoch 13/500\n",
            "28/28 [==============================] - 4s 160ms/step - loss: 0.5348 - auc: 0.9641 - val_loss: 0.5338 - val_auc: 0.9643\n",
            "Fold 10/10\n",
            "Epoch 1/500\n",
            "28/28 [==============================] - 5s 162ms/step - loss: 0.5324 - auc: 0.9644 - val_loss: 0.5303 - val_auc: 0.9647\n",
            "Epoch 2/500\n",
            "28/28 [==============================] - ETA: 0s - loss: 0.5330 - auc: 0.9643"
          ]
        }
      ],
      "source": [
        "es = EarlyStopping(\n",
        "                       monitor='loss',\n",
        "                       mode='min',\n",
        "                       patience=5,\n",
        "                       min_delta=0.0001\n",
        "                       )\n",
        "fold = 0\n",
        "hist = []\n",
        "for train_idx, val_idx in kf.split(X_bal, y_bal):\n",
        "  fold += 1\n",
        "  print(f\"Fold {fold}/10\")\n",
        "  Xfold_train, Xfold_val = X_bal[train_idx], X_bal[val_idx]\n",
        "  yfold_cat_train, yfold_cat_val = y_cat[train_idx], y_cat[val_idx]\n",
        "  metrics = mdl.fit(Xfold_train, yfold_cat_train,\n",
        "          validation_data=(Xfold_val, yfold_cat_val),\n",
        "          epochs=500, verbose=1,\n",
        "          batch_size=16000,\n",
        "          callbacks=[es])\n",
        "  hist.append(metrics)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 996
        },
        "id": "KpAaucZT0USe",
        "outputId": "98e8f093-43d8-44b0-84a4-de3d1cde44bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1610/1610 [==============================] - 2s 1ms/step\n",
            "Accuracy:  0.7129766249902928\n",
            "AUC:  0.7394281882941519\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x800 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.89      0.82     33656\n",
            "           1       0.43      0.35      0.39       916\n",
            "           2       0.06      0.40      0.11        63\n",
            "           3       0.42      0.53      0.47      1050\n",
            "           4       0.44      1.00      0.61        88\n",
            "           5       0.63      0.38      0.47     15735\n",
            "\n",
            "    accuracy                           0.71     51508\n",
            "   macro avg       0.46      0.59      0.48     51508\n",
            "weighted avg       0.70      0.71      0.69     51508\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\n",
        "from sklearn.preprocessing import label_binarize\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def report(model, X_test, y_test):\n",
        "    outputs = model.predict(X_test)\n",
        "    y_pred = np.argmax(outputs, axis=1)\n",
        "    y_true = y_test\n",
        "\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    print(\"Accuracy: \", accuracy)\n",
        "\n",
        "    # Binarize labels and compute ROC AUC\n",
        "    y_true_bin = label_binarize(y_true, classes=np.arange(num_classes))\n",
        "    y_pred_bin = label_binarize(y_pred, classes=np.arange(num_classes))\n",
        "    auc = roc_auc_score(y_true_bin, y_pred_bin, average='macro', multi_class='ovr')\n",
        "    print(\"AUC: \", auc)\n",
        "\n",
        "    report = classification_report(y_true, y_pred)\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "    # Plotting confusion matrix\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(cm, annot=True, cmap=\"Blues\", fmt=\"d\")\n",
        "    plt.title(\"Confusion Matrix\")\n",
        "    plt.xlabel(\"Predicted Labels\")\n",
        "    plt.ylabel(\"True Labels\")\n",
        "    plt.show()\n",
        "\n",
        "    return report\n",
        "\n",
        "report = report(mdl, X_test, y_test)\n",
        "print(report)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ifu0cjGapiW6"
      },
      "outputs": [],
      "source": [
        "mdl.save(path + 'model/keras/mdl234boost.keras')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
